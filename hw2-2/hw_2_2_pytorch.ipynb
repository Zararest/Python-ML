{"cells":[{"cell_type":"markdown","metadata":{"id":"cX_WL9cbbJas"},"source":["# Домашнее задание 2.2. Обучение сетей на Pytorch"]},{"cell_type":"markdown","metadata":{"id":"JMCFXAYFNpFx"},"source":["В этом задании нужно:\n","1. Написать свою сеть на Pytorch по варианту\n","2. Обучить ее и сравнить результаты с дообученной сетью из зоопарка моделей\n","3. Поставить ряд экспериментов, показывающих насколько гиперпараметры обучения влияют на результат"]},{"cell_type":"markdown","metadata":{"id":"qHaLl3E5cwy_"},"source":["**Варианты архитектуры сверточной сети:**\n","Вариант на ваш выбор - напишите его в чат. Не более двух человек на один вариант\n","1. Resnet v2\n","2. Inception Google LeNet\n","3. MobileNetv2 (Коростинский, Глаз)\n","4. SE Net\n","5. DenseNet\n","6. Conv Mixer\n","7. RepVGG"]},{"cell_type":"markdown","metadata":{"id":"3bWCyebM5HCh"},"source":["## Имплементация сети на Pytorch"]},{"cell_type":"markdown","metadata":{"id":"8_rU_f5-5L3D"},"source":["Здесь вы должны написать модель, выданную вам по варианту.\n","Для этого нужно:\n","1. Не забывать про использоватие блоков nn.Module, nn.Sequential, nn.ModuleList\n","2. Использовать материалы из предыдущих семинаров\n","\n","В качестве примера ниже реализован макет для модели, состоящей из блоков."]},{"cell_type":"markdown","metadata":{},"source":["## Архитектура Dense слоя сети DenseNet. \n","В нем все  признаки с каждого слоя конкатенируются и передаются во все следующие.\n","\n","![image.png](DenseNet.jpg)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"RjMhL5bcagsR"},"outputs":[],"source":["import torch\n","from torch import nn\n","from collections import OrderedDict"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Input: (N, C, H, W) tensor\n","# Layer: combination of (BN2D + ReLu + Conv2D1x1 + BN2D + ReLu + Conv2D3x3) layers\n","# Arch: each layer l accepts k_0 + k * (l - 1) feature maps\n","# There is a bottleneck in each layer: each Conv2D1x1 reduces number of chanels to bn_size\n","# This is needed because first convolution might have high num_input_features \n","#   because of data from the previous layers:\n","# Example of how C changes throughout the network:\n","# \tlayer 1: (input) -> (bn_size * k) -> (k) \n","#\t\t \t\t|\t\t\t\t\t\t |\n","# \t\t \t\t|\t\t\t\t\t\t V\n","# \tlayer 2: \t--------------> (input + k) -> (bn_size * k) -> (k)\n","#   layer 3:    (input + k + k) -> (bn_size * k) -> (k)\n","\n","# Size change:\n","#   (h, w) -> (h, w)\n","class DenseLayer(nn.Module):\n","\tdef __init__(self, num_input_features : int, bottle_neck_dim : int, num_out_features : int) -> None:\n","\t\tsuper().__init__()\n","\t\tself.bottle_neck = nn.Sequential(OrderedDict([ \n","\t\t\t('norm1', nn.BatchNorm2d(num_input_features)),\n","\t\t\t('relu1', nn.ReLU()),\n","\t\t\t('conv1', nn.Conv2d(num_input_features, bottle_neck_dim,\n","\t\t\t\t\t\t\tkernel_size=1, stride=1, bias=False))]))\n","\t\t\n","\t\tself.conv = nn.Sequential(OrderedDict([\n","\t\t\t('norm2', nn.BatchNorm2d(bottle_neck_dim)),\n","\t\t\t('relu2', nn.ReLU()),\n","\t\t\t# Pudding is needed in order to match concatinating outputs\n","\t\t\t('conv2', nn.Conv2d(bottle_neck_dim, num_out_features,\n","\t\t\t\t\t\t\tkernel_size=3, stride=1, padding=1, bias=False)),\n","\t\t]))\n","\t\t\n","\tdef forward(self, input : torch.tensor) -> torch.tensor:\n","\t\tbottle_neck_output = self.bottle_neck(input)\n","\t\treturn self.conv(bottle_neck_output)\n","\n","class DenseBlock(nn.Module):\n","\tdef __init__(self, num_input_features : int, num_layers : int, k : int, bn_size : int) -> None:\n","\t\tsuper().__init__()\n","\t\tself.dense_blocks = nn.Sequential()\n","\t\tcur_num_input_features = num_input_features\n","\t\tfor l in range(num_layers):\n","\t\t\tlayer = DenseLayer(num_input_features=cur_num_input_features, \n","\t\t\t\t\t\t\t   bottle_neck_dim=bn_size, \n","\t\t\t\t\t\t\t   num_out_features=k)\n","\t\t\tself.dense_blocks.add_module(f\"denseblock{l}\", layer)\n","\t\t\tcur_num_input_features = (l + 1) * k\n","\t\t\n","\tdef forward(self, input : torch.tensor) -> torch.tensor:\n","\t\tprev_features = None\n","\t\tfor layer in self.dense_blocks:\n","\t\t\toutput = layer(input)\n","\t\t\t# dim=1 is a dimension of blocks\n","\t\t\tif prev_features is not None:\n","\t\t\t\tinput = torch.cat((prev_features, output), dim=1)\n","\t\t\telse:\n","\t\t\t\tinput = output\n","\t\t\tprev_features = input\n","\t\treturn input"]},{"cell_type":"markdown","metadata":{},"source":["Архитектура из оригинальной статьи (после кажой свертки стоит BatchNorm и ReLu):\n","- 7 × 7 conv, stride 2\n","- 3 × 3 max pool, stride 2\n","- dense layer x 6\n","- 1 × 1 conv\n","- 2 × 2 average pool, stride 2\n","- dense layer x 12\n","- 1 × 1 conv\n","- 2 × 2 average pool, stride 2\n","- dense layer x 24\n","- 1 × 1 conv\n","- 2 × 2 average pool, stride 2\n","- dense layer x 16\n","- 1 × 1 conv\n","- 7 × 7 global average pool\n","- fully-connected, softmax\n","\n","Она была рассчитана на картинки большего размера. Для работы с картинками 32х32 была разработана архитектура:\n","- (32, 32)\n","- 7 × 7 conv, stride 1 -> (26, 26)\n","- 3 × 3 max pool, stride 2 -> (12, 12)\n","- dense layer x 6 -> (12, 12)\n","- 1 × 1 conv -> (12, 12)\n","- 2 × 2 average pool, stride 1 -> (6, 6)\n","- dense layer x 12 -> (6, 6)\n","- 1 × 1 conv -> (6, 6)\n","- 6 × 6 global average pool -> (1, 1)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Tp_igxkE6BnN"},"outputs":[],"source":["class DenseNet(nn.Module):\n","    def __init__(self, num_input_features : int, num_classes : int,\n","                 init_conv_num_features=24, k=4, bn_size=16, compression=0.5) -> None:\n","        super().__init__()\n","\n","        self.blocks = nn.Sequential(OrderedDict([\n","          ('conv0', nn.Conv2d(num_input_features, init_conv_num_features, \n","                              kernel_size=(7, 7), stride=1)),\n","          ('norm0', nn.BatchNorm2d(init_conv_num_features)),\n","          ('relu0', nn.ReLU()),\n","          ('maxpool', nn.MaxPool2d(kernel_size=(3, 3), stride=2))\n","\t\t]))\n","\n","        dense_sizes = [6, 12]\n","        dense_input_features_size = init_conv_num_features\n","        block_num = 1\n","        for dense_block_size in dense_sizes:\n","            self.blocks.add_module(f\"dense{block_num}\", \n","                DenseBlock(num_input_features=dense_input_features_size, \n","                            num_layers=dense_block_size, k=k, bn_size=bn_size))\n","            \n","            conv_input_feature_size = k * dense_block_size\n","            conv_output_feature_size = int(conv_input_feature_size * compression)\n","            self.blocks.add_module(f\"compress{block_num}\",\n","\t\t\t\tnn.Conv2d(in_channels=conv_input_feature_size,\n","              \t\t\t  out_channels=conv_output_feature_size,\n","                          kernel_size=(1, 1)))\n","            \n","            self.blocks.add_module(f\"norm{block_num}\", nn.BatchNorm2d(conv_output_feature_size))\n","            self.blocks.add_module(f\"relu{block_num}\", nn.ReLU())\n","            # last pooling is 7x7\n","            if block_num != len(dense_sizes):\n","                self.blocks.add_module(f\"avgpool{block_num}\", nn.AvgPool2d(kernel_size=(2, 2), stride=1))\n","            dense_input_features_size = conv_output_feature_size\n","            block_num += 1\t\t\t\n","\n","        # Classification\n","        self.blocks.add_module('globavgpool', nn.AvgPool2d(kernel_size=(6, 6)))\n","        self.classifier = nn.Linear(dense_input_features_size, num_classes)\n","\n","    def forward(self, x):\n","        output = self.blocks(x)\n","        # We don't want to flatten batchб so there is a start_dim=1\n","        return self.classifier(torch.flatten(output, start_dim=1))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"kPncPqPp_A6a"},"outputs":[],"source":["# если вы написали модель правильно\n","# эта ячейка должна выполниться\n","num_input_features = 3\n","model = DenseNet(num_input_features, num_classes=10)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["DenseNet(\n","  (blocks): Sequential(\n","    (conv0): Conv2d(3, 24, kernel_size=(7, 7), stride=(1, 1))\n","    (norm0): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu0): ReLU()\n","    (maxpool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (dense1): DenseBlock(\n","      (dense_blocks): Sequential(\n","        (denseblock0): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock1): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock2): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock3): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock4): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock5): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","      )\n","    )\n","    (compress1): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1))\n","    (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu1): ReLU()\n","    (avgpool1): AvgPool2d(kernel_size=(2, 2), stride=1, padding=0)\n","    (dense2): DenseBlock(\n","      (dense_blocks): Sequential(\n","        (denseblock0): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock1): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock2): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock3): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock4): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock5): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock6): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock7): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(28, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock8): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock9): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(36, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock10): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock11): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(44, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","      )\n","    )\n","    (compress2): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))\n","    (norm2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu2): ReLU()\n","    (globavgpool): AvgPool2d(kernel_size=(6, 6), stride=(6, 6), padding=0)\n","  )\n","  (classifier): Linear(in_features=24, out_features=10, bias=True)\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.1208, 0.0835, 0.1385, 0.2480, 0.1324, 0.2753, 0.0078, 0.0163, 0.4208,\n","         0.0054]], grad_fn=<AddmmBackward0>)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Если сделать картинк услишком большой, то она не свернется в 32x1x1 в конце\n","sample_tensor = torch.randn(1, num_input_features, 32, 32)\n","model(sample_tensor)"]},{"cell_type":"markdown","metadata":{"id":"iOTbIAOwHakP"},"source":["### Как проводить эксперименты"]},{"cell_type":"markdown","metadata":{"id":"oXJjLoZXHeHZ"},"source":["\"Neural net training is a leaky abstraction\" - Andrej Karpathy\n","\n","Знания теории, архитектур, оптимизаторов порой недостаточно для получения хорошей модели - значит, пришла пора подбора гиперпараметров.  \n","В таких случаях может помочь не *model-centric*, а *data-centric* подход: переразметить данные, поменять аугментации, докинуть новые.\n","\n","**Но во всех этих случаях правильно организовать эксперименты**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YByhO57qIh34"},"source":["**Перед началом:**\n","Убедитесь, что у вас есть хороший и адекватный бейзлайн\n","1. Сначала вместо самописных моделей берите архитектуры из известных репозиториев (torchvision, timm, mmdetection, huggingface etc)\n","2. Эти архитектуры должны быть стандартными для вашей задачи. То есть, для задач компьютерного зрения (классификации, детекции, сегментации) - ResNet, для обработки языков - трансформер.\n","3. Не придумывайте сложные пайплайны обучения - Adam + LR без расписания, предобработка входа - такая же как у предобученной модели\n","4. Первые пробные запуски делайте на подвыборках, тестовых датасетах\n"]},{"cell_type":"markdown","metadata":{"id":"tdRq8GwXKLJU"},"source":["**Снизьте число факторов влияния**:\n","1. Баги могут быть в разных частях: в модели, обучении, загрузке данных, проверке качества. Сначала избавьтесь от эффекта случайности и зафиксируйте seed и попробуйте поставить determenistic поведение\n","2. Визуализируйте *все*: метрики, лоссы, градиенты, примеры работы модели, работу аугментаций\n","3. Пишите unit-тесты. Даже небольшие!\n","4. Сохраняйте чекпоинты. Не только best и last. Полезно брать чекпоинты каждые несколько итераций\n","5. При проведении экспериментов вносите **только одно изменение за раз**.\n"]},{"cell_type":"markdown","metadata":{"id":"__1FXprlL0Ne"},"source":["Более полные и точные рецепты можете прочитать [здесь](https://github.com/puhsu/dl-hse/blob/main/week01-intro/lecture-best-practices.pdf)"]},{"cell_type":"markdown","metadata":{"id":"hLD8YPRH5UOS"},"source":["## Обучение и подбор гиперпараметров"]},{"cell_type":"markdown","metadata":{"id":"4AKF23u86UL3"},"source":["\n","\n","> **Гиперпараметры** отличаются от **параметров** следующим:\n","> * Они не могут обучаться с помощью градиентного спуска: например, выбор оптимизатора, learning rate, аугментаций, сам подбор архитектуры и пайплайна можно считать за гиперпараметры. Иначе говоря, все, что мы не можем включить в нашу end-to-end модель, чтобы обучать это через функцию потерь, является гиперпараметром\n","> * Часто гиперпараметры подбирают на валидационной выборке (точнее, если их подбор уж очень важен, для них создают специальную выборку, которая называется *dev выборка*): например, weight decay\n","> * Гиперпараметры бывают дискретными и без отношения порядка: например, выбор расписания для lr, а также выбор момента шага расписания - можно делать шаг на каждом шаге оптимизатора, можно на каждой эпохе\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZxXnWrbC74SC"},"source":["**Вопрос**: почему weight decay лучше подбирать на валидационной выборке? Можно ли его подбирать на обучающей? Если можно, то как?\n","\n","**Ответ** weight decay (L2 регуляризация) подбирается на валидационной выборке потому, что переобучение легче всего определяяется именно там. Переобучение можно попробовать определить по тренировочной выборке, если учитывать не текущее значение функции потерь а ее динамику за несколько эпох. В этом случае можно накладывать штрафы на веса модели."]},{"cell_type":"markdown","metadata":{"id":"plUS_5-X5YAh"},"source":["Чтобы не писать собственный train loop, мы будем использовать **Pytorch Lightning**.   \n","\n","Это не самый лучший фреймворк для обучения - в нем множество багов, которые особенно любят проявлять себя в сложных моделях, обучаемых в low-precision с параллелизмом.  \n","\n","Но большая часть популярных фреймворков организована именно так - train loop скрыт от глаз пользователя. Поэтому полезно посмотреть это на таком простом примере, как Pytorch Lightning"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"PwIM9K5wBF5B"},"outputs":[],"source":["! pip install pytorch_lightning >> None"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import pytorch_lightning as pl\n","from pytorch_lightning import loggers as pl_loggers"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Seed set to 42\n"]},{"data":{"text/plain":["42"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["torch.random.manual_seed(42)\n","pl.seed_everything(42)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Woi5D02x5Xac"},"outputs":[],"source":["# self.log() logs into Tenserboard\n","\n","class ConvModelPL(pl.LightningModule):\n","  def __init__(self, model, loss, lr, weight_decay):\n","    super().__init__()\n","    self.model = model\n","    self.loss = loss\n","    self.lr = lr\n","    self.weight_decay = weight_decay\n","\n","    self.validation_step_outputs = []\n","\n","  def training_step(self, batch, batch_idx):\n","    x, y = batch\n","    pred = self.model(x)\n","    loss = self.loss(pred, y)\n","    self.log(\"train_loss\", loss)\n","    return loss\n","\n","  def validation_step(self, batch, batch_idx):\n","    x, y = batch\n","    pred = self.model(x)\n","    loss = self.loss(pred, y)\n","    # Calculating accuracy\n","    pred = torch.argmax(pred, dim=1)\n","    train_acc = torch.sum(pred == y)\n","    metric = train_acc / float(len(y))\n","    self.validation_step_outputs.append(metric)\n","    self.log(\"val_loss\", loss)\n","    return metric\n","\n","  def on_validation_epoch_end(self):\n","    total_metric = torch.stack(self.validation_step_outputs).mean()\n","    self.log(\"val_epoch_acc\", total_metric)\n","\n","\n","  def configure_optimizers(self):\n","      optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n","      scheduler = {\n","            'scheduler': torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, total_iters=10),\n","            'interval': 'step',\n","            'frequency': 1,\n","        }\n","      return [optimizer], [scheduler]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"lNRIAatVCug5"},"outputs":[],"source":["model = DenseNet(num_input_features=3, num_classes=10)\n","model_pl = ConvModelPL(model, loss=nn.CrossEntropyLoss(), lr=1e-4, weight_decay=1e-6)"]},{"cell_type":"markdown","metadata":{"id":"y3CdP4tPC08O"},"source":["Дальше создадим датасеты и даталоадеры.\n","Опять же, вам нужно написать более точную конфигурацию: подобрать аугментации для baseline, batch_size, параметры даталоадера"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ltfuDf8gCvL3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["import torchvision\n","from torchvision import transforms\n","\n","batch_size = 32\n","workers = 1\n","\n","# вспомните, что вы можете использовать не только аугментации из torchvision\n","# но и из albumentations и, если уж совсем хотите заморочиться, nvidia dali\n","# прочитайте вот эту статью, возможно, аугментации из нее могут вам помочь\n","# https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf\n","transform_to_tensor = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","test_transform = transform_to_tensor\n","train_transform = transforms.Compose([transform_to_tensor, \n","                                      transforms.RandomHorizontalFlip(p=0.1)])\n","\n","train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=train_transform)\n","test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=test_transform)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["\n","# есть несколько способов ускорения даталоадера\n","\n","# главный из них - ставить pin_memory, когда вы работаете с gpu\n","# дело в том, что программы на host'е работает с логической памятью, которая называется paged memory,\n","# она связана с физической с помощью таблицы - page table\n","# когда физической памяти не хватает, страницы из page memory выгружаются (page out) на другие носители (например, на ssd)\n","# получается, paged memory нестабильна и может быть разбросана по разным физическим устройствам\n","# чтобы скопировать данные на device, сначала данные из paged memory копируются в page-locked memory,\n","# и только затем на device\n","# можно избежать такого: сразу выделять память в page-locked memory\n","# именно это и делает аргумент pin_memory=True\n","# https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n","\n","# также если у вашего трейнлупа нет точек синхронизации (напимер, print, logging, перемещение на cpu)\n","# то можно ставить data = data.to('cuda:0', non_blocking=True) при отправлении данных\n","# https://discuss.pytorch.org/t/should-we-set-non-blocking-to-true/38234/3\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n","                                          shuffle=True, num_workers=workers)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n","                                         shuffle=False, num_workers=workers)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"name":"stdout","output_type":"stream","text":["input shape torch.Size([3, 32, 32])\n","label example: 6\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 800x800 with 9 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","figure = plt.figure(figsize=(8, 8))\n","cols, rows = 3, 3\n","for i in range(1, cols * rows + 1):\n","    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n","    img, label = train_set[sample_idx]\n","    img = img.permute(1, 2, 0)\n","    figure.add_subplot(rows, cols, i)\n","    plt.title(label)\n","    plt.axis(\"off\")\n","    plt.imshow(img.squeeze(), cmap=\"gray\")\n","print(f\"input shape {train_set[0][0].shape}\")\n","print(f\"label example: {train_set[0][1]}\")\n","plt.show()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["number of labels: 10\n"]}],"source":["labels = set()\n","for img, label in train_set:\n","    labels.add(label)\n","number_of_labels = len(labels)\n","print(f\"number of labels: {number_of_labels}\")"]},{"cell_type":"markdown","metadata":{"id":"twX_vCwuNAKn"},"source":["**Вопрос:** на что влияет аргумент num_workers в DataLoader? Каким его можно ставить?\n","\n","**Ответ** num_workers - количество потоков, которые загружают батчи в память. Это ускоряет обучение сети потому, что перенос данных - значительная часть времени обучения. Его можно выставить каким угодно, но при значении боьше чем количество хартов компьютера они не будут радотать по-настоящему параллельно. Если память компьютера являетсся бутылочным горлом, то повыышение num_workers не ускорит программу."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"IdHuE97-DHSj"},"outputs":[],"source":["# а теперь можно запускать обучение и смотреть метрики и графики\n","# просмотр графиков вы должны вставить сами\n","\n","# чтобы запустить на маке\n","# напишите device='mps'\n","device = 'cuda'\n","\n","# здесь только пробный запуск\n","# очевидно, вы должны изменить параметры limit_train_batches и max_epochs\n","# когда будете делать более сложные эксперименты\n","#trainer = pl.Trainer(limit_train_batches=100, max_epochs=20)\n","#trainer.fit(model_pl, train_loader, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"aEUZsAL3GsML"},"source":["Попробуйте получить хороший бейзлайн по рекомендациям выше.  \n","После обучения модели подберите гиперпараметры и, если вы этого захотите, немного измените архитектуру модели так, чтобы добиться более высокой метрики."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"QltavClgHIVx"},"outputs":[],"source":["# baseline model\n","model = DenseNet(num_input_features=3, num_classes=number_of_labels)\n","model_pl = ConvModelPL(model, loss=nn.CrossEntropyLoss(), lr=1e-4, weight_decay=1e-6)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n"]}],"source":["tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"./log/densenet-baseline\")\n","trainer = pl.Trainer(max_epochs=40, logger=tb_logger)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-13 00:33:07.169703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-13 00:33:08.302720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 22.8 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","22.8 K    Trainable params\n","0         Non-trainable params\n","22.8 K    Total params\n","0.091     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3d6ebe61894404a8db391c5d1b3d3ca","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/azor/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n","/home/azor/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10b96a4bd2bb4665b13b528b588734b6","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","Detected KeyboardInterrupt, attempting graceful shutdown ...\n"]},{"ename":"NameError","evalue":"name 'exit' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39mckpt_path)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_stage()\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance()\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_loop\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(data_fetcher)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_optimization\u001b[38;5;241m.\u001b[39mrun(trainer\u001b[38;5;241m.\u001b[39moptimizers[\u001b[38;5;241m0\u001b[39m], batch_idx, kwargs)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step(batch_idx, closure)\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\n\u001b[1;32m    269\u001b[0m     trainer,\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_step\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    271\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mcurrent_epoch,\n\u001b[1;32m    272\u001b[0m     batch_idx,\n\u001b[1;32m    273\u001b[0m     optimizer,\n\u001b[1;32m    274\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    275\u001b[0m )\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1306\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1306\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep(closure\u001b[38;5;241m=\u001b[39moptimizer_closure)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39moptimizer_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39moptimizer_step(optimizer, model\u001b[38;5;241m=\u001b[39mmodel, closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py:122\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mstep(closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:137\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(opt, opt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/optim/adamw.py:197\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 197\u001b[0m         loss \u001b[38;5;241m=\u001b[39m closure()\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py:108\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m closure()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosure(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:138\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn(step_output\u001b[38;5;241m.\u001b[39mclosure_loss)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:239\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward_fn\u001b[39m(loss: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_strategy_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, optimizer)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:212\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mbackward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, optimizer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py:72\u001b[0m, in \u001b[0;36mPrecision.backward\u001b[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m model\u001b[38;5;241m.\u001b[39mbackward(tensor, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1101\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model_pl, train_loader, test_loader)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    540\u001b[0m )\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     exit(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n","\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"]}],"source":["trainer.fit(model_pl, train_loader, test_loader)"]},{"cell_type":"markdown","metadata":{},"source":["За 40 эпох нейросеть не дообучилась. Конечное значение accuracy на валидационной выборке:\n","`0.54`\n","\n","Проведем подбор гиперпараметров на меньшем числе эпох:"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import ParameterGrid\n","\n","param_grid = {\n","    'k': [2, 16],\n","    'lr': [1e-3, 1e-5],\n","    'weight_decay': [1e-5, 1e-7]\n","}\n","grid = ParameterGrid(param_grid)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9c9a0dec2384abf85f57c80919e44e0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/8 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_4147/811893383.py:5: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n","  params = grid[params_id]\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 13.4 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","13.4 K    Trainable params\n","0         Non-trainable params\n","13.4 K    Total params\n","0.053     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13949662b5ab4460b0b337c72b23950c","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/azor/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n","/home/azor/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"891c2cba583e45918846202c98fed22b","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18a22162c631463d8ff3cf586dc64b85","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e19d7a771491489fa6add805eb4e437f","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9332da858ba24dc5899aecfe3bd60f88","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b13d29072bdc4120a36615912264bbf5","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f60e5492a5754f5f992732d3df2bffea","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e0f806f1f614917b4ab9ce5ebf8431f","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"80f6e0f892784182bc132010005b2c04","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e887ad097e494678a4b64c1b5ffa9754","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47817eb08615433aa5c9282f9287b018","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7297ed73ba974207bf2a99b07ae893e7","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6a1689d56dd4a519d0fb9c2e9c49b79","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da098997cae54d73adbbd10813f770ec","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 13.4 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","13.4 K    Trainable params\n","0         Non-trainable params\n","13.4 K    Total params\n","0.053     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7cba78c79ae4f76ab29086db4453d41","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"866f576421d94d9e901552a3d1585f6c","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f68e416d2cf41688eb03e29f9f4ffc4","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d1925e0c95943959e79bd38a0b470d3","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23bfeb629ff747928c904ea2333b41c8","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b1d3fdc3921485cbc43b9e6637ff0ee","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7ab84192bfa45dd934780a20614178e","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f592f1801c643a59f6cadce8c448ee3","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"413298ef546a4aec82bbce245b6ec7b5","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72c0c00ed9e64fa3adc41f7a715219f8","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e351958d52dd4578945303242b9a69e9","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25bc8d0500854289a180fbe897f4c364","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0dc2548f2ea445ab4f55f6d9f9e9728","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c14b41bd928744f082fa3574c0c991b8","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 13.4 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","13.4 K    Trainable params\n","0         Non-trainable params\n","13.4 K    Total params\n","0.053     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a7dc10f93a4426892d61717f32e18b2","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6348b2faaa64461da786c7e441c238f8","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a38ae72b3757453bb0b0d47725f44d44","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f74239c2a9b140a6b1c501d2e94e3b04","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"362977d8b6784a2da0c5f91bb0686d15","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92899ee15780404ca45a46d15a2d3572","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da135303f75c44259425c5a22bcae7ce","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"292ee1fa185e42f28c8321bd10afc4a8","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"629ff6018e234086a93b745457635459","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e80959517724ac2a036d22690b13d7c","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"228ba59a1d744bec8830cb5c0b0ba68b","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3bb8390fc3f4f29b09833e3626e3ff8","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d2eaa566aa04044aae40b124cd8e9f2","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e07883d2baf4ac6b56559260c337466","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 13.4 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","13.4 K    Trainable params\n","0         Non-trainable params\n","13.4 K    Total params\n","0.053     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29fa19e4d10744bb9a639e4b2dd992e5","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55884a5c4b274679a87174205a9c1407","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3f56662a7d04678ae75d2d30e7af61f","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e27366a11f54d0eb432c324e66a26b9","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d43c491df1af442da78e708c2bd8b4a4","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ee0c6eb69d046e284253b45e13331d3","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ec51b28c4e34374ab2f8fcb2c715a6d","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82bcd55a2bb34f8c895df80ee43498ec","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6d1f16a7e924eb59a6dd66e773b9d34","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"992065aa35c840be937bf9db62df2b0a","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a814e29edaf84c50a8d4423c4723e046","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ee2436609854c8b8e9cdca6399abc84","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0b6c156595b432ba647eaf60edd1ae9","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4daf020b564549708ee14f378e584747","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 94.7 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","94.7 K    Trainable params\n","0         Non-trainable params\n","94.7 K    Total params\n","0.379     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9453017144e148efa3fa081fb50146cf","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97f318024b764bbcb97d983a578fafe5","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd69d3593a8944378e26044e7ba8fb7a","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e4b08b1fa6a457fa2f76d25ea3c4dc0","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd56485a58fd463c800a5a4041413fc2","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d339b87b126480885e070e9d6b5cdec","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af8101e851994356a50691bba0f4e47b","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbf995ddcf5d4478b940a77b50cd6e79","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e940c2ae7ab4381b42d5998cdb58ae1","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df49992eeaed4976b7ec8365ff77c421","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffd0d52b959642ccb3d552b827c8d050","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8e1dd4f04af4f67ae10aea6fe1a1536","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b492320c1784329985406ceab93de7a","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0967d4fbeaa547d3bac2b8587b76ee82","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 94.7 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","94.7 K    Trainable params\n","0         Non-trainable params\n","94.7 K    Total params\n","0.379     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2ceef785efa4527b6cf2bf53cbe540c","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e724163d10ee4cc1aff06262a2b54eac","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a33d400e499c4c8388206963881fd1bb","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"326dc990738443d99ea17de1e8ee4c57","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af8c6124dda842e48e1760b16b71588a","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"821f4bb4190e42f8832cb42131f6951f","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf373a91fabc46048ef0a5e3a2cab92f","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d53ed7108c0410db96df018f8c398d2","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"074581886fd04be292ac6c312618f35a","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5546e016804d4081ab62a135748cfeec","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f46570c21e0d463aacf4794ec625b47b","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2fc2fc882d19435890670e8a22bcac99","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"615ec0708a47405c8d062422c00410ac","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83f6017fbb8143d1be18e3f921dc571e","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 94.7 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","94.7 K    Trainable params\n","0         Non-trainable params\n","94.7 K    Total params\n","0.379     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c33f46091f2f471e9595f7f02520d96f","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81a30bf2e22d48b3ba7809687e146836","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"040dce58857740838b98df848755987d","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04330eace1434571a5a618140a559357","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b42ec2a39e07481eb39ddcfaefe09699","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc4f50217d924255a4395b5cea9518dc","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5bbb4ce61f534854819d35ed3049d163","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e1b6e2f72b04cd08b757e16837e13d1","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab39e8b2ce914efa8e308995e9368f38","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18e23e295607434098d92aeaf5ac6703","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"85b5e4153e93410984532eabafbfbcf2","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28ee089efe51415c815b9f54272b52d9","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35f9b9a7bf83470e868a5aff35fdfeff","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47b30668373a4522a957d19f23bacd2f","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 94.7 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","94.7 K    Trainable params\n","0         Non-trainable params\n","94.7 K    Total params\n","0.379     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8c2706f17a4494aa46dd095efff0df7","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"394f69b175c44b258a746e3543fcd492","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcb88999d6814ff49e09f25c5dd830fa","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f2e3543d8204119bda4e7e779e4d895","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf60d1648cb14965a163d5c21e069fd5","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c58e0e2a83cf49a39f12731b2e437620","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bd6945e140c48f79b9773dda1d3e8a8","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d7bfe5c5bbe48209ab7b3663216ea15","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"564c61437a914cc991fef65bf021a589","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ed870340d02441bbc3d6c7fbfa0e700","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94e97391be59477eacb2cbd6c6fba7d3","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75b2bbf8ad6c43ae824249de099a6afa","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2e911f08caf4d56883f23ead8a8a80f","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"798fff3fa50946e7b0d127d180d9a249","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n"]}],"source":["from tqdm.auto import tqdm\n","\n","results = []\n","for params_id in tqdm(range(len(grid))):\n","    params = grid[params_id]\n","    k = params['k']\n","    lr = params['lr']\n","    weight_decay = params['weight_decay']\n","\n","    model = DenseNet(num_input_features=3, num_classes=number_of_labels, \n","                    k=k)\n","    model_pl = ConvModelPL(model, loss=nn.CrossEntropyLoss(), lr=lr, weight_decay=weight_decay)\n","    tb_logger = pl_loggers.TensorBoardLogger(save_dir=f\"./log/k-{k}-lr-{lr}-dec-{weight_decay}\")\n","    trainer = pl.Trainer(max_epochs=12, logger=tb_logger)   \n","\n","    trainer.fit(model_pl, train_loader, test_loader)\n","    results.append((params, trainer.callback_metrics['val_loss']))"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters: {'weight_decay': 1e-05, 'lr': 0.001, 'k': 16}, Validation Loss: 0.7935603260993958\n"]}],"source":["best_params = sorted(results, key=lambda x: x[1])[0]\n","print(f'Best parameters: {best_params[0]}, Validation Loss: {best_params[1]}')"]},{"cell_type":"markdown","metadata":{},"source":["Из шрафиков видно, что наибольшее влияние на результат оказывет параметр k. Полберем только этот параметр."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["param_grid = {\n","    'k': [16, 24, 32]\n","}\n","grid = ParameterGrid(param_grid)"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9bbcf0f0f4c470aa97f1a0bec683009","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_4147/157379545.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n","  params = grid[params_id]\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 94.7 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","94.7 K    Trainable params\n","0         Non-trainable params\n","94.7 K    Total params\n","0.379     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f5f629bc2ee48d68768912dfa42ec10","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/azor/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n","/home/azor/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"986bbe112dee45c7bf9df4f9b32d0968","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c2c873de88e4effba2a82e232f8eb88","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14043f61bcaa4e43899aba8e0e4379ef","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a4c51dbb4ee488e93efe8c64f34026e","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e55a941891664a2ab96d12fd40fb5e11","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1107a0ad4a7d424c90a3ff1f58cc47ef","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c18e892fa4684717aab46bbd23a204dc","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c93deb3d053c4defb418db589777a596","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f34bd4f125584d359a25155d01ffba5a","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b05874576b474385967c51bde13ac7e9","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d5efe1ad5b74a45bf478ad0efd5c076","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"800176e91e39497fb04eddaedb0cfa90","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78ac7237746448e4a56ac0d1556f57bf","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 157 K  | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","157 K     Trainable params\n","0         Non-trainable params\n","157 K     Total params\n","0.628     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73e8974b2cf6406a8154622cd3296095","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2cb67b0e48e1431cb998a3d161bd9eaf","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef159ec2badd4804908e1d7fc61b7a49","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b22008b91e634995bee57e41b214b16b","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce29c1ae891f4b3e8eea978ea6ba5fe9","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bdf8978ebc641bb805d0f93e173229e","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c9e93a391cd4203aa30f28af0496d7a","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2617ef300354e2babb2e72f954ed854","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b62dfb5268304980970e5d1439343499","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c78806ad0fa443eb69bb6af8c0e2e8e","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c88ea8a32f2b4b27b295693827f7ba41","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fa398f5f3b94350a8d9b3114091acb8","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"540e2f3d9e034042a3d5f3b3e0b3278f","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0961f22be92049228ae59e18a26a2faa","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 230 K  | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","230 K     Trainable params\n","0         Non-trainable params\n","230 K     Total params\n","0.924     Total estimated model params size (MB)\n","182       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21ab7ae4adbd45e5956792e3724c4ca5","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd06e3f6fc6c46af99d1cfd8aa199daf","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17295ca56de2426f95ce114c0b6d0fa5","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6051a15b219d448eb080a34f3c253268","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10ef453f486849cca28734c3f9a6404d","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc11c31a074747989d6769e831fb7f83","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"124e15b4c87a47149c9f9c5bef6fd1f7","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36120a7e63b940e2b11577e6364953c7","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6570f3c9522f495c9458c4eaf21ba2a1","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f97ac4880bb84075b587451144e86f47","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f36d3729367d4fc2bfd7cc9fad17c106","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5809d71c759a44b2b0595da12bfe9700","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c230838d9ddc4572af60fc83774e170f","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25d8fd8e12d84fe7bdd5db4ca949fd74","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`Trainer.fit` stopped: `max_epochs=12` reached.\n"]}],"source":["results = []\n","for params_id in tqdm(range(len(grid))):\n","    params = grid[params_id]\n","    k = params['k']\n","\n","    model = DenseNet(num_input_features=3, num_classes=number_of_labels, \n","                    k=k)\n","    model_pl = ConvModelPL(model, loss=nn.CrossEntropyLoss(), lr=0.001, weight_decay=1e-05)\n","    tb_logger = pl_loggers.TensorBoardLogger(save_dir=f\"./log/only-k-{k}\")\n","    trainer = pl.Trainer(max_epochs=12, logger=tb_logger)   \n","\n","    trainer.fit(model_pl, train_loader, test_loader)\n","    results.append((params, trainer.callback_metrics['val_loss']))"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters: {'k': 32}, Validation Loss: 0.7367120981216431\n"]}],"source":["best_params = sorted(results, key=lambda x: x[1])[0]\n","print(f'Best parameters: {best_params[0]}, Validation Loss: {best_params[1]}')"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["# You might run this in terminal and visit the site http://127.0.0.1:6006/#timeseries\n","#%tensorboard --bind_all --logdir lightning_logs/"]},{"cell_type":"markdown","metadata":{"id":"b2IiIqFpMf_W"},"source":["## Transfer Learning и Fine-Tune"]},{"cell_type":"markdown","metadata":{"id":"yiOycRqMEk3x"},"source":["Для многих прикладных задач не существует больших датасетов с хорошей разметкой. Поэтому распространенным приемом является тренировка на похожем, но большом датасете и доучивание сети на целевом.\n","\n","Такой прием называют **Transfer Learning** или **Fine-tuning**.\n","\n","В сверточных сетях для классификации выделяют две части:\n","1. Тело сети (backbone, feature extractor) - это набор сверток и пулингов (convolutions and poolings)\n","2. Голову (head) - это MLP (набор полносвязных слоев) после которых делается softmax и получаются вероятности разных классов.\n","\n","Вычислительно простым вариантом finetuning является переучивание головы сети. Также можно фиксировать какие-то первый слои"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"X-dQYLDsDh4o"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/azor/.conda/envs/ML/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/azor/.conda/envs/ML/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["from torchvision import models\n","\n","model = models.resnet18(pretrained=True)\n","\n","# кроме torchvision очень известен репозиторий pytorch-image-models\n","# !pip install timm >> None\n","# import timm\n","# model = timm.create_model('resnet18', pretrained=True)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"ZWB9hYj6GtCt"},"outputs":[],"source":["# заморозим слои\n","for param in model.parameters():\n","  param.requires_grad = False"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"k4f6-sQ9GryD"},"outputs":[],"source":["# 10 - число наших классов\n","model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n","# теперь requires_grad=True только у model.fc"]},{"cell_type":"markdown","metadata":{"id":"O9FVdZ_uA1gV"},"source":["**Вопрос:** почему нужно использовать lr warmup для fine-tune предобученной модели?"]},{"cell_type":"markdown","metadata":{},"source":["### Дообучение головы\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["model_pl = ConvModelPL(model, loss=nn.CrossEntropyLoss(), lr=1e-4, weight_decay=1e-6)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n"]}],"source":["tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"./log/resnet-only-head\")\n","trainer = pl.Trainer(max_epochs=15, logger=tb_logger)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | ResNet           | 11.2 M | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","5.1 K     Trainable params\n","11.2 M    Non-trainable params\n","11.2 M    Total params\n","44.727    Total estimated model params size (MB)\n","69        Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ceedecbf09754252976e90b368ec7239","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f75d9d27ac7f498cbb1fb0705a5e75c3","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8bc252540cd0449fbb587fa7f057dcfc","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b333cbdcaca457fa8907c6d43ca78b9","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4f4f7a4782242d3bc3053f881e038fe","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"823c282724ee4582997588e366aaedbf","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a7d7d837bb848aebd367c9fca1c6500","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"493d65c030e34e53afded5d62ea7b627","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4e0fee56b6a4d69bfa9440fbd1da074","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["trainer.fit(model_pl, train_loader, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gB-fxutNWqf"},"outputs":[],"source":["# осталось лишь заметить, что пайплайн обучения уже написан - он хранится в model_pl\n","# вам осталось его только запустить\n","# проведите несколько экспериментов:\n","# 1. Дообучите только голову\n","# 2. Дообучите всю модель\n","# 3. Поменяйте пайплайн аугментаций с вашего на тот, что использовался для предобученной модели\n","# 4. Откусите голову и обучите SVM на данных, полученных из feature extractor'a. Попробуйте с аугментациями и без них.\n","# Такой подход сработает, ведь feature extractor можно рассматривать как функцию, которая отображает данные из одного пространства в другое,\n","# где эти данные линейно разделимы\n","# сравните результаты между полной сетью, сетью с дообучением головы и сетью с SVM. Где результаты лучше и почему?"]},{"cell_type":"markdown","metadata":{"id":"2W2AIPlp93_b"},"source":["**Вопросы:**  \n","1. Какая разница по качеству между обучением всей модели и только головы? Как вы думаете, какие преимущества у каждого из этих подходов?\n","2. Какие зависимости вы обнаружили между различными значениями гиперпараметров и процессом обучения модели?\n","3. Прочитайте раздел Loss Functions [отсюда](https://cs231n.github.io/neural-networks-2/) (можете и другие разделы). Как вы думаете, почему нельзя обучать классификатор на MSE?"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPaVIzsVCrg+zgqrZqYExN+","provenance":[{"file_id":"1-QsqbFnU1KhIiKO6ERjanY825JUSZwiK","timestamp":1727991278398}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
