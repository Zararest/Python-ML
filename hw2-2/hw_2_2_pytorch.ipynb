{"cells":[{"cell_type":"markdown","metadata":{"id":"cX_WL9cbbJas"},"source":["# Домашнее задание 2.2. Обучение сетей на Pytorch"]},{"cell_type":"markdown","metadata":{"id":"JMCFXAYFNpFx"},"source":["В этом задании нужно:\n","1. Написать свою сеть на Pytorch по варианту\n","2. Обучить ее и сравнить результаты с дообученной сетью из зоопарка моделей\n","3. Поставить ряд экспериментов, показывающих насколько гиперпараметры обучения влияют на результат"]},{"cell_type":"markdown","metadata":{"id":"qHaLl3E5cwy_"},"source":["**Варианты архитектуры сверточной сети:**\n","Вариант на ваш выбор - напишите его в чат. Не более двух человек на один вариант\n","1. Resnet v2\n","2. Inception Google LeNet\n","3. MobileNetv2 (Коростинский, Глаз)\n","4. SE Net\n","5. DenseNet\n","6. Conv Mixer\n","7. RepVGG"]},{"cell_type":"markdown","metadata":{"id":"3bWCyebM5HCh"},"source":["## Имплементация сети на Pytorch"]},{"cell_type":"markdown","metadata":{"id":"8_rU_f5-5L3D"},"source":["Здесь вы должны написать модель, выданную вам по варианту.\n","Для этого нужно:\n","1. Не забывать про использоватие блоков nn.Module, nn.Sequential, nn.ModuleList\n","2. Использовать материалы из предыдущих семинаров\n","\n","В качестве примера ниже реализован макет для модели, состоящей из блоков."]},{"cell_type":"markdown","metadata":{},"source":["## Архитектура Dense слоя сети DenseNet. \n","В нем все  признаки с каждого слоя конкатенируются и передаются во все следующие.\n","\n","![image.png](DenseNet.jpg)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"RjMhL5bcagsR"},"outputs":[],"source":["import torch\n","from torch import nn\n","from collections import OrderedDict"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Input: (N, C, H, W) tensor\n","# Layer: combination of (BN2D + ReLu + Conv2D1x1 + BN2D + ReLu + Conv2D3x3) layers\n","# Arch: each layer l accepts k_0 + k * (l - 1) feature maps\n","# There is a bottleneck in each layer: each Conv2D1x1 reduces number of chanels to bn_size\n","# This is needed because first convolution might have high num_input_features \n","#   because of data from the previous layers:\n","# Example of how C changes throughout the network:\n","# \tlayer 1: (input) -> (bn_size * k) -> (k) \n","#\t\t \t\t|\t\t\t\t\t\t |\n","# \t\t \t\t|\t\t\t\t\t\t V\n","# \tlayer 2: \t--------------> (input + k) -> (bn_size * k) -> (k)\n","#   layer 3:    (input + k + k) -> (bn_size * k) -> (k)\n","\n","class DenseLayer(nn.Module):\n","\tdef __init__(self, num_input_features : int, bottle_neck_dim : int, num_out_features : int) -> None:\n","\t\tsuper().__init__()\n","\t\tself.bottle_neck = nn.Sequential(OrderedDict([ \n","\t\t\t('norm1', nn.BatchNorm2d(num_input_features)),\n","\t\t\t('relu1', nn.ReLU()),\n","\t\t\t('conv1', nn.Conv2d(num_input_features, bottle_neck_dim,\n","\t\t\t\t\t\t\tkernel_size=1, stride=1, bias=False))]))\n","\t\t\n","\t\tself.conv = nn.Sequential(OrderedDict([\n","\t\t\t('norm2', nn.BatchNorm2d(bottle_neck_dim)),\n","\t\t\t('relu2', nn.ReLU()),\n","\t\t\t# Pudding is needed in order to match concatinating outputs\n","\t\t\t('conv2', nn.Conv2d(bottle_neck_dim, num_out_features,\n","\t\t\t\t\t\t\tkernel_size=3, stride=1, padding=1, bias=False)),\n","\t\t]))\n","\t\t\n","\tdef forward(self, input : torch.tensor) -> torch.tensor:\n","\t\tbottle_neck_output = self.bottle_neck(input)\n","\t\treturn self.conv(bottle_neck_output)\n","\n","class DenseBlock(nn.Module):\n","\tdef __init__(self, num_input_features : int, num_layers : int, k : int, bn_size : int) -> None:\n","\t\tsuper().__init__()\n","\t\tself.dense_blocks = nn.Sequential()\n","\t\tcur_num_input_features = num_input_features\n","\t\tfor l in range(num_layers):\n","\t\t\tlayer = DenseLayer(num_input_features=cur_num_input_features, \n","\t\t\t\t\t\t\t   bottle_neck_dim=bn_size, \n","\t\t\t\t\t\t\t   num_out_features=k)\n","\t\t\tself.dense_blocks.add_module(f\"denseblock{l}\", layer)\n","\t\t\tcur_num_input_features = (l + 1) * k\n","\t\t\n","\tdef forward(self, input : torch.tensor) -> torch.tensor:\n","\t\tprev_features = None\n","\t\tfor layer in self.dense_blocks:\n","\t\t\toutput = layer(input)\n","\t\t\t# dim=1 is a dimension of blocks\n","\t\t\tif prev_features is not None:\n","\t\t\t\tinput = torch.cat((prev_features, output), dim=1)\n","\t\t\telse:\n","\t\t\t\tinput = output\n","\t\t\tprev_features = input\n","\t\treturn input"]},{"cell_type":"markdown","metadata":{},"source":["Архитектура была взята из оригинальной статьи (после кажой свертки стоит BatchNorm и ReLu):\n","- 7 × 7 conv, stride 2\n","- 3 × 3 max pool, stride 2\n","- dense layer x 6\n","- 1 × 1 conv\n","- 2 × 2 average pool, stride 2\n","- dense layer x 12\n","- 1 × 1 conv\n","- 2 × 2 average pool, stride 2\n","- dense layer x 24\n","- 1 × 1 conv\n","- 2 × 2 average pool, stride 2\n","- dense layer x 16\n","- 1 × 1 conv\n","- 7 × 7 global average pool\n","- fully-connected, softmax"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Tp_igxkE6BnN"},"outputs":[],"source":["class DenseNet(nn.Module):\n","    def __init__(self, num_input_features : int, num_classes : int,\n","                 init_conv_num_features=24, k=4, bn_size=16, compression=0.5) -> None:\n","        super().__init__()\n","\n","        self.blocks = nn.Sequential(OrderedDict([\n","          ('conv0', nn.Conv2d(num_input_features, init_conv_num_features, \n","                              kernel_size=(7, 7), stride=2)),\n","          ('norm0', nn.BatchNorm2d(init_conv_num_features)),\n","          ('relu0', nn.ReLU()),\n","          ('maxpool', nn.MaxPool2d(kernel_size=(3, 3), stride=2))\n","\t\t]))\n","\n","        dense_sizes = [6, 12, 24, 16]\n","        dense_input_features_size = init_conv_num_features\n","        block_num = 1\n","        for dense_block_size in dense_sizes:\n","            self.blocks.add_module(f\"dense{block_num}\", \n","                DenseBlock(num_input_features=dense_input_features_size, \n","                            num_layers=dense_block_size, k=k, bn_size=bn_size))\n","            \n","            conv_input_feature_size = k * dense_block_size\n","            conv_output_feature_size = int(conv_input_feature_size * compression)\n","            self.blocks.add_module(f\"compress{block_num}\",\n","\t\t\t\tnn.Conv2d(in_channels=conv_input_feature_size,\n","              \t\t\t  out_channels=conv_output_feature_size,\n","                          kernel_size=(1, 1)))\n","            \n","            self.blocks.add_module(f\"norm{block_num}\", nn.BatchNorm2d(conv_output_feature_size))\n","            self.blocks.add_module(f\"relu{block_num}\", nn.ReLU())\n","            # last pooling is 7x7\n","            if block_num != len(dense_sizes):\n","                self.blocks.add_module(f\"avgpool{block_num}\", nn.AvgPool2d(kernel_size=(2, 2), stride=2))\n","            dense_input_features_size = conv_output_feature_size\n","            block_num += 1\t\t\t\n","\n","        # Classification\n","        self.blocks.add_module('globavgpool', nn.AvgPool2d(kernel_size=(7, 7)))\n","        self.classifier = nn.Linear(dense_input_features_size, num_classes)\n","\n","    def forward(self, x):\n","        output = self.blocks(x)\n","        # We don't want to flatten batch\n","        return self.classifier(torch.flatten(output, start_dim=1))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"kPncPqPp_A6a"},"outputs":[],"source":["# если вы написали модель правильно\n","# эта ячейка должна выполниться\n","num_input_features = 3\n","model = DenseNet(num_input_features, num_classes=3)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["DenseNet(\n","  (blocks): Sequential(\n","    (conv0): Conv2d(3, 24, kernel_size=(7, 7), stride=(2, 2))\n","    (norm0): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu0): ReLU()\n","    (maxpool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (dense1): DenseBlock(\n","      (dense_blocks): Sequential(\n","        (denseblock0): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock1): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock2): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock3): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock4): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock5): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","      )\n","    )\n","    (compress1): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1))\n","    (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu1): ReLU()\n","    (avgpool1): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n","    (dense2): DenseBlock(\n","      (dense_blocks): Sequential(\n","        (denseblock0): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock1): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock2): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock3): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock4): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock5): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock6): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock7): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(28, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock8): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock9): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(36, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock10): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock11): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(44, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","      )\n","    )\n","    (compress2): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))\n","    (norm2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu2): ReLU()\n","    (avgpool2): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n","    (dense3): DenseBlock(\n","      (dense_blocks): Sequential(\n","        (denseblock0): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock1): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock2): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock3): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock4): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock5): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock6): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock7): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(28, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock8): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock9): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(36, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock10): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock11): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(44, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock12): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock13): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(52, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock14): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(56, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock15): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(60, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock16): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock17): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(68, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock18): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(72, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock19): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(76, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock20): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(80, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock21): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(84, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock22): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(88, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock23): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(92, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","      )\n","    )\n","    (compress3): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n","    (norm3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu3): ReLU()\n","    (avgpool3): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n","    (dense4): DenseBlock(\n","      (dense_blocks): Sequential(\n","        (denseblock0): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock1): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock2): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock3): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock4): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock5): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock6): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock7): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(28, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock8): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock9): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(36, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock10): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock11): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(44, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock12): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock13): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(52, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock14): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(56, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock15): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(60, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","      )\n","    )\n","    (compress4): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","    (norm4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu4): ReLU()\n","    (globavgpool): AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=0)\n","  )\n","  (classifier): Linear(in_features=32, out_features=3, bias=True)\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"Given input size: (48x1x1). Calculated output size: (48x0x0). Output size is too small","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Если сделать картинк услишком большой, то она не свернется в 32x1x1 в конце\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sample_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, num_input_features, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model(sample_tensor)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","Cell \u001b[0;32mIn[3], line 42\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 42\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks(x)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# We don't want to flatten batch\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(torch\u001b[38;5;241m.\u001b[39mflatten(output, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/pooling.py:756\u001b[0m, in \u001b[0;36mAvgPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mavg_pool2d(\n\u001b[1;32m    757\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,\n\u001b[1;32m    759\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding,\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mceil_mode,\n\u001b[1;32m    762\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount_include_pad,\n\u001b[1;32m    763\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisor_override,\n\u001b[1;32m    764\u001b[0m     )\n","\u001b[0;31mRuntimeError\u001b[0m: Given input size: (48x1x1). Calculated output size: (48x0x0). Output size is too small"]}],"source":["# Если сделать картинк услишком большой, то она не свернется в 32x1x1 в конце\n","sample_tensor = torch.randn(1, num_input_features, 32, 32)\n","model(sample_tensor)"]},{"cell_type":"markdown","metadata":{"id":"iOTbIAOwHakP"},"source":["### Как проводить эксперименты"]},{"cell_type":"markdown","metadata":{"id":"oXJjLoZXHeHZ"},"source":["\"Neural net training is a leaky abstraction\" - Andrej Karpathy\n","\n","Знания теории, архитектур, оптимизаторов порой недостаточно для получения хорошей модели - значит, пришла пора подбора гиперпараметров.  \n","В таких случаях может помочь не *model-centric*, а *data-centric* подход: переразметить данные, поменять аугментации, докинуть новые.\n","\n","**Но во всех этих случаях правильно организовать эксперименты**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YByhO57qIh34"},"source":["**Перед началом:**\n","Убедитесь, что у вас есть хороший и адекватный бейзлайн\n","1. Сначала вместо самописных моделей берите архитектуры из известных репозиториев (torchvision, timm, mmdetection, huggingface etc)\n","2. Эти архитектуры должны быть стандартными для вашей задачи. То есть, для задач компьютерного зрения (классификации, детекции, сегментации) - ResNet, для обработки языков - трансформер.\n","3. Не придумывайте сложные пайплайны обучения - Adam + LR без расписания, предобработка входа - такая же как у предобученной модели\n","4. Первые пробные запуски делайте на подвыборках, тестовых датасетах\n"]},{"cell_type":"markdown","metadata":{"id":"tdRq8GwXKLJU"},"source":["**Снизьте число факторов влияния**:\n","1. Баги могут быть в разных частях: в модели, обучении, загрузке данных, проверке качества. Сначала избавьтесь от эффекта случайности и зафиксируйте seed и попробуйте поставить determenistic поведение\n","2. Визуализируйте *все*: метрики, лоссы, градиенты, примеры работы модели, работу аугментаций\n","3. Пишите unit-тесты. Даже небольшие!\n","4. Сохраняйте чекпоинты. Не только best и last. Полезно брать чекпоинты каждые несколько итераций\n","5. При проведении экспериментов вносите **только одно изменение за раз**.\n"]},{"cell_type":"markdown","metadata":{"id":"__1FXprlL0Ne"},"source":["Более полные и точные рецепты можете прочитать [здесь](https://github.com/puhsu/dl-hse/blob/main/week01-intro/lecture-best-practices.pdf)"]},{"cell_type":"markdown","metadata":{"id":"hLD8YPRH5UOS"},"source":["## Обучение и подбор гиперпараметров"]},{"cell_type":"markdown","metadata":{"id":"4AKF23u86UL3"},"source":["\n","\n","> **Гиперпараметры** отличаются от **параметров** следующим:\n","> * Они не могут обучаться с помощью градиентного спуска: например, выбор оптимизатора, learning rate, аугментаций, сам подбор архитектуры и пайплайна можно считать за гиперпараметры. Иначе говоря, все, что мы не можем включить в нашу end-to-end модель, чтобы обучать это через функцию потерь, является гиперпараметром\n","> * Часто гиперпараметры подбирают на валидационной выборке (точнее, если их подбор уж очень важен, для них создают специальную выборку, которая называется *dev выборка*): например, weight decay\n","> * Гиперпараметры бывают дискретными и без отношения порядка: например, выбор расписания для lr, а также выбор момента шага расписания - можно делать шаг на каждом шаге оптимизатора, можно на каждой эпохе\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZxXnWrbC74SC"},"source":["**Вопрос**: почему weight decay лучше подбирать на валидационной выборке? Можно ли его подбирать на обучающей? Если можно, то как?\n","\n","**Ответ** weight decay (L2 регуляризация) подбирается на валидационной выборке потому, что переобучение легче всего определяяется именно там. Переобучение можно попробовать определить по тренировочной выборке, если учитывать не текущее значение функции потерь а ее динамику за несколько эпох. В этом случае можно накладывать штрафы на веса модели."]},{"cell_type":"markdown","metadata":{"id":"plUS_5-X5YAh"},"source":["Чтобы не писать собственный train loop, мы будем использовать **Pytorch Lightning**.   \n","\n","Это не самый лучший фреймворк для обучения - в нем множество багов, которые особенно любят проявлять себя в сложных моделях, обучаемых в low-precision с параллелизмом.  \n","\n","Но большая часть популярных фреймворков организована именно так - train loop скрыт от глаз пользователя. Поэтому полезно посмотреть это на таком простом примере, как Pytorch Lightning"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"PwIM9K5wBF5B"},"outputs":[],"source":["! pip install pytorch_lightning >> None"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import pytorch_lightning as pl"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Seed set to 42\n"]},{"data":{"text/plain":["42"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["torch.random.manual_seed(42)\n","pl.seed_everything(42)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Woi5D02x5Xac"},"outputs":[],"source":["# self.log() logs into Tenserboard\n","\n","class ConvModelPL(pl.LightningModule):\n","  def __init__(self, model, loss, lr, weight_decay):\n","    super().__init__()\n","    self.model = model\n","    self.loss = loss\n","    self.lr = lr\n","    self.weight_decay = weight_decay\n","\n","  def training_step(self, batch, batch_idx):\n","    x, y = batch\n","    pred = self.model(x)\n","    loss = self.loss(pred, y)\n","    self.log(\"train_loss\", loss)\n","    return loss\n","\n","  def validation_step(self, batch, batch_idx):\n","    x, y = batch\n","    pred = self.model(x)\n","    loss = self.loss(pred, y)\n","    # Calculating accuracy\n","    pred = torch.argmax(pred, dim=1)\n","    train_acc = torch.sum(pred == y)\n","    metric = train_acc / float(len(y))\n","    self.log(\"val_loss\", loss)\n","    return metric\n","\n","  def on_validation_epoch_end(self, validation_step_outputs):\n","    total_metric = torch.stack(validation_step_outputs).mean()\n","    self.log(\"val_epoch_acc\", total_metric)\n","\n","\n","  def configure_optimizers(self):\n","      optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay,)\n","      return optimizer"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"lNRIAatVCug5"},"outputs":[],"source":["model = DenseNet(num_input_features=3, num_classes=10)\n","model_pl = ConvModelPL(model, loss=nn.CrossEntropyLoss(), lr=1e-4, weight_decay=1e-6)"]},{"cell_type":"markdown","metadata":{"id":"y3CdP4tPC08O"},"source":["Дальше создадим датасеты и даталоадеры.\n","Опять же, вам нужно написать более точную конфигурацию: подобрать аугментации для baseline, batch_size, параметры даталоадера"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ltfuDf8gCvL3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["import torchvision\n","from torchvision import transforms\n","\n","batch_size = 32\n","workers = 1\n","\n","# вспомните, что вы можете использовать не только аугментации из torchvision\n","# но и из albumentations и, если уж совсем хотите заморочиться, nvidia dali\n","# прочитайте вот эту статью, возможно, аугментации из нее могут вам помочь\n","# https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf\n","transform_to_tensor = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","test_transform = transform_to_tensor\n","train_transform = transforms.Compose([transform_to_tensor, \n","                                      transforms.RandomHorizontalFlip(p=0.1)])\n","\n","train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=train_transform)\n","test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=test_transform)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["\n","# есть несколько способов ускорения даталоадера\n","\n","# главный из них - ставить pin_memory, когда вы работаете с gpu\n","# дело в том, что программы на host'е работает с логической памятью, которая называется paged memory,\n","# она связана с физической с помощью таблицы - page table\n","# когда физической памяти не хватает, страницы из page memory выгружаются (page out) на другие носители (например, на ssd)\n","# получается, paged memory нестабильна и может быть разбросана по разным физическим устройствам\n","# чтобы скопировать данные на device, сначала данные из paged memory копируются в page-locked memory,\n","# и только затем на device\n","# можно избежать такого: сразу выделять память в page-locked memory\n","# именно это и делает аргумент pin_memory=True\n","# https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n","\n","# также если у вашего трейнлупа нет точек синхронизации (напимер, print, logging, перемещение на cpu)\n","# то можно ставить data = data.to('cuda:0', non_blocking=True) при отправлении данных\n","# https://discuss.pytorch.org/t/should-we-set-non-blocking-to-true/38234/3\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n","                                          shuffle=True, num_workers=workers)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n","                                         shuffle=False, num_workers=workers)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"name":"stdout","output_type":"stream","text":["input shape torch.Size([3, 32, 32])\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAn4AAAKQCAYAAAABnneSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABvK0lEQVR4nO3dfYCcZX3v/+9OhslkMizDsCzLuizLEmKMMaYYMUR+MSBFRFCOtVYrLT3UB1Q8h3p8qn0AH9pDz/FUbXu0WqsW0PoA1ioGVMpTeQjhKSQhhBDCslk2y2azGTaTyWQymfz+oHq01+cb5k52s5u93q8/v7m455r7vue+rx3uz3xb9u/fv98AAAAw7aUmewIAAAA4PFj4AQAARIKFHwAAQCRY+AEAAESChR8AAEAkWPgBAABEgoUfAABAJFj4AQAARIKFHwAAQCRY+E0BO3futI997GN23nnn2fHHH28tLS129dVXT/a0gGnp7rvvtgsuuMCOPfZYmzVrlp122mn2mc98ZrKnBUwrjzzyiF188cXW2dlpuVzO5s2bZ5/+9KetUqlM9tSix8JvCti+fbt99atftT179tjFF1882dMBpq1vf/vb9rrXvc6OOeYYu/baa23FihX28Y9/3OhcCYyf9evX29KlS62vr8++8IUv2E033WTveMc77NOf/rS9853vnOzpRS892ROA2cknn2w7duywlpYWGxkZsa997WuTPSVg2nn22Wftve99r73vfe+zL33pS7+sn3322ZM4K2D6+fa3v23VatVuvPFGO/XUU83M7JxzzrGtW7faV7/6VduxY4cde+yxkzzLeLHwmwJaWlomewrAtPe1r33Ndu3aZR//+McneyrAtHbUUUeZmdkxxxzza/VCoWCpVMoymcxkTAv/gf/VCyAKd911lxWLRduwYYMtWrTI0um0tbe32+WXX25jY2OTPT1g2rj00kutUCjY+9//ftu8ebPt3LnTbrrpJvvKV75iH/zgB2327NmTPcWosfADEIVnn33WKpWK/fZv/7b9zu/8jt1666320Y9+1K699lq74IILeM4PGCc9PT1233332bp16+zUU0+11tZWu+iii+zSSy+1L37xi5M9vejxv3oBRKHRaFi1WrWrrrrKPvGJT5iZ2fLlyy2TydiVV15p//Zv/2bnnnvuJM8SOPL19fXZRRddZCeccILdcMMNdvzxx9v9999vn/3sZ61cLts//uM/TvYUo8Y3fgCicNxxx5mZ2Rve8IZfq7/xjW80M7OHH374sM8JmI4+8YlP2NjYmP30pz+13/qt37Jly5bZRz/6UfvCF75gX//61+3OO++c7ClGjYUfgCgsXLhQ1n/xv3hTKS6HwHhYvXq1zZ8/P3iW79WvfrWZma1bt24ypoX/wJUOQBR+67d+y8zMbr755l+rr1ixwszMlixZctjnBExHnZ2d9thjj1m5XP61+n333WdmZl1dXZMxLfwHnvGbIm6++WbbtWuX7dy508xe+AHMG264wczMLrjgAsvlcpM5PeCId95559lFF11kn/70p63RaNiSJUvswQcftE996lN24YUX2llnnTXZUwSmhSuvvNIuvvhi+83f/E37oz/6I2tra7OVK1fa//yf/9Pmz5//y8crMDla9hNlmxJ6enrsmWeekf/29NNPW09Pz+GdEDAN7d692z71qU/Zt7/9bdu6dat1dnbau971Lrvqqqts5syZkz09YNq4/fbb7ZprrrE1a9bY888/byeddJJddNFF9sd//Me/fN4Wk4OFHwAAQCR4xg8AACASLPwAAAAiwcIPAAAgEiz8AAAAIsHCDwAAIBIs/AAAACLBwg8AACASTXfueNvb3y7rnR1h/8tareG8ml5nzuntCWor77pFjr3xX7+lt40jzAd1eZbop7r7Z842bjzkWUzFn7FsaWmZ7CkgVkc59Q6nvqX5TU/Fz5qnXq9P9hSi1mjoNYRXT6fjbEJ2sO+bb/wAAAAiwcIPAAAgEiz8AAAAIsHCDwAAIBJNPxmYyWZkPZfLhWP1UKubfjAzlxfbyE63hzWPEzXvAeLnJ3IiU8T3dHl3TRRXT+REAPzCcifd8fO9h3cekyyVCr8TUTVMDC9c44U7Yjhe3ns/GNNrzwAAAMDFwg8AACASLPwAAAAiwcIPAAAgEs0nKBI8V+g9VNmoqwf3zVTIYZo9l2lm80Vt1BlbdepdouYdwrJTL4maPi4zZrXpTYhjs2/XsPN6+5z6Nqd+vajtdsYC09zLRe2xCXy99XGFODzTLRhwpPH2vxf6yHiJ0mlkPM9Jzm4AAIBIsPADAACIBAs/AACASLDwAwAAiAQLPwAAgEg0ner1EiUqTeMEbyzVcNK+IjKcPWJbtqnWbGY2QyRk93nvcUSXjw1b283K6W00Gvog5PNhMritrSjHdnf2yHpPd1jv6NAJ4HxKJ4ZXr1kv6/983bdlHYjSRCZ4XyZqj0/g6x1BVHsskr6HZjxajnnbiOF4qURzOn1w66TptWcAAADgYuEHAAAQCRZ+AAAAkWDhBwAAEAkWfgAAAJFoPhLiLBFVqsRbTVZqOpFTr4e9aY/cQI6TXNq3WhSfTrbpHc8Fpd07km1ij6htf1KPfcLua3q7Lz3zVbJ+5eW/L+sXnn+GrP/we9cFtd1q0gAOTbuokeqNXNLkbfM3aq/Prgrqevd/79cq1C+DTCVJEs3e2FpN/0KG8mJp3yN2eQUAAIBkWPgBAABEgoUfAABAJFj4AQAAROKQW7Yp3kOc7sOdol6rhYGPI4OXtkiYwjjCPHHfQ7L+fqf+hje9WtYnKshx6ilHTcyGganuBKd+52GdBQ6CeszfCzKknO9xkny7U7OKrKedpULKskHN6dhq9VTY3vU/NhKW0t5awVkXiDBDw2kR6+2Rw93izQtreHW1fvKCIPl8/oCvzTd+AAAAkWDhBwAAEAkWfgAAAJFg4QcAABAJFn4AAACRSJDqbb67W91rq+KkVdTwJC1OcOT56U8ekPWZojYeQd+nnt47DlsBjkDdTj3sAIkjgHdndL/Fcf4DdY+tO0uC9as3y/oPv3NrUOsbLsmxdSc1293VEdSKbToB3NVdkPXly8IWoO1FnWz11hYTmepV2/Zez2u3psZns2Gquqn5HNR/BQAAgCMOCz8AAIBIsPADAACIBAs/AACASLDwAwAAiETzUV1njaj6BmYyXirFeTnRU49Mb5zOeVmY67358Qlq4AvEQAfocQCHu29rEl5PXveu6QyX77Gi07Q/vP5nsv6pL35MVJP+gkLYR/0omyNHfvh/fEDWi7n2oHbWslY5NpNxegZPIJUk9tK7Xl052PN06p7dAAAAGFcs/AAAACLBwg8AACASLPwAAAAi0fRThI2604atrh5a1OvJlPPQYk0++MiaNEanzzsrqJUf/zc5ti4bvJndNy5N3oAmne3Ubz+ss8A4qlarQc0LBUxoq68may/Q4Y5KaUTWV628N6itW79Jjl29KmzNZmb2mhPnB7Vib68cO1bVa4j+TWE7uDOWni7HXnCurhfackGtVCrpsYWCrCvesT3c7d3MxreNLasrAACASLDwAwAAiAQLPwAAgEiw8AMAAIgECz8AAIBINJ3qrdZqTj1MP6XrerNlkZQyMytXKkGtVi43O7UjV8vRuu4dlYw4BrumV4L12n8JE7xb3NHT671PSzp47Z/j4aXAbP84zSWJY0Rtnh76ug/r+p2keo9YKtVbc+6B4yFJejTlfHgyKZ2a/eZX/07WP/bxvwhqu7wJJrH1UVl+11teJ+tf+uvPBbVisSDHDgz0y/otNz0Y1Fo7dLrY29fnn39+UOvs7JRjfc1/l5Y0pavG07INAAAAB8TCDwAAIBIs/AAAACLBwg8AACASLPwAAAAi0XSq10s01aphvZHW6aKKk9QdGQrH1yt6GxNphlO/8C2/ExZTOqGcaW2V9Y65YY/BbC6vt2F6X6dEv2Sv72BbsSjrpfJYUBurhTUzs/SYPl6NkXB8aawkx/7w//69rD9pe2X9d3/70qB2+jsukWNzHW2yvnRud1B78MHb5FhMsPBQvODJwzoLX4tTVx/vdXrond9ztvH/idq/v/iUcPisWLFC1lWCMpvNyrFppwe9ujZ7Y72Ep0zw1vXYfFbXa5WSrF/w+pcGtdFRfS8YWL9V1jeJH1bYJ0eanbtsqayvX706qA0ODMqxjYb+rmpT/0BQG354gxyby+v7bkdHR1ArOvfRdNrr2yzL8vh6od50euK/j+MbPwAAgEiw8AMAAIgECz8AAIBIsPADAACIBAs/AACASBxyqrcskrqZjN5sraITQ6Ojw0Et29AJqlNmzdbbToXzy+R1wjabL8j6vPmLZL3YFqZHczmd6sm36hRQQdTTOafnYka/9+72rvD1nIRSxemLXGgNxzfqes6Zkk711jPhcfz6vd+RY7307kc/+iFZ/8hH/jSo5fPtcmzKOXsz4tCMiTQzDpJKwnr9dKdKetejP2pmu8PSjPDjZ2ZmZ83R9TtVb9/5zut9xaljQj24cqWsN0Q889YVt8ixbeL+YGY2d/7coOalRPPiumxmlsvmRE2ftG1FvY2uObrJ9B8sCE/GdENfVMsjJVmvVcPm2qmsl3LWfW/f8K4/lPWJcvYrXiXrxUwhqDX0bdRqOSeS67RzVr9SUq/qXy7JtzqJYVH2uv2m1E3wV//9gP8KAACAaYOFHwAAQCRY+AEAAESChR8AAEAkmg53lMf0w/EjqZGg5oU78k67mk0bNoZjM/pB1Xd/4M/1/NLhY44DA/1ybN0JPuTz+oHIQi58mLa1XQcOWlu9ugh35PWjmYVi+ECvmVmrCKt4oZtsRq/pq9XwNdOjOsSx6e5Vsv7nX/7fQe15OdLsqj/7qKxf9u4/kPWceLC1XBmSY2uihZ2ZWbEQtt7p6AxrUVLZKO8JYRFwMDM/yHEk8lrKPRGW9oUZNDMzK2/W9T+5/MSg9uCQbn31U8Idk2L1w6tl/ZOfvTqo9W3cJMde+8/fkvX9N/+k6XnMcloH9vSE55CJe52ZWW9vr6x3deuTvChaynUWnfuXE5RsbQsDGxknWHDXXXfLunKsU9/R9BZ869Y+JOsFMW/vm7Ga11HWuZbWwwyMlYf1OsQ5vJbOh7NJ1b2AqN7GL/+7A/8zAAAApgsWfgAAAJFg4QcAABAJFn4AAACRYOEHAAAQiaZTvaOlkqxXKwNBrdNJUG5Y87Csr3360aB26eveJceu3qAjdNmO8DWL7T1ybLqhk7CphojemFlBpH2zOafFjtNCLSuSzjmnZZvXkqdUChPUmzbr/TG3p0fPox5Ghu665TY59jPXfVnWlZ//q06wnX7GAlkfGRqU9VFRyxf0Pm04f7aofT064kQyY7NrsicwxagTzrPT2YTT1ultiy4JamO3hol4M7Ofeq95lKjpLog4CP/ykx/LerorbMNWqupftuh5yXF6G/XwxBgb0x/AhtcBrByeoOWxPXJsdeQ5vQ3REtXMrE/c/vudtmqdnToZXBW/kJF2emlmM/q++6n3/XZQyzn317RopWemFzJeOnbM+TWI/qF1QW2kHt5zzcy6enXvxa52vZ/q4pbeyOv7fN1J6tbFj29UTb+X9gIt2wAAAGAs/AAAAKLBwg8AACASLPwAAAAiwcIPAAAgEk2neoeHdL/UXDZMlaSzOk6j0ruefJtO9VSd+FNVJK5KDd2DtjXv9cItyHojG+6mlNN3OO1EiTIiwJNJOwmluq6nauG2K1X9HnNO08DVP7olqCVJ75qZ/cuPwyTcuRdeIMcOD+vzZnBUJ+TW3BUmjN/+9nfIsblc2P/Ys3ljmNjCJHqpUxc9cl1Of1PrEjWnt+Ys3d7Udi8Ma6foU9zefc6rZP2O0bC3699+Um8DU8v3v/KNpsfOmKHrb1726qBWr+tka0bdIMwslw3TmTnvvuHUW1t1n92USN+2tjq/SuH80kTDwvk1nHt0e5vXMzi8jpecXxHx3ku+NbynV0Wq2szM0jrxWkuFF4nSmE71tpf0zwHUcwVZr5bDbVdr+lyoVvRxVGHklJNybu/Va5xf/ncH/FcAAABMGyz8AAAAIsHCDwAAIBIs/AAAACLRdLhj23NbZX320WHNCxwkMVItybp4RvIF4qHZVE4/kJpynvTesGGDrC9atCioFdsK3kRktSHaxDWc1iwN0VbNTD/YunTJEjl29a26Ddv/+MrfyrryV3/xV7J+7oUXBrWyaN1jZpZO6WNQcx4Avu2OcN5Lly6TY4ttev+1thaC2sBgvxyLSVIah23sd+qq65R+JtzmiBCHmVkYyzCbp7sP2op7V8v6PV9/KCyu1duwU5z6005dme3UadM3ofbt0/VUNgxKtBUKcmzdaSOWy4hwh/N1TS6rH+jPiG2YmeVEyDFf1NfUfKuzDdFazQsclMec+10uTGP96Af6/jWnd66sz1swJ3y9mr4n1Z2WrSosmHJCkutHV8u605XOUulwP41V9PyqNb3/RkthIHJ0VIdM5i95s57IL+ZzwH8FAADAtMHCDwAAIBIs/AAAACLBwg8AACASLPwAAAAi0XSq16MSqNueG0i0jRlHhXG0zSO61dfIkE6xZEWiqae3R46tVPXbXvXgSllfuCiM82WcFjZea5t8Pkz15HI6hZV1UlgZ0TpuQ59OIv+PP7lK1pNoLej2PZs2rg9qczt1O56M09qu5KSRqiId7LXvsZSeX29POJfSqLMNTI7nxmEbJzt1FeB2Ur2Vc3V995qwdvOfOq/3gBPrTOKQr8RGeneKufGWu4Lace0dcuz2556d6Ok05SibJeuZmfpepdqz7d5bcbaur9fHHtsT1HbsEIl4MzMLW46+oF3UxuMio/tCnvmSHln/b//tClnvmR/+fEBZtGA1Mxsd0+1MBwbCddXYmPcLKqR6AQAAYCz8AAAAosHCDwAAIBIs/AAAACLBwg8AACASh5wly2TDBOru3XsTbWPf3jCO9sD9dx70nH7h8Sfud/5FJ3Ve/oozZP1LX/q7oJZK6d6KxWLY78/MrKenJ6i97W1vk2PPPfccWc+IJo3XfvPrcmwSpx0vGi6bWSqt32NVpI76Kn1ybLd432Zm69eHyWBPvlWnwbxUtOL1j8QRrM2pDzdZM7Pi8AmyPr877IH942/9a3PzOpBjnfqTh75pTDH7w7T3VEnvevbabl3fo+vJ7JHVHTu2J9iG16B7PBK8zb/eUEmnaQedX6swkci1jP4FkHJZbzsjVmudHXq98WK4GwIAAESChR8AAEAkWPgBAABEgoUfAABAJA453KFakT2/41C3OtH0A5uPrfXCIM3btVO/+S3PPBXU/v3Of5Njf367rleqpaA2VnIeJk2g4YQ4ahXdOmZkaDAsFrvkWK+13ZjTlqZeD+eizjEzs44O3f5IqdVqTY/FEcLr6nSMqDlBkHylIOt33L3uYGb04qb8tRGel7/0lbJed1pHZrLhg/drH7nV2fp4hCdwuPzBlR+W9WJ3p6z/YEXYam7T5s1ybG+nvpdaNbw3Fgq6F+V7P/wBvY3/wDd+AAAAkWDhBwAAEAkWfgAAAJFg4QcAABAJFn4AAACROORU77NbwlYks2YdJ8fu3q1bs7TMCtsm7d89US1Ypr7hkRFZX3HLD4LaPXc8kGjbJxwf1moVnSj70l9/TtYvee8VQe0dl4UtrszMKg2dGK5UKrJerVaDmtfCptFo6LqFddVaEJNohlMPu1wlJ06LmTpsZ3evfkLW9x56wD8R3Thu4hpR4QWvPfXVst4u0pmLly2VY1tbvd6B4TWn8tYL5cgNGzbI+po1Dwa1jesflmN37gtbn8bihONPDmof+/Dlcmx5LLzHmJlt3NgX1Hq658ixnd4vSuhbkq1ZvTqoPfHM43LsI+Pw6yJfs2sP+O984wcAABAJFn4AAACRYOEHAAAQCRZ+AAAAkWDhBwAAEIlDTvWa7Qwqu522g0fNFJFSMyvmC0GtktZr0p07tzY9syNVb69OEi1ZEqbK1jy4So4dGg7T1mZm519wflDraS3IsT2982T99KXnhMWMTs3WnOSt16tXpX1LoyU51otQpcTfM3V69U4tSdK7Rzn1vU49vCTZwoV66AM3JZjHBCK9Ozk6OtplfXg07IG+adMmOXZOr3MdEtc+J/RpqXpJ1hfMCfu2vuPCZXJs1umLnk7r23ytFv7iQtmZYU30UDcz+9RffEbWD7d53b1BbdM6nZTesFH3yN24oS+o9fb06xd0Et6dXfrnA85aHP7qRWlI/3pHT3ePrOdzuaCWpF/9r+IbPwAAgEiw8AMAAIgECz8AAIBIsPADAACIxDiEO5q3d882WS+Vw2mknCXpzNk6ILJnl952ErOPO1HWd22fmEDJ7136flkfHAwfLDYz65mzKKhd84Wvy7HZnA5bZEQIo6tNtxwqFopNb6OR0adSvaJDFerBZzOzhniI2MmNWL02LOv33rEiqF1/3e1y7NcP3NkGh+oUp/50gm14IY4EOnucf3jm0LeNI5f3cHy+EV4TvRaRpTF9vVa3sL6+Pjl21cqVst4QLS/LzuvVnQCGF2wbLZWC2oiomZmNiLDLVHLnQ+H1/c6HDn27z67dIuuZlD4Xli9fLutzesLwyX/7QNj61OwAx1HeGw+uFSnf+AEAAESChR8AAEAkWPgBAABEgoUfAABAJFj4AQAAROKwpno9e+rVoDYzq9MqTuBFapl1jKy3OynWjk7dbqV4xhnh2LaCHFtobZX1vGhL11bUibJNm/pk3XLh4apWw31nZjY0NCTrXV1hC6BiUad3583RreNOXxi2cmt1TqXRSknW0yk9/vxzzxNVnUpbftYiWX/iqT2yjkmQJL07gf71E5M9A0xFrU67yrk94XVypKLbTJbKZVkvV8L65kF9Xe4b1qnZ/ft3BbVn/m36ty2d8mpO8726075PfMXWEC3zzMzqdX2/q4tUudeO78XwjR8AAEAkWPgBAABEgoUfAABAJFj4AQAARIKFHwAAQCSmRKrX9u4ISrl23eRzx7PNxwT3735e1p/b4tWfanrb4+Gd7/pDWe/uDfv6mZm1ptuD2qpVq+TYn3znO7J+vNi21+/vYx/5sKyftXhhUGuYTjPVnITS8IjusztSGghq5eqIHJskvXv2q5seiimm5TRd3/9kgo3sG5epYJoZLek0bb5cCGoZpx95zenhOzwWpnofePBhPRGR3sXUlUrr78xqzq9smDhH6qIP8wtDnWSwqqm4cBP4xg8AACASLPwAAAAiwcIPAAAgEiz8AAAAIjE1wh1CJqunNuOY42R93/PbJ3I6E2J0TD9Y3FrWLeUyhbAd3Bynrdo73/teWe/u7g5qnU6rusWLFsl6RbSaafUefHZ67PUPDsr6wgXh/FatvEuO9Rw3M6yN6HwIjgD7E7RpBMZDf39/UEs5bUS9Vm5DQ+IaR4jjiHKUU6+JNrNmZlUnzKjCjzWnZZsXlBxPfOMHAAAQCRZ+AAAAkWDhBwAAEAkWfgAAAJFg4QcAABCJQ0/1thwd1vJFPXbnM81vN60TVJ3dPbK+Ze2Rl+rt7NGt2XKtBVkvlUpB7W+/8AW9cSdNe6lI+5577rlybL41TBGbmdVqYXKp4aR66077mccee0LWrVEKX6+yTQ49dpbexFlLZgS10VF6do0bFXXTH1ez8QgxNt+lEUikUqnIerUcXrdSOX2SDw7rXyhYvWb1Qc8LU0Ork+v1WqV5SV0lacu2urine2NfDN/4AQAARIKFHwAAQCRY+AEAAESChR8AAEAkWPgBAABE4pBTvSf2hr1iq3W92R3lst5Ia5iWyuZ0Mjifz+ttHPsS8YLP6rGT4MSXvjKopdL6vbS1dch6X9/GsLgzWZr5lhUrgtq73/3uRNtQvL8gvFSvZ2R0OKi163CxLT/rWFmfNzfs97tmzYZE88AB7G2yBkxxlaruuTomerE2avoqNzqme/Xu27Xj4CeGwy78LQiztmPb5VhvHVIu63MhnQ7XRKp2IOrXNA4W3/gBAABEgoUfAABAJFj4AQAARIKFHwAAQCRY+AEAAETikFO9W59aE9RmHjtXjj26q0fWC8UwtpnL6ShnLpeT9TOXnhPUyhWdIi6VRmV9TPTCNTOrVMKEV8p0wmbuHP3ely5dHtRyWZ0Mam/vkvV8a1bWk7j88suDWltRJ6hzWd2bMpPxGrOGavVkqd7nhvcHtbnds+XY+fP0vu7uDlO9mzeNJJoHgOmv0tDX8aroi1qp6rFjTpITRxa1ssg4Pei9hG3VSYkrXp/dJPWkyeBf4Bs/AACASLDwAwAAiAQLPwAAgEiw8AMAAIjEIYc7zPYFlT07Hpcj9zgdbHZuCR/eP/6UeXJspqNT1lP58NHMtg7dbmXOPL3t1lYdtmhtDYMmBadlSy6rwyd1EXIoFtrk2M4uJ9yRC0MLP77zATk2k9VBkJ7ucP957yWd1n8XJPlrIWXJwh0WZjssZeGD1mZmqZSeSb0u6qlxONUBTCtl52H8SiO85pRrTns3rxUpjijqTlWpVOTYUkkHelLOfSZJCMMLd6htJAmT/Cq+8QMAAIgECz8AAIBIsPADAACIBAs/AACASLDwAwAAiMQUiTruCirbnn5IjvTq0tEnyPJJc+fIepeTpu0QSeJqUSdyC277szDtm8k56+6UTvWo7mdt7Tq5rJLIZma5XJj2zTjTSDuJ3HSCvxfuuuO2psf6dKq3r69P1kWHPas6iTwA8aq4qd6wJVfFuYZ4yU9MTTOcelb8S8NpOVpzzpsxJ+2r2px6Sd+6SJSb6bSv98sWL4Zv/AAAACLBwg8AACASLPwAAAAiwcIPAAAgEiz8AAAAIjFFUr0TZOdzsrzlIa8+kZMJE0OzTtR9hzs7O2RdJXK9JLKXLm4VPY0LTqx37pxeWZ8/b35Q+94NN8ixn//fX5T1JLxkldfTsCJivSTvAPxndfUTAGZWF6ler+94uqGvn3tFbfbsE+VY71q2e7e+V+Hged92NcTxTTk/BlEd0/8gThszM8ukw1Rvva7Tu2Plkt6ImLj36x0vhm/8AAAAIsHCDwAAIBIs/AAAACLBwg8AACAS0zvcMaXsCyq7t26RI59y6srag57PkaNe3y/r3gPR5XLYNme0tHNc5wTgyFcpl2W9JtpmVp2H8ffu0dswawm3W9VP/+/d56QCcNioVqSN/foeU92lwx3Vij6Oqj1baW9Jjt1mzzszDJ28++BakfKNHwAAQCRY+AEAAESChR8AAEAkWPgBAABEgoUfAABAJFr279+vI5MAAACYVvjGDwAAIBIs/AAAACLBwg8AACASLPwAAAAiwcIPAAAgEiz8AAAAIsHCDwAAIBIs/AAAACLBwg8AACASLPwAAAAiwcIPAAAgEiz8AAAAIsHCDwAAIBIs/AAAACLBwg8AACASLPymgNtuu80uu+wymzdvns2ePdte8pKX2Fve8hZ76KGHJntqwLSyc+dO+9jHPmbnnXeeHX/88dbS0mJXX331ZE8LmHZWrVplb3jDG+zoo4+2fD5vZ599tt1zzz2TPS0YC78p4ctf/rL19fXZf//v/91WrFhhX/ziF214eNiWLFlit91222RPD5g2tm/fbl/96ldtz549dvHFF0/2dIBp6YEHHrBly5bZ7t277brrrrPrrrvOqtWqvf71r7f77rtvsqcXvZb9+/fvn+xJxG54eNja29t/rVYul23OnDm2YMECu/XWWydpZsD08ovLXUtLi42MjNjxxx9vV111Fd/6AePo/PPPt9WrV9vmzZstl8uZ2Qvftvf29trcuXP55m+S8Y3fFPCfF31mZvl83ubPn29btmyZhBkB01NLS4u1tLRM9jSAae2ee+6x5cuX/3LRZ2Z29NFH27Jly+zee++1rVu3TuLswMJvinr++eft4Ycftpe//OWTPRUAAJpWq9Vs5syZQf0XtbVr1x7uKeFXsPCboj74wQ/arl277E/+5E8meyoAADRt/vz5tnLlSms0Gr+s1et1u//++83shWdtMXlY+E1Bf/Znf2bf+ta37POf/7y96lWvmuzpAADQtA996EO2ceNGu+KKK+zZZ5+1LVu22OWXX27PPPOMmZmlUiw9JhN7f4r51Kc+ZZ/97GftL/7iL+yKK66Y7OkAAJDIZZddZtdcc41dd9111tXVZd3d3bZ+/Xr7yEc+YmZmL3nJSyZ5hnFj4TeFfOpTn7Krr77arr76avvkJz852dMBAOCgfPzjH7eRkRFbu3at9fX12b333ms7duyw2bNn83+yJll6sieAF3zmM5+xq6++2v70T//UrrrqqsmeDgAAh2TmzJm2YMECMzPr7++37373u/ae97zHZs2aNckzixsLvyng//yf/2N//ud/bueff7696U1vspUrV/7avy9ZsmSSZgZMPzfffLPt2rXLdu7caWZm69evtxtuuMHMzC644IJf+wkKAMmtW7fObrzxRlu8eLHNnDnTHn30UbvmmmvstNNOs8985jOTPb3o8QPOU8Dy5cvtzjvvdP+dQwSMn56enl8+ZP6fPf3009bT03N4JwRMMxs3brT3vOc9tm7dOiuXy9bd3W3veMc77BOf+ITNnj17sqcXPRZ+AAAAkSDcAQAAEAkWfgAAAJFg4QcAABAJFn4AAACRYOEHAAAQCRZ+AAAAkWDhBwAAEImmO3d8/etf1xtIh5toNBpybL1eT1RXMpmMrOfz+aCWzWYTbcObt6p7c67Vak3XUym97k4yP7X/zfz3rl5zdHRUjl29erWsf+c73wlqW7ZskWPf9773yfqyZctkXc17bGxMjh0YGJD1wcHBoOYdr69+9auyPplaWloOeRsnzD5G1i9429uDWqq1IMfms7qey4SdLRoZfS5Xnf3ev1kfuw2bNwW13nlz5djNfX2yXiuH58tTD/xcjvUcfUr4I7M7h3fpwU7Zjg1LJ3boVlVbN+7W29gXlmY4L1c8Ttd7usVEzCydDj9rlXpVjq3V9LXRGuH15/HHt8uhU/EnY4vXhNcKM7N6PbxeO3vAag19jnvXd8W79yTZRtJtJ9qGM49UOqy7c/ZOoSSDD7OUNw13nzrvXZTdTbuzEf/iDK7/aa+7FWc6AAAAmI5Y+AEAAESChR8AAEAkWPgBAABEgoUfAABAJJpO9eZyYZLPTKdKvWSrly5S2/CSrV6KVSWJvHSRV/fmp95Pteql3/R7V6nSpPNQ793bHx41Py/xWigUZP38889vehvd3d3NT870/JIkpc30fi2Xy4nmMRXpPKjWO2+OrJcrlaCWS+vPWrXh/F2oEo8i3WlmVq3p86JS0cdDnUfecfYibV6iPYlcQ+yTVj2PcmavrLd1hDHbtmJBjm3M0fujWmv+M59OOdeeXPiLB2ZmKTE+W3d+JcDZ1zV5C9Gp3qko5Vy30vXw/bppS+/rE3EddxO24vXMkl/fJ0rDy96q3edFYRMkl5N+IyW37O1rb10ga3ps2ql7+0mV68nCz/LccVPHL4Jv/AAAACLBwg8AACASLPwAAAAiwcIPAAAgEk0/OeqFLZSkLWLUw9jeA9pJwh1JH4xN0mouaeAgSbu18WixkyQ44s3Zm19XV1dQ846XaqV3oNdU9eHhYTnWC2wkaY83FZ04K2wXZmZWLYgH/fM6dFV12khVRbgjm9HHqFrXrfJqabGNdKscmzRgJYNeXpjBqecSXKs8mWr4OWkvdsqxI7Vwf5iZpUVoJuNcknq6O2S9LkImFScIoNqMmZk52R1Li1Mk7Vx7Mk7Ltto4BGkmUzalD0hdPGLvZZ3G49pSTzkhEzU/9+W8z1qCiSRqq6b3iRtw8IISid6jN5GmX86/N4qNeOEJtyud89lMMD2fTJ8c3FrhyLkbAgAA4JCw8AMAAIgECz8AAIBIsPADAACIBAs/AACASDQde/WSpkkSqF7yU9WTJnLVeC+947UX85Kmqj2bN7YiUpNmej95bfC8BLV6P9578ajx3jH05qeOlzdnr56kPZ4nSZpuPJLSh0umLUxNm5llxfFoK+o0baHgpC3FLhsZ1alp9XpmZulseEyrJX0eppzjX/NaZYlj6h45J67qvWYSqc4wZdso6vTz0FC/rO+38Fwererj0uq9yVp47SlXR+XQerkk6w0ntZ1Xv4RQ0tevjNfx0GlBd6RwW4OKmpfqTXJlce+jCVLunqQJeqXupVKd9GiitGqSf0ic6j30e0FKrSGcg+sdFXc/yZZtydLPam8f7Dd3fOMHAAAQCRZ+AAAAkWDhBwAAEAkWfgAAAJFg4QcAABCJpiNDXno0SY/cJKmjpCnMJGlV77149SRzSZKgcnuNemlKMT7pe0zyekn6/XrcBFWCFJs3P49KHXs9g6eifE4nP3PqfaWc1HRN79+xaimolSu6J2+m4qRBC8VwrDmJ/ZROHddF4tXMzFLiWKf0tjMiXWxmZjVx7rfM0mP375bl/MYwqZvbpcd26y1bu6g1bJscmz3uOFmvtIfHYCTn/FpBvk3Po6L3UzkbHvcxc64bTi/ZTCpMHR9J8t4ppIoJvyZJcgtLOT2D9XXSuY86+eK0c0wr4rPmJeJTpo9zSuwpbx4pJ8VaE9uouztbzy+bFr8M4mzB6yVcTbCGSHvHoO7c10St5hyXuverBKIXd6Z+cJ8/vvEDAACIBAs/AACASLDwAwAAiAQLPwAAgEgccsu2JKGKJC3UxqP9jCdpcMRr66N4bemShBaShC28FnFe6zP13r2QiVdX23Yfgk0Y9FHjvW14+zpJ4GgqSmWcz0kq3O+lqu6lVR/Tx7+rNQwL9ObCsIaZWSWngxmjIsiRcgIY1tD7vS4eVDYzK+fFsWvoscUNG/Q2Nq0Oar/hhDi8T3ZWBDm8M6jHqc8VNe/qVd++Xdb7RV1/4s2qLz1V1mvdKmZi1iirz5rzmfJmnhb1p57TY6egfFa/r5p4X4m7iIlLYrIQh+beG71QhRMiSItgWKPhjHU+gzXxmnXnPTaccysjAhEF536Sr+mzv7R5TVDbvOlBOTad1fNbes7yoJZ1WmJWnRZx1ZredmksfD9Zr22ps59M3MMyzXc4/TV84wcAABAJFn4AAACRYOEHAAAQCRZ+AAAAkWDhBwAAEIlDbtmm0pxewjNJmtZL0iZpI5akbdmBtt3s6yWVtN2aml/S9PN4HK/xeO8eNW/vXBiPNoJTkTdXeeycxF7/wICsz5kzL6htXqXTb0t+9/dlPSXmV/faRXmpblk1s4xIv42NyKFDj98n6yVR85Kw3lmhtuEF6JwMnt0iakucsb1OfbOoDTpjFzzxlKw7nfcs2xq2eBO7/4VtpJ0EovPrAUeKnNP2L5Ps1tE0/x4zcfeetJOyTYs2bG1p55MyFrYwNDPLqPaSrZ1y7IhqpWhm9Xq4jfImndi/89rPyfqM4XB8OuO0mWvVv5qxeFmYfh9aNyTH9o/oNpetnQtkvb0jzPhXUwU5dtjZTw11/3d+NeHF8I0fAABAJFj4AQAARIKFHwAAQCRY+AEAAESChR8AAEAkDjnVqyRNqybZRpJ+v17iLEmfWG8u3ntJkh71es161GtWqzq5lOQYJE0/J3k97xgk6eGbtFevGj+RSeTx5r1feeycBNhYSafORhvh+dJxhk6ipdt0+s1KYX/gjNP/Mu31Ha7r87atHm5ntH+dHLtJz84Ks48PX6+zIMeODunUXmHnzqBWnDFDj110hqwPV8Jk9d2Pb5FjN8qqWdfMWUGt0ROmcc3M+p7Q2+56SKd9x35DnDuFghybqerPcab5W8iUlHPOT/Vu/W9JvF9WaLZ4gF7Iopz0UuYNz6XCz+B583QEPDuoj/93rv9SUOsb0Z/tM865QNbr+UI4t4K+fp31jh5ZP73r9KA22Dcqx37zO9+W9buu/eugdvt998uxyb0sqLz8v14pR/Yue7OsVxsige6cvy+Gb/wAAAAiwcIPAAAgEiz8AAAAIsHCDwAAIBJNP5mbNGyRRJIH+r0wQ6XiNWVq7vXMkrUAS7rtfD58aLajo0OObWvTD2+rbQ85D6cPDurGTips4b1vL5iRJCiRNOijjnvSMI7X4u1IsX69blfUqIf7cvee5xNte7gSBjPyPXPk2MFqSdbXb1gT1KpO67icExYYG9Rt2Hpr4TG9+4mH5FgvkpSeVwxq25zPyTE7m79ujOT2yXqhoT8nXe3h5ziX0+ds5aGn9Wvu2R3UFrTrBm+lgg7jDNz/hKx3PvJMUKueqR/uTzutzWwcgmGTyckkWboxDt+JqBZb7uAEiQ2365sTVHHGF9PhsZvTqu+v3/nq9bL+k3/+ljOZ0IaVt8r6vp3hNey/vOu/yLGf+OxnZf0jH7giqN148+1Nz83MbGBUB0rGx+NB5bFv/C85srUzbO9mZtY5d1FQq9UJdwAAAOAAWPgBAABEgoUfAABAJFj4AQAARIKFHwAAQCQmpN+Ol7x9+OGHZV0lcgtOGrCzs1PWu7u7g5qXKPUSwF7SVG0nScsxM52Q9VKzHrVPkrT3MtMp4KTzSNL2LWmrNDXe20aSY3AktWzbtWvHhG27tRAmXvO5ghzbMJ3kHKuG+7LsnEO1tNPqq6GP3dgTYXu2MNf6gpN/45WyniqKVO+ATvVWW3RSN7M/rHkBVq9eEIm7eptO8udPDNPWZmbVrdvC2phO7I+IFLGZmX7nZuFeMsutD9vMmZmVF+nrblm23mtxXnHqyTtdM+viO5GkVxB1hqecLHrD3bq4n6Sca75TTzuftbZceOxqdZ1svXuj/qUBmzE7rO3T93+V3vX0bdKp/5pI/ZuZDQzr9mxJlCvjkFA/6hRZfsXb3xHUSs5tN1XXn9jWjLjuppy2mi+Cb/wAAAAiwcIPAAAgEiz8AAAAIsHCDwAAIBIs/AAAACJxyL16VYLXGztnju4Jum5dmORTNTOz1atXy7rqhdvbq3taenWvR24u13xyxks0qwSqly723qOat9eX1qsXReLRS/V67yVJv9+JlKSH8tjYRPZhHG9HOXX1udKpVE9GpBjntepzJZXW9eFceA41TJ8r2VSrrPfXdYp11HbJutz2mH7N1lRYr9ad97h/hqynxX5NO/Hi0lrdSzjXEh7HbHdBv15JpxJV6HTk0Sfl2E2m67r7rtk8USs+r5OXm4faZX2gI/w1BbMtzitOPW4L4kb4D6JV9gt1Z9tp8XnNOJesqnMrboikrpcMdgLKlq7p+0xnRlzHvXuBlx7tEGnvsrOjnHSxiXtjvqhT5N7ePmf5GUGt6Gzj5p/fLOv79jd/7fG89uKLZf3Nf3BZUPvhj34kxxa8X0JIhfV0xvt0Hxjf+AEAAESChR8AAEAkWPgBAABEgoUfAABAJFj4AQAARKLpVK+XoFQJXi/h2dqqE37nnntu06+nes2amQ0MhD0m169fL8f+wz/8g6x7jjvuuKDmJWF37tzZ9HZf+9rXyvp5550n62r/dXTo3p9eH9sk6WIvnT0evYuTJHKTvBezqZM6Pnh7D3kLxzr1Rf3DQa19pCTHjjlJ056BsFdsab9obnsAXgJR5fC6nLGZp56Q9YKo9Tjb8C6A6p17Z6xXT+8Pj2PqmbD37oGo3LL+7QEz/ZsJPpXT1VcTs+oTuj/wYLqQ8FWnlnxaH72qOEFrXirVkWqE15yUc7aknGttViRvCyK1bmbWltXb6GzV855bDBOhw336OI+N6HuEpcSOSnvxZy/SXApLY7pXbybjHAN5P0l2zZ898+igtnjRIjn2zvv/XdY3rF4p68s3LwtqG2+7TY7tmaPy9mZzFiwParXcwfWg5xs/AACASLDwAwAAiAQLPwAAgEiw8AMAAIhEsqdVhWw2fLjTe5A+yQP9Xsux+fPny/oZZ4QtW1RoxBtrZnbTTTfJ+mOPPSbrh+qee+5JVFf+8A//UNbnzdMPiKr2c+3tuh2TF55QvGPutX1LErbwzgXvfFLbPrLCHc17qVN/r1OvikDEamdsGAN5QZI9WXDqPU59rqjpM8ingiNemKTk1NV7VHMz8y+iahtJwiRmZv2ipq9efrjDa1YYxuH8/VF2Wund89gDzn9xZOjK6ZDeSDmsN5wgSNathw/e55wToOgEM4oi3NHuPdBf1Ud6uKTr6XJ4L6iO6VaK9ar+1J8yN/xUPL1hs57foA5s2P6wxd/6h51PhBOCWbJkaVBrbdVRpc5O3bJ12bIlQa13To8cu2LFHbI+WtYhmMF19wa1hV26Dd7oyAZZt9LGoNTRVtBj3SveC/jGDwAAIBIs/AAAACLBwg8AACASLPwAAAAiwcIPAAAgEoec6lXJyqQttlTSVKWFvdcz0+lRbxtvfetbZf2SSy6R9bvuuiuoXXvttXLs/fffL+sT5R//8R9l/ZWvfKWsP/roo0HtjW98oxx75ZVXynqSNn1eqjdJ3Rvrtc1TLei8ZPCRRCV4L3DGFpy6SnLq/LfZIqeujoaXAHYaPbn1JH+JemOTNDHyzook2/Auomp+3ut52yiImmprZ+bvU2/bKqWsM51+svpMUesTLS6nqvmt+ro1mA7ruZw+eu1ZvY1sKqy3ZvXRKI/qVmn1SnhE2oo6rTo8WpL1tHP9zItE6EjZy4DrT8RZ88OE7MhGnUrdKdK7noXzdEY95czjjCVhInfpWcvl2LGSPl4NcZaPlUty7He+901Zv+Lyy2X99NMXhduu622POi00K5lwfsNjKvdvZrbAqb+Ab/wAAAAiwcIPAAAgEiz8AAAAIsHCDwAAIBIs/AAAACLRdKrXS22qBKU31ktWqvFeYlMlgJPy0sVeYlj1vfUSr6tWrZL1z3/+881NbpxceOGFsq5SvTfffLMc++EPf1jW1f7zjm3ShLfajkoRm/lp3yQ9hqeiWU497NRottgZq7NlZnsTzOPjTr1V1LzUp/eXpddJUo33jmaSRK6+mvjbyIua9x69baj34iVvvTStmofT8dTtyZvkGOi8qJ/8VvtkTq/X1Xjq6VYns5kVRFK3Na/PxKFN62U9lQ3PjGKn3sMV51qWzagJqrPCrL1T7/fOLid1LHoMDzrp4lRaz0/1Ht456mX8tde9NsyGX/YH+hc2vHv0+vVhkjjfqg9uZ3uX3nYj3PZYQ++7p59+RtYffPhhWe/oCOdy04ofybE1537X2h4e3+G0fi/2VlK9AAAAMBZ+AAAA0WDhBwAAEAkWfgAAAJFo+il474F5FcxQgQ8z/2F89fC+9xBnkgf3k4RJzMyGhoZkXc1PtXEz81u5JXHSSSfJek9PT1A7/fTT5djFi/Vj/5deemlQKxQKcqzX8i5JGMc75mNj+lF0tW0v0OMdXzUXLyAyFS1y6urR7X+awHn8lVP/bVHrdsbqx9DN9CdNByX0pzVZ+zPvL1xv2wVRa3PGettWZ77arplZyamrK+lmZ6zH20/qU+UFWIpOXV0h7n7gvhed01RRrY7KeqYaXp8KeX0GZDp0YCMjrp8N52xpzRdkPZ0Kj15WhBBe2LZ3Njv3XXFmjIzoT2ZatLAzM0up+3Hdi1JpqXR4bR4Y0q3IajX9XtS9IJXRawXVms3MLFUP55HPJAuTlsackE4+3M66h/Uneayqo17LLugJauWKF/U6ML7xAwAAiAQLPwAAgEiw8AMAAIgECz8AAIBIsPADAACIRNMRWS9ZqdKS+bzO8iVJBntGR3UKq78/TAF56WJPqVRqun7bbbfJsbt37070mkpXl27DohKyd9xxhxw7MDAg6+ecc05Q6+zslGNHRnRiSB1zL73r7VPvOKrzzEt4e+eNN5cjhdNFyvoO5yQO4Pui9j5nbJJWZF7dywh6Fy91tnjZvCTb9sZ67eeStI7zqPfind1ebr35q6s/P68dnEr7HkkNE7uca1+jKs5Ep32X1xpMXbf8dqZOa0uxjVRKb6PuzK/hnRni1w/GhvU1v5hz7unq7HKu157b77w/qN0tamZmF5x3vqz39vYGNe+8V/vUzKzeCD9ZtYQ/BlGrOZ+UVHh8h0f0PTBb1OdTW0d4ro4MH9yvVfCNHwAAQCRY+AEAAESChR8AAEAkWPgBAABEgoUfAABAJJoOYCVJ3q5evVrWVfLWTKd9vTSol9jcvDnse7djxw49wSnuvvsOvdflo48+KuvlcpizvOSSS+RYr7+tqift1esldVV/YC8N7s1P9W305jcVrXbqzx3OSSS03ql7CeVCgm3r7JufYlVH2kvCern/jaKWJEVsplOFXo/idqeuOm57vXe99+IlctU+8faT95oq6/mkM/ZIoq9P3nVIb0Ndn7xrVsXpz5oVad+Mm4lv/nptZlariZ7rJT2PDie5nEmF2z62vSDHzutS3cbN7rsnTPC2zmqRY++6Vf+aRu/ccNtV53itWbdG1vvE+mRkuCTHesbKOhW9+uHwNZ/bsd3ZiP7ErhTbWHrOW5uf3K/gGz8AAIBIsPADAACIBAs/AACASLDwAwAAiETL/v379zcz8MILL5T1vr6+oDY4OCjHHqlhi+nu85//vKy3tbU1vQ0vrJEkIGKmgxxJt62oUIuZ2Xvf+96mt3G4tLToB5vHw3EnnhjUCu06WvCUExBK4gSnPpWDKjg0s48+RtbLY6XDO5EmlJzwWb0SPmCfclqi1ROEOzyNhg6fpcWlT4XXzMzSWV1fv1FFlczasmFI5O3v+AM5tlbX+2ne/HlB7fvf/1c59kMf/ENZX3XrrUHt/ieekWOTeMXLXy7ro8694Nlnmn/No46aIevFNh0oeW7rnqa3ncSJr36TrA+uuumA/x3f+AEAAESChR8AAEAkWPgBAABEgoUfAABAJFj4AQAARKLplm0/+clPJnIemERf+MIXZP3Tn/5009tQrdbMkiXbzHSC19tGLpdrehve/KaiGU6od19T+fsXHHPs8bLeVgwTvKnmuzEmRnp3enjlb7xa1guFQlDr7u6c4NmMn5Tz3YeqpzP6GpJxfnVA8a5loyO6TZdqI9ao6wRwf59uifq9H/5I1tsL4a82PJQwyV+peo0CQxucdPF4JHiVtY89JutvestvyXpbV3jeVsd0mvmJtY/Iend3mHI2M3tuq57Lodr6wMGty/jGDwAAIBIs/AAAACLBwg8AACASLPwAAAAiwcIPAAAgEk2nejF95fNhz0Yzv0eu6qeragfaRpKUbalUknVv3qqXpTePqejc886U9YH+oaD22ONPy7He/h0eCrfh7V9MD8cde7Ssb9+xs+ltPLr6AVmfIT5W+/bpbVz7zW82/XqHi9tLXNwaN23qk2PXPfygrI+Ojga1qtMb+Ac3fE/WH1g7MWlQM7NZ47CN7p6eoHbGkiVy7K0/C3vyToY7br1D1hedHiZyH3XSu54NawYOZkqH3ZFzNwQAAMAhYeEHAAAQCRZ+AAAAkWDhBwAAEImW/fv3N9UIqqXF6SOFI95VV10l63Pnzm16GypQYeaHPrx2a7Va2I5oZGREjm1tbW16Lt7rnXPOObI+mSbys9YyY2ZQ279vz4S9HvALTd5qDqvBug539K3fENRe+8qXT/R0jjgnn/ySoKau4WZmW7dum+jpHFH+8KOfkfWeebrtW7FYDGq9c3rl2PMX9BzwtfnGDwAAIBIs/AAAACLBwg8AACASLPwAAAAiwcIPAAAgErRsg3V2dsr62NiYrJfL5aDmtQjztuFJ0srN27ZKEnsJ4NiQ4AX+n1Raf/dxy61To73YVPH5v/orWe/q7Ahq3jX8ot/+nUOex2t+41Wyvnrd+qC2Z+/uQ369ifT7H3i3rHf2hPvUzKxaD2v1mk6lvxi+8QMAAIgECz8AAIBIsPADAACIBAs/AACASLDwAwAAiASpXiRKx5qZVSqVpmpmZtVqVdYbDZ1GGhoaanpsd3e3rKsE7+joqBx7ZJmRYOy+CZvFePC6EafEv2Rm6pRg2ukPXRXn4t59e5uem5nZMbOPCeeW0n8nV6thyt1MJ0YLXro8pc/xZ7duD2rHHTNLjs3lC7Jed3qnVirhZ7Oto0tPL6WvBWqP1J3P61RUquh9c8eKOw7vRKaID73v/bJeKBRkvb+vP6j19fWN44x+XXdvj6xXamHkde1jj07YPMZDpq7vjam6iO+aWVZ8rrxU+ot9p8c3fgAAAJFg4QcAABAJFn4AAACRYOEHAAAQCcIdcB/G9Vq5ZcRD9V4QpOY8WO61UFPt4AYHB+XYnp4eWVfUnKeq44+ZKevq/dbrev/mcvr99veHD2Pncjk51nugvzVfFGPlUDdUk83o/6BUCse3FcPXM/PPuZHR8OHo4WEd7sg5HQI7uwph0XnoemBwh6yriEMupR/ozmb1e3lW1LY/r1tRdbXpz1TJCZ9s3RW27+syHfRqbS3IelqcI+pB+6nqr//yc7L+7/+24jDPRDvppFOD2pYtT03Y6/3tV748YdseD5s298n6VA9yvOa004Jaujwgx45uCgOOZmZp8T1dJuNcwHoXHnA+fOMHAAAQCRZ+AAAAkWDhBwAAEAkWfgAAAJFg4QcAABAJUr1wU7NtbW1Nb8NrzaZSpGZ+klSlgNvb2+VYL6lbFClQL0U8FW17PkxbmpnZ+ieCUs3pRJZ2urttl53cdErU91xQ8ZrJeY3jkox/ZpvKto6Pnbt0/bknnpmQ19u+e+eEbNfM7NGnwuOS1GNPbXX+xasf2YY3b3L+xfkMTpAWO0rWz1h8RlCbyFTvVPfIIw9N2LbVNSmvD4stW3Kyrp+1TNbbO8N72IZ1N8mxtZrTyk2k5WtVnaCff+Xfy/ovt3XAfwUAAMC0wcIPAAAgEiz8AAAAIsHCDwAAIBIs/AAAACJBqhfWaKiuomZDQ7pnYJJt1J3+pl6qt1QqBbWU0wjW6wOrXjNJX9+papuT4JW8OO0ESfpyh3l6iR0tahOXx8VkWbhgjqyPnv3KoPbvt+t+sGe/9k2yfvs9P2l6HvtNf7hv/Jd/bnobaM4rTtL189/8+qCWzetfjsg4fcLrGd0Xu1IPx4/1j8ixo8P6vlsZDftoj42V5Nj3kuoFAACAGQs/AACAaLDwAwAAiAQLPwAAgEiw8AMAAIgEqV7Y5s2bZX1kRKeO0iLRNDw8nOg1x8bChJKZ7vmbz+flWK/H8MaNG4OaN7+3vvWt3hQxRTjtMp0c5PggwRuHvs0PynqlHPYYP1ZFvc2skNP9yDG5XnaCrl/w5t+Q9Xsf/Legti68lZiZWWvYDt7MzJwfoLD29rAT8GCf89sGYbt6MzMriB/CyGb12BfDN34AAACRYOEHAAAQCRZ+AAAAkWDhBwAAEAnCHbBNmzbJ+qJFi2RdhTtqNf1EqteybcOGDbKuWrZ57dZWr14t66rFW1dXlxw7FZ120ixZT1nYPqhW063yUhn90c5mVQsi/fdfxtmGGp51njJOOZeYVEO/ZqMRni/ZnNMeqa7PuUwmfI+plN6G12pwrFIJt+u8x1xOh4/q9XDbde94pZ39Id5jxnkvaefJcu89qiDVWFW3QSyXdSuqRj18Ta8d41R068/+Rda3bml+G6s3rJX1l50W1ubOPUaOXbx4uaznc+F1a8VNd8mxP/93PY9YjYSnt5mZfe7vH5H1fQn6SO7YkWwuTz/Z/MZn6VPE8oWwNlBKNo9f4Bs/AACASLDwAwAAiAQLPwAAgEiw8AMAAIgECz8AAIBIkOqF7d69W9bnzp0r6yrB2d7eLseuXLmy6W2Y6fZsXns3LzGsksFeAngq6u0qyLpKUKYzej/WTSc5VWq2VtP70UzX1V+LKQtTsGZmaZGwNdPvxcys0QhTrCrZamaWEelyM7NqJUygNpxzxUvTZsR7r405yfUxL9Es3rvzp7ZKIpuZqcNYqujkbbX2vKw7u88y2RZR3a+n4SQkVZA47Zw3U1FJX1oSeTpBAvjxfn2MBof/VdaXnvGqoPbmty6VY7Ot+jXvuEOnfUXo3JwAuO3Zo+tT2Ta9q6e83fpSao8/OX6vwTd+AAAAkWDhBwAAEAkWfgAAAJFg4QcAABAJFn4AAACRINUL15o1a2S9UCgEtQcffFCO9Xr4XnjhhbKukroV0TfVzE8Sq96k3jymop/et3Wyp4BEdk72BA6STvAeul0TtN3x57Q9njhOOvaBB3R9YPNDQW3p0j45drHTW73R0M1f16wJY69bntXzwGG0d+Jfgm/8AAAAIsHCDwAAIBIs/AAAACLBwg8AACASLfv372/qCd+WFtXeBzF62cteFtQGBwfl2Oef131zTj31VFlXrdy89m5dXV2ynqTt249+9CNZn0x81nAwjnFOm+edK/zJx4a1Z3aM33z+syZvNYdVe6feaaOiK17BaYm2fduhz2PmbF3fI3IyM2fqsU62w8pOW7r+/rC288jJ5eAAXuyzxjd+AAAAkWDhBwAAEAkWfgAAAJFg4QcAABAJFn4AAACRaDrVCwAAgCMb3/gBAABEgoUfAABAJFj4AQAARIKFHwAAQCRY+AEAAESChR8AAEAkWPgBAABEgoUfAABAJFj4AQAARIKFHwAAQCRY+AEAAESChR8AAEAkWPgBAABEgoUfAABAJFj4AQAARIKF3xSwevVqe9Ob3mTd3d02a9YsKxaLduaZZ9r1118/2VMDppVVq1bZG97wBjv66KMtn8/b2Wefbffcc89kTwuY9r72ta9ZS0uL5fP5yZ5K9Fj4TQGlUslOOukk+8u//EtbsWKFXXvttdbT02O/93u/Z5/97Gcne3rAtPDAAw/YsmXLbPfu3XbdddfZddddZ9Vq1V7/+tfbfffdN9nTA6atZ5991j7ykY9YZ2fnZE8FZtayf//+/ZM9CWhLliyxwcFB6+/vn+ypAEe8888/31avXm2bN2+2XC5nZmY7d+603t5emzt3Lt/8ARPkoosuspaWFisWi3bDDTdYuVye7ClFjW/8prC2tjZLp9OTPQ1gWrjnnnts+fLlv1z0mZkdffTRtmzZMrv33ntt69atkzg7YHq6/vrr7c4777QvfelLkz0V/AdWFVNIo9GwRqNhO3bssO9///v205/+1P7u7/5usqcFTAu1Ws1mzpwZ1H9RW7t2rZ144omHe1rAtDU8PGxXXnmlXXPNNdbV1TXZ08F/YOE3hXzgAx+wr3zlK2Zmlslk7G/+5m/sfe973yTPCpge5s+fbytXrrRGo2Gp1Av/s6Ner9v9999vZmbbt2+fzOkB084HPvABe+lLX2rvf//7J3sq+BX8r94p5JOf/KQ98MAD9pOf/MQuu+wyu+KKK+xzn/vcZE8LmBY+9KEP2caNG+2KK66wZ5991rZs2WKXX365PfPMM2Zmv1wMAjh0N954o/34xz+2f/iHf7CWlpbJng5+Bd/4TSHd3d3W3d1tZmYXXHCBmZn98R//sV166aV2/PHHT+bUgCPeZZddZtu2bbPPfvaz9uUvf9nMzM4880z7yEc+Yn/1V39lL3nJSyZ5hsD0UC6X7YMf/KB96EMfss7OTiuVSmb2wuMWZi/8ksVRRx1ls2fPnsRZxotU7xT2jW98wy677DJbuXKlveY1r5ns6QDTwp49e+zJJ5+0o48+2k4++WR73/veZ9/61rds27ZtNmvWrMmeHnDE6+vrs1NOOeWAY97ylrfYD3/4w8MzIfwavvGbwm6//XZLpVLW29s72VMBpo2ZM2faggULzMysv7/fvvvd79p73vMeFn3AOOno6LDbb789qF9zzTV255132s0332xtbW2TMDOYsfCbEt773vdaa2urnXHGGXbCCSfYyMiIff/737fvfve79tGPfpT/zQuMg3Xr1tmNN95oixcvtpkzZ9qjjz5q11xzjZ122mn2mc98ZrKnB0wb2WzWli9fHtS/+c1v2owZM+S/4fBh4TcFnHnmmfaNb3zD/umf/slKpZLl83l75Stfadddd51dcsklkz09YFrIZDJ222232d/8zd9YuVy27u5uu/zyy+0Tn/gEzxoBiAbP+AEAAESC3y8AAACIBAs/AACASLDwAwAAiAQLPwAAgEiw8AMAAIgECz8AAIBIsPADAACIRNM/4PyXf/mXsv6Lpsu/KpVKtp5sNBqJxitJXzOJtNh23Vkzp/O6Dc23/+Z/BbXHnn7q0CZ2EI6eeXJQS6f1e8lkMrKeToenTSqlT6VUuvltvLCdJMfROQbi/XjbXbfhtgSvd3i0tLRM9hQwpXk/Nr0r4XZmhqUZc/XQfWub3+xRZ8ry/tq9zW/jMOGzhunoxX6emW/8AAAAIsHCDwAAIBIs/AAAACLBwg8AACASTYc7xsbGZL1er4/bZCadkzFppMN/qHphhoGyrCcJcrzLqf9A1HY3vdUXNOphGKfWcNb/XlnU686+S3n71An0JAl3+GNV+IS/cTBNnLpY15+6M9Fmjn79u4Naz9x5cuzaa7+tN7Lr4bDW2ZloHgAOL+6GAAAAkWDhBwAAEAkWfgAAAJFg4QcAABCJpsMd3sP449F1Y6orlypBrdDWLsc+/OD3mt7uaxPOI2mQQ0klWOunnNCHPOSJ/4Twzpsk4Y7mX83rFAJMaSe/PKzl8nrszJfpuuiuZGZW6AivYV29vXJs+ZLflfX+geVhkSAVMKXxCQUAAIgECz8AAIBIsPADAACIBAs/AACASLDwAwAAiETTUcdaTbdmUy3bpkx7LC9x7CQ8h4eGZP273/3noPbON75Jb2PTE83NzczuSVgfD3XRfq6Rycqx3nFUey/tprv1NuqmXzMterylGjqVWG/obWTFBCuj/c78gCng6KN0vVgMa971deF8WX7ZwoWy3tU7J6jl8hk5dv6CubLeM6cnqI2Ojur5HUlmiNq+wz4LYEJMkRUaAAAAJhoLPwAAgEiw8AMAAIgECz8AAIBIsPADAACIxBGX6vWyoyKs6vcR1mFQG+wfbHoe/3zzT2RdhcGmkt17tobFPXpsfsYsWa8WuoNaLqVPpVxanwu1bE6/qDrCdec4OqfZxqfCXPR+59WAKSHrnMwb1oS1uYvl0OO7O2S9t1v3Fe/pDcdX9WXeylX9GVS9v7MqiXykIcGLaYxv/AAAACLBwg8AACASLPwAAAAiwcIPAAAgEk2HO7yghAp3TAa3Y5ga6zyoXKvp1mBnn3JaULv96Sfl2On0TPD2fbudfwjb0j0/Tq95lJ0c1NqP1w+tl0vrZF0FOXRMBUc0p8uZ7W1+EzNP0PU9zyWeTUjNz/tTu+okrFQ7Reeqfd55y2W9s71N1lUeK+OEsdJOm8uMGF5r/rYCYBLwjR8AAEAkWPgBAABEgoUfAABAJFj4AQAARIKFHwAAQCQStGzTidepkupNJUj1ejPOqgSdmc1ftDCojTqp3s3Otnc2MS+Y7bVngtqz28Lagagw5cUHNx1MZa0JxmZ02WscqP4idjLuPrVx70/tVp07P3rO6UFtwaKz5Ng5PT2yns/oy7y6pnst21LezyaoXple+zm4jnfq2w7rLBALPqEAAACRYOEHAAAQCRZ+AAAAkWDhBwAAEAkWfgAAAJFoOtVbr+m4V02keqf6arLR0DOsVnVyudAW9oqde4zedsZpWvtAUzM7MrzxlJcFtUJbuxz7zw/cOdHTCZwnasXDPosj37FOXQVkS85YpwOtOR8fGYQtO2Pbx3Q9kw9rI0581/nIJ0rwzjzO+QdxydzjpItP6Jor652dvUFt6YIw6Wtm1p0Tb9zMGs7vGFTFlVr13jUzS3m/haDCvumqHhuZ2S8Lr5O7Hn9cju05cYasb9t66N3fw+7nL1j2yhOD2nWPbj3k18PUN9XXaAAAABgnLPwAAAAiwcIPAAAgEiz8AAAAItF8uMN5tlfVU1NmPann4c2uPFqR9YooF7rCB2PNzIaf1w/HvkLU1jrzmCr+7F1/KOsLl701qJVTeq92zO2R9c9/658Oel4vRsVMnGfqcQALnLp6dF9He3xdTl1tZ9jbyF5dbt0R1kZEzcxsyAlm9Iln7ate1zJdtl0iOHJcsUWOnb9gkaw3UmFfuq5iQY5tyzqt2er6s1kRw9NOiM+7pstWblPl8j/J3npOGDOrL5gjx678/o8nbB45nRux8z7w50Htuve9f8LmgamDjygAAEAkWPgBAABEgoUfAABAJFj4AQAARIKFHwAAQCQOOdXbqE+NVJcK3HlJtIbzZkZHS7I+VhY5xrxuAlY2neoNs3lmOt9ntt+pT5R3vkpljs3OOu98Wa9nw/5XY2WdiF66XDVQM/s7J9XrBDWl1zh1leDlL5zkvCS06nLmNenyLjBOQNayopY0Mdwtam3O2Lbtuq5Sx84l0O51tqFkW9U7NGvN6z01WAr70mVa9ZGpZ/VeTdV0PdMIX7PutLP0jletIeZS0e8xNtf93y8GtTee/UY5dmQC51Ev6uj63/z9NyfwVTGVcT8EAACIBAs/AACASLDwAwAAiAQLPwAAgEiw8AMAAIhE06neRkNn2uoiIZty+rZOpIbMnemsYUolkc0sndbvcdPmDUGttzVMtpqZ5fX0pkxf3leILPGbL36bHJvrKMh6JhdmJLNjel+nazqBqDPRZs85dWWRU1cJau+4wOwop57kU+ylPr1ksLdttR39SfMvXh2ips4JMz8xPCpqXqp3jVPfrYojsmrlNStlvZEJP2uDA+H1yMwsN2+erOczeg/Wq2E+e6Sk86X9A0OyXhUp4FvveFiO/dzbl8l6TFatWiXrOyfwNZ/c5sTOvTqmPb7xAwAAiAQLPwAAgEiw8AMAAIgECz8AAIBIsPADAACIRNOp3lpNdejU9clI9co8YEpnDesV3Vc2m9MZxHw+7D1Zq+j0W3GWnl2/CPN5/UO3OfUkvKTmJe/83aCWaS3IsbWsPj2yufD45qr6mJdG9HmTJL17glMvOHWVYdSzgJnfH/nn47Dtk5y6l7IdEDWv82uvUy+LmtdL2LtSqWSwNzbJ57j3WT22s/6YrGc7Tg5qD/7wh3Ls6JKzZL2jS3UvNluzLkwHP7xmnRz79Lr1sm4jpbC203mT9jmnPnled+aZsj6vIzxDb737Z3JsJavvG3N75ge1O//9kQSzm1jqHlFwxo7HPQlTB9/4AQAARIKFHwAAQCRY+AEAAESChR8AAEAkEoQ7vJZtKlSht5FyGzsdOtmyzZnH5k3qEXKzZYvPkPXlp4etkFbf+iM5dpPuyGQ9olbSQ10qN3LG0TrGcfGFb5X10aGw9dLwZr0/Wnt0C6jh0cGgNjasmlyZVYf0tpPQj6z7AQHFax2GibUlYf0UUZub8DVLoqYCH2Z+q7mCqHnt3XoSbFvHLMxanbRT5rlnglppQH/WBjZtkvVVed2w8KFNm8PiiN627dun60e4Sy5/t6ynBsPgS7lckmPnnqNb0a1fL47HFAp3LDrx1KB25bsvlmN/dIu+3/UPhedLPa3Pt5rT9DBbFdGrho7jjZR1c7uS2EQ9o++Nz+/24myhk07T8bSM08K2UhqT9bS4GMzv7ZJji3l9t9o4OBzUammvoeWB8Y0fAABAJFj4AQAARIKFHwAAQCRY+AEAAESChR8AAEAkmk/1qvSu6VSv37FNbyNJ2rfR0GMboj1bKqXfXrmkM379G3Vbok2ZcHy1qlNHOnOk20s97YxVyUYz3XYql9bvcc2Dq2S9b1P4qgudxHabaDlkZpbKhU20RgbCtLCZWdFplvUqWTV7SNS8NKVHtfiauDw5xlOfqC1yGxDqdJ66/Hgt+3TjRZ0C15+SZOenzjuaFZ26es3Cdn2VKW/Xbd90ztDs9SceHdRKczvl2E0N3Tjv+SfC1P5RM709NfX09PTIev9g2LpuZFBf487t0bnztq5w26VRvW+qY/oMPX3R6UFtxU03ybFPPL1W1j0PbH0qqC0491w5dtT5CYXN/eHxT2f02VxT6V0zq46Gn8LqmE6Xp5w2olWx6Kg5y5tGVidh6+nwU59z1hAZZz2Ude7HGTGXfF6PzTtB3blqrdX8Eu4//XcAAACIAgs/AACASLDwAwAAiAQLPwAAgEiw8AMAAIhE05GQet3r1ZsgweX0t/NTwGqs2wg4UHOSQV1OtK676KR9qpWgNjams3KvatHbru0PazP0UDeBulXU8jt0c+DRHTozvOClJwa1Qpt+3yNDopenmeUKhaCWruqkdDar+w7mZzk7ane4o7wzLEld5/Ew1RRErdGiP/MZ8Zky0xc1r6+z1+lSXSK88208/nr2tqHmnXQeXq/j1q1hOri/pBPDjY4wAWxmln9VuPV6w8sRT0F1nTStlMKk6fBgvxy7fmPY19fMbN6ihUHtw5+8Uo4t5guyvnBu2C99UW+bHPuxD39E1p/b73xQhCv/9H/J+if+/ApZ75gXXvczWX2DrVZ0cnndutVBzdvX3e36vbe2hq9ZdZK3+YLeRjYXftrWb+6TYzf16fk1cvqKkhLza3Xey7x2nYrOiV8uscrBfdb4xg8AACASLPwAAAAiwcIPAAAgEiz8AAAAInHI4Y5aLXxg0wtgpNO6rsZXRaDCzA9VVGrh+PKgDiec3qYfPs2bfs2GaFeUclqzLF36G7K+fv3qoNbh7P0Ht+mHccNYhlmXfubaxpzecZlceBy7e3TTqWxOH69GNTwG3r7bsDpsfWRmVncTPfuCin782j951fjVztgjyWxR0w22/ABAh6jp+I0ffFBHzgvPPOzUvWOn5je4f48c67VKU9vQDcf8Vm5JeGEstV+9952kpaD3XjyFBK95i86K2WNPOxeUpx9NOJupxQsRbFwfXrdGd+jr8qbN+j7T2hGeoaMjw3JsTrQLMzNrjITbTo3q1qLnn66vBtc/9Kysh1das9v//XY59t7f1PULL/rNoNYrAilmZp3dPbJeF1eUQlF/uvMZfe/OibPZu65VndZ7I6VwX6+/42459t5HdHu8Hc5rKiccpQOOv//mt8n66Yt6glqptCnBK/4/fOMHAAAQCRZ+AAAAkWDhBwAAEAkWfgAAAJFg4QcAABCJplO91aqXrQx5CeAHHljp/Bc6tTdRTp8/R9bbWnVebrQi3rvT6mfTxkFZL5XCRFjv3OPk2HOK+rC0F8JE07CTXG7N6QTaxk3bgtrQ2A/k2EKH3k8ZcdrkUnp/1Ks6xVbsKMi6PbU9KOktmIUNkV6gct86m3Vk2SVq3qfSq3v7UtENhXQ7My9B15Pg9czMwkZZ+niamXU7dS/prOgsuv6L2EveeglqlRhOmupV2/b+Wm/6Yv4f1Px0k8vpa9X3rpX1v/3xI01vY2let9iqNcQRcdqINVL6LMq0hp/Ctoy+T2Wd9l1nnHSCrN+35TlZV7w79I0//rmoqloyMxOOVxngLvUzCGb6QmpmfaLmJei9a6PXGlJdd5/bq+/R//vG7+uN3BiWLn3jmXLo5c48foFv/AAAACLBwg8AACASLPwAAAAiwcIPAAAgEiz8AAAAIpEgCKbXiP2bNwa17c9vOdj5HBbd8xfJek+bzuSsXhVmQmsl3f9wcxiaNTOzoogpFYuqq6hZNq+7pFYGwh6DDZEWNjNL65aGlsvPCmrlsu7DObJOJ9uymbDHYNaJP2XSen71+lH6PxD6mh75ApWb25twG0e6JH2MvbFeH9uSqHmpVG/b3l+c6jW9bXvza/73B5LPTyk7dZVQ9voLe6noJPNIuj/UfvVSztPV5jvuk/VXiFr9hGPk2Pa2LlkvFsLre5vTJ95L9ZroTVsa1dnr1qy+b5y3+CxZX39dGBPVv+Pgn599oqbOe7Nk12AvRay72+prUt5J73rJdbX3vP3h9TFvP17nkVdvC9+R97nUXYC1vnUDCUb/P3zjBwAAEAkWfgAAAJFg4QcAABAJFn4AAACRaDrc8cgjdzj/sm98ZjIB9KO4ZoV23ezJe+izfUH4cGxm4yY5tqdekvUzlobbyOV1mKS/X7dhm79wcVDbkNZtenLOg77VenjIK3X9zquqVZ2ZVSrhMc9l9UOtaeex4ErNO/V2BJUnnJHeQ8QbnPp0NHcctuE9qOw90K3OijB29AKvnZlucqV54Q5v3t5rJtm2+os4aas0FZTwXs/b12q89/68h8W98Al/9ZvNf9tvy3pvKjwirR26GeBYWu/JsbFSUGtv19f8RkOfGcMj4cP76bxO0s1ffIasF+fq5pbLTghbdS4o6vBJbUgHAOeEl2v3upwkBJX0M68+a9757TWqU4GeBS+dIcfOcfZ1Z945R74SBmnqetO2NsGS6uEtBxek5bMPAAAQCRZ+AAAAkWDhBwAAEAkWfgAAAJFg4QcAABCJBC3bpm5617P8ZafKekeXbrHz9v/6Xlm/+KKLg9q5b7tMv2hDN04qFgpB7d5773Lmp1PHxXlLglpbRie8unJ6Hv0b1gW1RkmnegvtOnvZ3x/2pRsZ0k12Otq9FkVejrF5XopxuqZ6VQis4Iz1/qJT43XO0E/qqhSedyFxOge683te1I5NuA2VevVSgl5CViUQvfPN2086m69570U1dUzaYi9JW7rYvgko9zpNudLhXit29cih2ao+i1oL4ScrldJ7OOXs+VI9POuKc+fLsV3z9Ce5tU3fTy648MKgtunen8mxHb36Vxvm5MNPeP+gvp+Uh3X7zn7xoS/Jkcl+acA7l71moeqztvS8N8ux3YuXynrG+RC2/jBMUDec8+nlw3ojj20J28QebIvF2D7nAAAA0WLhBwAAEAkWfgAAAJFg4QcAABAJFn4AAACRSJDqbZ7Tgs41UXnh2x5/StavqOmugZ2z9e5Y8ePvB7W3vfkbcmzO2aP1athTd+Gi0+XYr17/HVm/87s3h8WZJ8uxf3Rx2NfXzKwt3x7U1jyou+EO79ol6ypH7KUmx7LbZX19GAxOzEtkPnnom56S1OdkozN2gVNXZ77XW3OFU1f57ZcknEeSNJrX19dLDKtMnNeH20vqqoRfwRk76NR3i9pjzljv8xPmLvXn70B17z2qY+D1U52uOtt1qnd0LDxjqmN6T5bG9F5LZ8MMaq2uz9pMTtdbRc/1QkH3gy2kdao35ySJe0WiedOqW+VYE79KYWbWvWBeUEu36Zx7/2r9ewv1VJj27XJO5op34RAf+rL6AJpZOOMXzDkurHXP0QnqXFH/Mkja+yR3hscsM2+RHJovON/HbQn7/S466Rg99kXwjR8AAEAkWPgBAABEgoUfAABAJFj4AQAAROKQwx2qkUuPMzaMN7xg66FOwrHTqQ9s1s2Urv7Ih2X9e9++PqiNlkpybMNpt7Zo4RlB7frLddu3O58OW7O49jwjy4tP1+3niqqlnNP2bdMGHR0YHQ2PZKW2Q469wwlxeMdGmeXUvYfqY+K16fKege4TtUfHYR7eGbvIqYcRoxeoqNI5px4vx85bqqIPZlYNH8IfG9Jni1fvKoYPaRd69KzzP7xPz0N3MZS8c1nFBrywi1cvOXUVVdjrjJ2uVq5cJev5XBjMGHK+Jhkc1Eevczi8F4z06PtDR5cObFhbeIuup8LAh5lZw5lfqqajTSOD/UFNb9lsrKQDLOvWrw9qhYxurFbI661n28P7T9HZT9WyDtiMlcLakHP/6tym46QjIodYKw3LscWsvmfWKno/DZXDK3Jve68cu+a2O2Rdmd9VaHrsr+IbPwAAgEiw8AMAAIgECz8AAIBIsPADAACIBAs/AACASBxyqle1NsrKrK9ZNUnMbQLdccdtsn7huefI+oI5ImFU1mmf3k7dKq1WLgW1gXXr5NgTZNXsD37rDUGt20mDlYf6ZL1/NGzQ1dal2890dOpkVWm0FNTGSrpNz6033yPrSeijYjZwyFs+8ulme379cPNayulGSLqd0nC/joZv2qzbJooOUO6FzmtRdpfa7kCYgjQzK+WdJpV7mm9G+bxTV78/4LUq9BLeXmI4f6wo6nD+tDU8rK9b1hFmpLMZ/T2JSgCbmdVEm86hgT45dnRUz2O0K7zDznXaiNVEctTMrLVdt3IbqobJ9WpFv8cH1+rfYUiJ32fo0bd/a1eLBTObe/qioNZ5um5nWujQ96S6aOD44Ardfq5nQ5hENjMbXPd4UNu4Ro+dd+7vy/qmfn0c+54MP1gdTlJ699ZNsq7UvF6PL4Jv/AAAACLBwg8AACASLPwAAAAiwcIPAAAgEiz8AAAAItF0qvcYp64SZqNOetdL0E2U45z68IjOg9579y2yXhdJ2MWLF8qxuZJO5Nx7R5gTvPAcnVz6xNIlsj5aC/sUDgzqdHFpzNnb6bDHYHdR9yD1+pj2bw6zmj+7f60cKwKWB3SaqOmuiGYPJ9w2knnl771T1h+95Y6wuE133H7S2bZXl6ZIA9mZz+qJdJ96kv4Ptm855Nf8qZqHM9bp9ur2X90QWYJXmTdP90vNt4ZXndERndjsEclbMzNLhd+r1EzHMLNZfSsuj4bX93pNJ1srDSdd7HRxPv+Sdwe1723SfewbT+mO3gvFydjuxHpbu/WvR/TMD++lxW6dXG7r6JH1MZGgXnDOuXJsY9EZst65/t6gpn6Nw8ysXtX10WF9z1S/bjDyg+/IsX7GP3TBm9/a9NhfxTd+AAAAkWDhBwAAEAkWfgAAAJFg4QcAABCJpsMd3uOGqu4FQZp/ZHF8LDhJz6Sjs0fW0xaGJ8zM2gphy5tcQzdOWn3bj2R9YEP4eOfcuYvk2ExWxxnKIrBRz+h2PMXeHllfuPisoFYaCcMrZmabNuuHmVet3hDU+uTI5NRjt16LquYbYuFgpCvhA9NmZrPSYWuo3RM9mSnAazj55FOHHuIYj3nUTj1a1vPFgqzve+Dwznsq6uzWkZj+/jDkkMro22U+r+MzrfmwjVgtpcMdrUUdwEiJq1+9rIN7dSfcscZpO1YdCYMjyy/RrciyY38u62N9u4JaW0+PHDvqXMkzOdEezwp6G5tHZX1T/8qwNqKbGJYb+p5Zqobfg1X6+uTYVicI2uacC5e8IuyP+I9rk6WrTpgVbqNnrtf88sD4xg8AACASLPwAAAAiwcIPAAAgEiz8AAAAIsHCDwAAIBJNp3qTONzpXTPdni2T04mthQuWynoxFaYVzcyqA2HCa2SoJMeuW79a1ufOnysmqFNY/SN628WuOeEmnIZmuaJujzNQDtf6/YM6JXbvBt3arpFvC2r5Pbpll5f2PNupqxyxzsFholUHdIJu99BkfMIn31FHzZD1vXsPc758VossP/vUzkR1mI2V9C8a5PJh8rPhfU+S0rfRjs7w/pPKOQ0o03rbdXHxq9Z0OnZwQP8KQ6qhr6Dlani/6+wMr+1mZvPm6/ToDx55IKjd8tMn9OvJqtn8txaCWvc83RJ1dEDfk/r6w/3aKOik9NzuBbL+sY+ELdSefU4n35eep+/dPTl9Lrz14vOC2oq135Vj9Z3UrOf0cN739ukWccucbfwC3/gBAABEgoUfAABAJFj4AQAARIKFHwAAQCRY+AEAAERiQlK9k6FgYeKuUtYp3bGK7uG3dPm5sn738E1B7YfX3yDHLlqm8zTzznpzUCuN6IRSvrVD1q21PSgNDZbk0AEn7ZPNhr0ER5wUcUr0UDQzK3b2BrU123UWaZasmunMsZnK2IVdjnE4PHb/fZM9hXFz7Em6j+3SxYtlffkZYb29Q/9KwA/vuFvWN/aHKcv+IZ283Dmm+yKbulbtiDNVPRHSg+EvNpiZ5fPhta/spGnnLNIp0TaR8CzX9D3JuxWXy2H/+MFhnbYfHdV171cR2jvC+8nosD4/GzXdxz51fFi78vL3yLHfWaH7217/s1uDWqld3yE2bFwn6w8/vCqoNSp6n2762rWyrhK8r//N18ixfRW9rzNh+2MzM2vLhingj/2XV8uxf/QvYVLazKw+Et7TR0e8rPSB8Y0fAABAJFj4AQAARIKFHwAAQCRY+AEAAESChR8AAEAkpk2qd84pYRK2UnV60N4VpojMzOoNvTu6550R1PIbdfrpnD/4mKx3LJoX1Gqb1sixIyM64Tc8GCbChoZ1SqzY0S3r7W2FoJbN6P6R7a1hAtjMbMNdYTpLZ77M9Cz88eoVnaAUjgAvf82rZD2b1edctRqeGbW6Plu6e3T6vUukFYt5fS53d4Zjzcw6xeekUtWfy1RdX2fGSuE1Im36FwVmpXRidLeTJMU4EUlJMzMTfWwL2bwc2prS35+MDYdXrnJdH//WYkHW0yKT21YM+wibmRVa9WeqUnF60I+Fv6FQb+hzOZ3T771cDH+34fS3/74cW+8J74FmZg9u7AtqAyO6h3Kb+GybmS1cEt6ji3l9fThnmb6eDIj7cSOrM9GDYyVZHx7Q14g3Lw1/JWDxGbrf7//o3yTrNzz0VFArb9ZjXwzf+AEAAESChR8AAEAkWPgBAABEgoUfAABAJKZNuCOfFw9KVkty7ODT4UOSZmZ3lb8n6609i4La3EW61dOtD66X9Q2itUq6oR/09VbjA6I9W7FdP8A6f55+kLatPWxFNFbS7WfWjOoAy1Bf2ERNN3czc5rPmffIunrcdaczFuOj5QTRd8nMerr10Tt90cKgdtYZ4cPVZmaFgn4QfWBAtytcee9KMbZPjh0Z1NtYv+7BoFat6wfcG7ZX1ov58KH1bE4HRB7fuF3WzSlj6sjkdWih2BGe+/mCvsr1DeoggqXDq1nNu/Jl9eekraMtqKXS+rZdcq7j1up8BjeHQYSMc08aHHRauTXCz0TJ6T5YbejwSbEY7uuUszRpzeq742AqfI+ZnA6C5NM6sDG8ObyvtRcKcmzDCfpsdlqlDjTC7Sydq+fX0a5fs992BLW8CJA1g2/8AAAAIsHCDwAAIBIs/AAAACLBwg8AACASLPwAAAAiMW1SvZVKmEZqb9PJm9Vbd8l6Yds2We/oDdNSIwMb9ETGdKQpnQqTRO1Om56xmk4g9szvDWqLFoYJSzMza+jkUlVs20tsbVivW8oNP/tMUNN5x+QnmM6UReb4U3R5Tk9Qy2eclNtQn6zXRbO8Qk6n7dIZfQ5lRb1W1+d9o6HbErUW9BnTWgjnUuvTLZZKozpNOVR6PqjtT5iwfd52i6qq4UjWPXeBrBfbwjTthr4+ObZ/WKfLVfOzdF5/1hY594KhDeF9JuOkejsK4ZzNzKpl3YatNRV+Nkf7Nsuxmzc/LeulSktQG94cpurNzOo1PY9GI0w6j43oRp3Zin7vubHwGjE2pt9Le1eXrFcq4TYGB/U8ynV9zyy266TuwFA4vj+lr4EdTnp8v4XHYGidvke/GL7xAwAAiAQLPwAAgEiw8AMAAIgECz8AAIBIsPADAACIxJRN9c5IOH54tBTUerq65dj59pysb3K23dEf9t/t1OEde/Den+l6KlxjL156nhz79is+IOvLzl0W1NLO2r1UKsl6pRrmZjPpTj12LHw9M7O+234Q1Ea3hX0Ezcx0l0j/xNM5rMhs0wm6bdvC9OC2o5y/3fbuafrlvMCrV39y3WNBbUX7sXJsu9NL2uvhW6+HieFUViche+bNl/XOVHiOD3k9LXXo2Oq1MGn43CZ93TCvXaY6yb34u9e8Wv8AAcbJ3Q+H/VnNzNLp8G5w7+qH5dh8Qd8MuheF5+fYmE62Vtesk/XeYpjwHO7vk2PHenpkvdXp1VsdKQW1B2/4uRw7qn/wwoZsf1BbdcsNcmy6Q9+Pa6lCuF2n//HmcknWC8XwPeadpHSpVV8zs63hdSbbqhO2mbrz+xMVPe9KpRTUBht626mUvt4dJWrlsYO7QPCNHwAAQCRY+AEAAESChR8AAEAkWPgBAABEYsqGO/Y59ROd+vCO8CHHDZv65Njlb3yFrGfuWCvrq7eGrZqKGf1E99vevFzW2xaErdWWXvAOObZn4SJZT7JMb+/Q7XsaFj4839GuHzLduKFP1jeIIIc3Nf2Yqj++36kfupkTtuXDZ29TpQkXdkSzHc/rcM+OJ3V9ypstarqDnX8VbQvbWVnGSZOknfrgzubnUdDn+AkFve2R4XDb+47Qw3WwHnaucf394ZVoz05x4pvZjGN1S8G0CDY9ctdtcuxpZyyR9XImDHTVSjpAUBXBPTOzvHN9718XBko6CkfLsY2qOA/NbECUb7vlHjm2e+6grLd2zQtqpVHdArI8qu+7jXTYhq3QXpBjxyphC1YzM9HBzjY7QZp0TX8I81Ud3rF6KSgNOteCMxbpc2HRt8L92tPrrYgOjG/8AAAAIsHCDwAAIBIs/AAAACLBwg8AACASLPwAAAAi0bJ///6w5woAAACmHb7xAwAAiAQLPwAAgEiw8AMAAIgECz8AAIBIsPADAACIBAs/AACASLDwAwAAiAQLPwAAgEiw8AMAAIjE/w9j/EgyS/eBywAAAABJRU5ErkJggg==","text/plain":["<Figure size 800x800 with 9 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","figure = plt.figure(figsize=(8, 8))\n","cols, rows = 3, 3\n","for i in range(1, cols * rows + 1):\n","    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n","    img, label = train_set[sample_idx]\n","    img = img.permute(1, 2, 0)\n","    figure.add_subplot(rows, cols, i)\n","    plt.title(label)\n","    plt.axis(\"off\")\n","    plt.imshow(img.squeeze(), cmap=\"gray\")\n","print(f\"input shape {train_set[0][0].shape}\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"twX_vCwuNAKn"},"source":["**Вопрос:** на что влияет аргумент num_workers в DataLoader? Каким его можно ставить?\n","\n","**Ответ** num_workers - количество потоков, которые загружают батчи в память. Это ускоряет обучение сети потому, что перенос данных - значительная часть времени обучения. Его можно выставить каким угодно, но при значении боьше чем количество хартов компьютера они не будут радотать по-настоящему параллельно. Если память компьютера являетсся бутылочным горлом, то повыышение num_workers не ускорит программу."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"IdHuE97-DHSj"},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","2024-11-10 15:52:00.050411: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-10 15:52:01.399222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type             | Params | Mode \n","---------------------------------------------------\n","0 | model | DenseNet         | 83.9 K | train\n","1 | loss  | CrossEntropyLoss | 0      | train\n","---------------------------------------------------\n","83.9 K    Trainable params\n","0         Non-trainable params\n","83.9 K    Total params\n","0.336     Total estimated model params size (MB)\n","554       Modules in train mode\n","0         Modules in eval mode\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ccb29d87e7b497ca14d07b5411a1fc4","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/azor/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"]},{"ename":"RuntimeError","evalue":"Given input size: (48x1x1). Calculated output size: (48x0x0). Output size is too small","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# здесь только пробный запуск\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# очевидно, вы должны изменить параметры limit_train_batches и max_epochs\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# когда будете делать более сложные эксперименты\u001b[39;00m\n\u001b[1;32m     11\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(limit_train_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model_pl, train_loader, test_loader)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    540\u001b[0m )\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39mckpt_path)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_stage()\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1052\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1049\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m val_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39m_call_strategy_hook(trainer, hook_name, \u001b[38;5;241m*\u001b[39mstep_args)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    322\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:411\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","Cell \u001b[0;32mIn[16], line 20\u001b[0m, in \u001b[0;36mConvModelPL.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m     19\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 20\u001b[0m   pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[1;32m     21\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(pred, y)\n\u001b[1;32m     22\u001b[0m   \u001b[38;5;66;03m# Calculating accuracy\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","Cell \u001b[0;32mIn[3], line 42\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 42\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks(x)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# We don't want to flatten batch\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(torch\u001b[38;5;241m.\u001b[39mflatten(output, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/torch/nn/modules/pooling.py:756\u001b[0m, in \u001b[0;36mAvgPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mavg_pool2d(\n\u001b[1;32m    757\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,\n\u001b[1;32m    759\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding,\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mceil_mode,\n\u001b[1;32m    762\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount_include_pad,\n\u001b[1;32m    763\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisor_override,\n\u001b[1;32m    764\u001b[0m     )\n","\u001b[0;31mRuntimeError\u001b[0m: Given input size: (48x1x1). Calculated output size: (48x0x0). Output size is too small"]}],"source":["# а теперь можно запускать обучение и смотреть метрики и графики\n","# просмотр графиков вы должны вставить сами\n","\n","# чтобы запустить на маке\n","# напишите device='mps'\n","device = 'cuda'\n","\n","# здесь только пробный запуск\n","# очевидно, вы должны изменить параметры limit_train_batches и max_epochs\n","# когда будете делать более сложные эксперименты\n","trainer = pl.Trainer(limit_train_batches=100, max_epochs=20)\n","trainer.fit(model_pl, train_loader, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"aEUZsAL3GsML"},"source":["Попробуйте получить хороший бейзлайн по рекомендациям выше.  \n","После обучения модели подберите гиперпараметры и, если вы этого захотите, немного измените архитектуру модели так, чтобы добиться более высокой метрики."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QltavClgHIVx"},"outputs":[],"source":["# что вы можете подбирать: оптимизатор, scheduler, learning rate, аугментации,\n","# weight decay, тип инициализации\n","# <your code here>"]},{"cell_type":"markdown","metadata":{"id":"b2IiIqFpMf_W"},"source":["## Transfer Learning и Fine-Tune"]},{"cell_type":"markdown","metadata":{"id":"yiOycRqMEk3x"},"source":["Для многих прикладных задач не существует больших датасетов с хорошей разметкой. Поэтому распространенным приемом является тренировка на похожем, но большом датасете и доучивание сети на целевом.\n","\n","Такой прием называют **Transfer Learning** или **Fine-tuning**.\n","\n","В сверточных сетях для классификации выделяют две части:\n","1. Тело сети (backbone, feature extractor) - это набор сверток и пулингов (convolutions and poolings)\n","2. Голову (head) - это MLP (набор полносвязных слоев) после которых делается softmax и получаются вероятности разных классов.\n","\n","Вычислительно простым вариантом finetuning является переучивание головы сети. Также можно фиксировать какие-то первый слои"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-dQYLDsDh4o"},"outputs":[],"source":["from torchvision import models\n","\n","model = models.resnet18(pretrained=True)\n","\n","# кроме torchvision очень известен репозиторий pytorch-image-models\n","# !pip install timm >> None\n","# import timm\n","# model = timm.create_model('resnet18', pretrained=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWB9hYj6GtCt"},"outputs":[],"source":["# заморозим слои\n","for param in model.parameters():\n","  param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4f6-sQ9GryD"},"outputs":[],"source":["# 10 - число наших классов\n","model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n","# теперь requires_grad=True только у model.fc"]},{"cell_type":"markdown","metadata":{"id":"O9FVdZ_uA1gV"},"source":["**Вопрос:** почему нужно использовать lr warmup для fine-tune предобученной модели?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gB-fxutNWqf"},"outputs":[],"source":["# осталось лишь заметить, что пайплайн обучения уже написан - он хранится в model_pl\n","# вам осталось его только запустить\n","# проведите несколько экспериментов:\n","# 1. Дообучите только голову\n","# 2. Дообучите всю модель\n","# 3. Поменяйте пайплайн аугментаций с вашего на тот, что использовался для предобученной модели\n","# 4. Откусите голову и обучите SVM на данных, полученных из feature extractor'a. Попробуйте с аугментациями и без них.\n","# Такой подход сработает, ведь feature extractor можно рассматривать как функцию, которая отображает данные из одного пространства в другое,\n","# где эти данные линейно разделимы\n","# сравните результаты между полной сетью, сетью с дообучением головы и сетью с SVM. Где результаты лучше и почему?"]},{"cell_type":"markdown","metadata":{"id":"2W2AIPlp93_b"},"source":["**Вопросы:**  \n","1. Какая разница по качеству между обучением всей модели и только головы? Как вы думаете, какие преимущества у каждого из этих подходов?\n","2. Какие зависимости вы обнаружили между различными значениями гиперпараметров и процессом обучения модели?\n","3. Прочитайте раздел Loss Functions [отсюда](https://cs231n.github.io/neural-networks-2/) (можете и другие разделы). Как вы думаете, почему нельзя обучать классификатор на MSE?"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPaVIzsVCrg+zgqrZqYExN+","provenance":[{"file_id":"1-QsqbFnU1KhIiKO6ERjanY825JUSZwiK","timestamp":1727991278398}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
