{"cells":[{"cell_type":"markdown","metadata":{"id":"cX_WL9cbbJas"},"source":["# Домашнее задание 2.2. Обучение сетей на Pytorch"]},{"cell_type":"markdown","metadata":{"id":"JMCFXAYFNpFx"},"source":["В этом задании нужно:\n","1. Написать свою сеть на Pytorch по варианту\n","2. Обучить ее и сравнить результаты с дообученной сетью из зоопарка моделей\n","3. Поставить ряд экспериментов, показывающих насколько гиперпараметры обучения влияют на результат"]},{"cell_type":"markdown","metadata":{"id":"qHaLl3E5cwy_"},"source":["**Варианты архитектуры сверточной сети:**\n","Вариант на ваш выбор - напишите его в чат. Не более двух человек на один вариант\n","1. Resnet v2\n","2. Inception Google LeNet\n","3. MobileNetv2 (Коростинский, Глаз)\n","4. SE Net\n","5. DenseNet\n","6. Conv Mixer\n","7. RepVGG"]},{"cell_type":"markdown","metadata":{"id":"3bWCyebM5HCh"},"source":["## Имплементация сети на Pytorch"]},{"cell_type":"markdown","metadata":{"id":"8_rU_f5-5L3D"},"source":["Здесь вы должны написать модель, выданную вам по варианту.\n","Для этого нужно:\n","1. Не забывать про использоватие блоков nn.Module, nn.Sequential, nn.ModuleList\n","2. Использовать материалы из предыдущих семинаров\n","\n","В качестве примера ниже реализован макет для модели, состоящей из блоков."]},{"cell_type":"markdown","metadata":{},"source":["## Архитектура Dense слоя сети DenseNet. \n","В нем все  признаки с каждого слоя конкатенируются и передаются во все следующие.\n","\n","![image.png](DenseNet.jpg)"]},{"cell_type":"code","execution_count":122,"metadata":{"id":"RjMhL5bcagsR"},"outputs":[],"source":["import torch\n","from torch import nn\n","from collections import OrderedDict"]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[],"source":["# Input: (N, C, H, W) tensor\n","# Layer: combination of (BN2D + ReLu + Conv2D1x1 + BN2D + ReLu + Conv2D3x3) layers\n","# Arch: each layer l accepts k_0 + k * (l - 1) feature maps\n","# There is a bottleneck in each layer: each Conv2D1x1 reduces number of chanels to bn_size\n","# This is needed because first convolution might have high num_input_features \n","#   because of data from the previous layers:\n","# Example of how C changes throughout the network:\n","# \tlayer 1: (input) -> (bn_size * k) -> (k) \n","#\t\t \t\t|\t\t\t\t\t\t |\n","# \t\t \t\t|\t\t\t\t\t\t V\n","# \tlayer 2: \t--------------> (input + k) -> (bn_size * k) -> (k)\n","#   layer 3:    (input + k + k) -> (bn_size * k) -> (k)\n","\n","class DenseLayer(nn.Module):\n","\tdef __init__(self, num_input_features : int, bottle_neck_dim : int, num_out_features : int) -> None:\n","\t\tsuper().__init__()\n","\t\tself.bottle_neck = nn.Sequential(OrderedDict([ \n","\t\t\t('norm1', nn.BatchNorm2d(num_input_features)),\n","\t\t\t('relu1', nn.ReLU()),\n","\t\t\t('conv1', nn.Conv2d(num_input_features, bottle_neck_dim,\n","\t\t\t\t\t\t\tkernel_size=1, stride=1, bias=False))]))\n","\t\t\n","\t\tself.conv = nn.Sequential(OrderedDict([\n","\t\t\t('norm2', nn.BatchNorm2d(bottle_neck_dim)),\n","\t\t\t('relu2', nn.ReLU()),\n","\t\t\t# Pudding is needed in order to match concatinating outputs\n","\t\t\t('conv2', nn.Conv2d(bottle_neck_dim, num_out_features,\n","\t\t\t\t\t\t\tkernel_size=3, stride=1, padding=1, bias=False)),\n","\t\t]))\n","\t\t\n","\tdef forward(self, input : torch.tensor) -> torch.tensor:\n","\t\tbottle_neck_output = self.bottle_neck(input)\n","\t\treturn self.conv(bottle_neck_output)\n","\n","class DenseBlock(nn.Module):\n","\tdef __init__(self, num_input_features : int, num_layers : int, k : int, bn_size : int) -> None:\n","\t\tsuper().__init__()\n","\t\tself.dense_blocks = nn.Sequential()\n","\t\tcur_num_input_features = num_input_features\n","\t\tfor l in range(num_layers):\n","\t\t\tlayer = DenseLayer(num_input_features=cur_num_input_features, \n","\t\t\t\t\t\t\t   bottle_neck_dim=bn_size, \n","\t\t\t\t\t\t\t   num_out_features=k)\n","\t\t\tself.dense_blocks.add_module(f\"denseblock{l}\", layer)\n","\t\t\tcur_num_input_features = (l + 1) * k\n","\t\t\n","\tdef forward(self, input : torch.tensor) -> torch.tensor:\n","\t\tprev_features = None\n","\t\tfor layer in self.dense_blocks:\n","\t\t\toutput = layer(input)\n","\t\t\t# dim=1 is a dimension of blocks\n","\t\t\tif prev_features is not None:\n","\t\t\t\tinput = torch.cat((prev_features, output), dim=1)\n","\t\t\telse:\n","\t\t\t\tinput = output\n","\t\t\tprev_features = input\n","\t\treturn input"]},{"cell_type":"markdown","metadata":{},"source":["Архитектура была взята из оригинальной статьи (после кажой свертки стоит BatchNorm и ReLu):\n","- 7 × 7 conv, stride 2\n","- 3 × 3 max pool, stride 2\n","- dense layer x 6\n","- 1 × 1 conv\n","- 2 × 2 average pool, stride 2\n","- dense layer x 12\n","- 1 × 1 conv\n","- 2 × 2 average pool, stride 2\n","- dense layer x 24\n","- 1 × 1 conv\n","- 2 × 2 average pool, stride 2\n","- dense layer x 16\n","- 1 × 1 conv\n","- 7 × 7 global average pool\n","- fully-connected, softmax"]},{"cell_type":"code","execution_count":128,"metadata":{"id":"Tp_igxkE6BnN"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, num_input_features : int, num_classes : int,\n","                 init_conv_num_features=24, k=4, bn_size=16, compression=0.5) -> None:\n","        super().__init__()\n","\n","        self.blocks = nn.Sequential(OrderedDict([\n","          ('conv0', nn.Conv2d(num_input_features, init_conv_num_features, \n","                              kernel_size=(7, 7), stride=2)),\n","          ('norm0', nn.BatchNorm2d(init_conv_num_features)),\n","          ('relu0', nn.ReLU()),\n","          ('maxpool', nn.MaxPool2d(kernel_size=(3, 3), stride=2))\n","\t\t]))\n","\n","        dense_sizes = [6, 12, 24, 16]\n","        dense_input_features_size = init_conv_num_features\n","        block_num = 1\n","        for dense_block_size in dense_sizes:\n","            self.blocks.add_module(f\"dense{block_num}\", \n","                DenseBlock(num_input_features=dense_input_features_size, \n","                            num_layers=dense_block_size, k=k, bn_size=bn_size))\n","            \n","            conv_input_feature_size = k * dense_block_size\n","            conv_output_feature_size = int(conv_input_feature_size * compression)\n","            self.blocks.add_module(f\"compress{block_num}\",\n","\t\t\t\tnn.Conv2d(in_channels=conv_input_feature_size,\n","              \t\t\t  out_channels=conv_output_feature_size,\n","                          kernel_size=(1, 1)))\n","            \n","            self.blocks.add_module(f\"norm{block_num}\", nn.BatchNorm2d(conv_output_feature_size))\n","            self.blocks.add_module(f\"relu{block_num}\", nn.ReLU())\n","            # last pooling is 7x7\n","            if block_num != len(dense_sizes):\n","                self.blocks.add_module(f\"avgpool{block_num}\", nn.AvgPool2d(kernel_size=(2, 2), stride=2))\n","            dense_input_features_size = conv_output_feature_size\n","            block_num += 1\t\t\t\n","\n","        # Classification\n","        self.blocks.add_module('globavgpool', nn.AvgPool2d(kernel_size=(7, 7)))\n","        self.classifier = nn.Linear(dense_input_features_size, num_classes)\n","\n","    def forward(self, x):\n","        output = self.blocks(x)\n","        # We don't want to flatten batch\n","        return self.classifier(torch.flatten(output, start_dim=1))"]},{"cell_type":"code","execution_count":129,"metadata":{"id":"kPncPqPp_A6a"},"outputs":[],"source":["# если вы написали модель правильно\n","# эта ячейка должна выполниться\n","num_input_features = 3\n","model = Model(num_input_features, num_classes=3)"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[{"data":{"text/plain":["Model(\n","  (blocks): Sequential(\n","    (conv0): Conv2d(3, 24, kernel_size=(7, 7), stride=(2, 2))\n","    (norm0): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu0): ReLU()\n","    (maxpool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (dense1): DenseBlock(\n","      (dense_blocks): Sequential(\n","        (denseblock0): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock1): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock2): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock3): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock4): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock5): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","      )\n","    )\n","    (compress1): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1))\n","    (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu1): ReLU()\n","    (avgpool1): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n","    (dense2): DenseBlock(\n","      (dense_blocks): Sequential(\n","        (denseblock0): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock1): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock2): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock3): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock4): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock5): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock6): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock7): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(28, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock8): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock9): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(36, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock10): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock11): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(44, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","      )\n","    )\n","    (compress2): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))\n","    (norm2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu2): ReLU()\n","    (avgpool2): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n","    (dense3): DenseBlock(\n","      (dense_blocks): Sequential(\n","        (denseblock0): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock1): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock2): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock3): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock4): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock5): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock6): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock7): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(28, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock8): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock9): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(36, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock10): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock11): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(44, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock12): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock13): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(52, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock14): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(56, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock15): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(60, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock16): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock17): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(68, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(68, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock18): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(72, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock19): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(76, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock20): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(80, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock21): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(84, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock22): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(88, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock23): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(92, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","      )\n","    )\n","    (compress3): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n","    (norm3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu3): ReLU()\n","    (avgpool3): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n","    (dense4): DenseBlock(\n","      (dense_blocks): Sequential(\n","        (denseblock0): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock1): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock2): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock3): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock4): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock5): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock6): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock7): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(28, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock8): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock9): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(36, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock10): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock11): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(44, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock12): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock13): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(52, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock14): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(56, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","        (denseblock15): DenseLayer(\n","          (bottle_neck): Sequential(\n","            (norm1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu1): ReLU()\n","            (conv1): Conv2d(60, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          )\n","          (conv): Sequential(\n","            (norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu2): ReLU()\n","            (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          )\n","        )\n","      )\n","    )\n","    (compress4): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","    (norm4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu4): ReLU()\n","    (globavgpool): AvgPool2d(kernel_size=(7, 7), stride=(7, 7), padding=0)\n","  )\n","  (classifier): Linear(in_features=32, out_features=3, bias=True)\n",")"]},"execution_count":130,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":133,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["out torch.Size([1, 32, 1, 1])\n"]},{"data":{"text/plain":["tensor([[-0.2350,  0.1957,  0.1086]], grad_fn=<AddmmBackward0>)"]},"execution_count":133,"metadata":{},"output_type":"execute_result"}],"source":["# Если сделать картинк услишком большой, то она не свернется в 32x1x1 в конце\n","sample_tensor = torch.randn(1, num_input_features, 320, 320)\n","model(sample_tensor)"]},{"cell_type":"markdown","metadata":{"id":"iOTbIAOwHakP"},"source":["### Как проводить эксперименты"]},{"cell_type":"markdown","metadata":{"id":"oXJjLoZXHeHZ"},"source":["\"Neural net training is a leaky abstraction\" - Andrej Karpathy\n","\n","Знания теории, архитектур, оптимизаторов порой недостаточно для получения хорошей модели - значит, пришла пора подбора гиперпараметров.  \n","В таких случаях может помочь не *model-centric*, а *data-centric* подход: переразметить данные, поменять аугментации, докинуть новые.\n","\n","**Но во всех этих случаях правильно организовать эксперименты**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YByhO57qIh34"},"source":["**Перед началом:**\n","Убедитесь, что у вас есть хороший и адекватный бейзлайн\n","1. Сначала вместо самописных моделей берите архитектуры из известных репозиториев (torchvision, timm, mmdetection, huggingface etc)\n","2. Эти архитектуры должны быть стандартными для вашей задачи. То есть, для задач компьютерного зрения (классификации, детекции, сегментации) - ResNet, для обработки языков - трансформер.\n","3. Не придумывайте сложные пайплайны обучения - Adam + LR без расписания, предобработка входа - такая же как у предобученной модели\n","4. Первые пробные запуски делайте на подвыборках, тестовых датасетах\n"]},{"cell_type":"markdown","metadata":{"id":"tdRq8GwXKLJU"},"source":["**Снизьте число факторов влияния**:\n","1. Баги могут быть в разных частях: в модели, обучении, загрузке данных, проверке качества. Сначала избавьтесь от эффекта случайности и зафиксируйте seed и попробуйте поставить determenistic поведение\n","2. Визуализируйте *все*: метрики, лоссы, градиенты, примеры работы модели, работу аугментаций\n","3. Пишите unit-тесты. Даже небольшие!\n","4. Сохраняйте чекпоинты. Не только best и last. Полезно брать чекпоинты каждые несколько итераций\n","5. При проведении экспериментов вносите **только одно изменение за раз**.\n"]},{"cell_type":"markdown","metadata":{"id":"__1FXprlL0Ne"},"source":["Более полные и точные рецепты можете прочитать [здесь](https://github.com/puhsu/dl-hse/blob/main/week01-intro/lecture-best-practices.pdf)"]},{"cell_type":"markdown","metadata":{"id":"hLD8YPRH5UOS"},"source":["## Обучение и подбор гиперпараметров"]},{"cell_type":"markdown","metadata":{"id":"4AKF23u86UL3"},"source":["\n","\n","> **Гиперпараметры** отличаются от **параметров** следующим:\n","> * Они не могут обучаться с помощью градиентного спуска: например, выбор оптимизатора, learning rate, аугментаций, сам подбор архитектуры и пайплайна можно считать за гиперпараметры. Иначе говоря, все, что мы не можем включить в нашу end-to-end модель, чтобы обучать это через функцию потерь, является гиперпараметром\n","> * Часто гиперпараметры подбирают на валидационной выборке (точнее, если их подбор уж очень важен, для них создают специальную выборку, которая называется *dev выборка*): например, weight decay\n","> * Гиперпараметры бывают дискретными и без отношения порядка: например, выбор расписания для lr, а также выбор момента шага расписания - можно делать шаг на каждом шаге оптимизатора, можно на каждой эпохе\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZxXnWrbC74SC"},"source":["**Вопрос**: почему weight decay лучше подбирать на валидационной выборке? Можно ли его подбирать на обучающей? Если можно, то как?"]},{"cell_type":"markdown","metadata":{"id":"plUS_5-X5YAh"},"source":["Чтобы не писать собственный train loop, мы будем использовать **Pytorch Lightning**.   \n","\n","Это не самый лучший фреймворк для обучения - в нем множество багов, которые особенно любят проявлять себя в сложных моделях, обучаемых в low-precision с параллелизмом.  \n","\n","Но большая часть популярных фреймворков организована именно так - train loop скрыт от глаз пользователя. Поэтому полезно посмотреть это на таком простом примере, как Pytorch Lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PwIM9K5wBF5B"},"outputs":[],"source":["! pip install pytorch_lightning >> None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Woi5D02x5Xac"},"outputs":[],"source":["import pytorch_lightning as pl\n","\n","class ConvModelPL(pl.LightningModule):\n","  def __init__(self, model, lr, weight_decay):\n","    super().__init__()\n","    self.model = model\n","    self.lr = lr\n","    self.weight_decay = weight_decay\n","\n","  def training_step(self, batch, batch_idx):\n","    # training_step определяет шаг в train loop\n","    # forward модели и подсчет лосса\n","    x, y = batch\n","    # <your code here>\n","    # по умолчанию логгируем в TensorBoard\n","    self.log(\"train_loss\", loss)\n","    return loss\n","\n","  def validation_step(self, batch, batch_idx):\n","    x, y = batch\n","    # соответсвенно, здесь выполняется шаг валидации\n","    # тоже нужно сделать forward модели и подсчитать лосс\n","    # но кроме этого - вычислить метрику\n","    # <your code here>\n","    self.log(\"val_loss\", loss)\n","    return metric\n","\n","  def validation_epoch_end(self, validation_step_outputs):\n","    # этот шаг выполняется в конце эпохи\n","    # здесь мы усредним накопленную метрику\n","    # и передадим ее в логгер\n","    total_metric = torch.stack(validation_step_outputs).mean()\n","    self.log(\"val_epoch_acc\", acc_epoch)\n","\n","\n","  def configure_optimizers(self):\n","      # здесь мы настраиваем оптимизатор\n","      # вы можете сделать более сложную конфигурацию\n","      optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay,)\n","      return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNRIAatVCug5"},"outputs":[],"source":["model = ConvNet()\n","model_pl = ConvModelPL(model, lr=1e-4, weight_decay=1e-6)"]},{"cell_type":"markdown","metadata":{"id":"y3CdP4tPC08O"},"source":["Дальше создадим датасеты и даталоадеры.\n","Опять же, вам нужно написать более точную конфигурацию: подобрать аугментации для baseline, batch_size, параметры даталоадера"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ltfuDf8gCvL3"},"outputs":[],"source":["import torchvision\n","from torchvision import transforms\n","\n","batch_size = 32\n","workers = 1\n","\n","# вспомните, что вы можете использовать не только аугментации из torchvision\n","# но и из albumentations и, если уж совсем хотите заморочиться, nvidia dali\n","# прочитайте вот эту статью, возможно, аугментации из нее могут вам помочь\n","# https://openaccess.thecvf.com/content_CVPR_2019/papers/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.pdf\n","transform = transforms.Compose(\n","    # <your code here>\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","\n","# есть несколько способов ускорения даталоадера\n","\n","# главный из них - ставить pin_memory, когда вы работаете с gpu\n","# дело в том, что программы на host'е работает с логической памятью, которая называется paged memory,\n","# она связана с физической с помощью таблицы - page table\n","# когда физической памяти не хватает, страницы из page memory выгружаются (page out) на другие носители (например, на ssd)\n","# получается, paged memory нестабильна и может быть разбросана по разным физическим устройствам\n","# чтобы скопировать данные на device, сначала данные из paged memory копируются в page-locked memory,\n","# и только затем на device\n","# можно избежать такого: сразу выделять память в page-locked memory\n","# именно это и делает аргумент pin_memory=True\n","# https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n","\n","# также если у вашего трейнлупа нет точек синхронизации (напимер, print, logging, перемещение на cpu)\n","# то можно ставить data = data.to('cuda:0', non_blocking=True) при отправлении данных\n","# https://discuss.pytorch.org/t/should-we-set-non-blocking-to-true/38234/3\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n","                                          shuffle=True, num_workers=workers)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n","                                         shuffle=False, num_workers=workers)"]},{"cell_type":"markdown","metadata":{"id":"twX_vCwuNAKn"},"source":["**Вопрос:** на что влияет аргумент num_workers в DataLoader? Каким его можно ставить?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IdHuE97-DHSj"},"outputs":[],"source":["# а теперь можно запускать обучение и смотреть метрики и графики\n","# просмотр графиков вы должны вставить сами\n","\n","# чтобы запустить на маке\n","# напишите device='mps'\n","device = 'cuda'\n","\n","# здесь только пробный запуск\n","# очевидно, вы должны изменить параметры limit_train_batches и max_epochs\n","# когда будете делать более сложные эксперименты\n","trainer = pl.Trainer(limit_train_batches=100, max_epochs=20)\n","trainer.fit(model_pl, train_loader, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"aEUZsAL3GsML"},"source":["Попробуйте получить хороший бейзлайн по рекомендациям выше.  \n","После обучения модели подберите гиперпараметры и, если вы этого захотите, немного измените архитектуру модели так, чтобы добиться более высокой метрики."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QltavClgHIVx"},"outputs":[],"source":["# что вы можете подбирать: оптимизатор, scheduler, learning rate, аугментации,\n","# weight decay, тип инициализации\n","# <your code here>"]},{"cell_type":"markdown","metadata":{"id":"b2IiIqFpMf_W"},"source":["## Transfer Learning и Fine-Tune"]},{"cell_type":"markdown","metadata":{"id":"yiOycRqMEk3x"},"source":["Для многих прикладных задач не существует больших датасетов с хорошей разметкой. Поэтому распространенным приемом является тренировка на похожем, но большом датасете и доучивание сети на целевом.\n","\n","Такой прием называют **Transfer Learning** или **Fine-tuning**.\n","\n","В сверточных сетях для классификации выделяют две части:\n","1. Тело сети (backbone, feature extractor) - это набор сверток и пулингов (convolutions and poolings)\n","2. Голову (head) - это MLP (набор полносвязных слоев) после которых делается softmax и получаются вероятности разных классов.\n","\n","Вычислительно простым вариантом finetuning является переучивание головы сети. Также можно фиксировать какие-то первый слои"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-dQYLDsDh4o"},"outputs":[],"source":["from torchvision import models\n","\n","model = models.resnet18(pretrained=True)\n","\n","# кроме torchvision очень известен репозиторий pytorch-image-models\n","# !pip install timm >> None\n","# import timm\n","# model = timm.create_model('resnet18', pretrained=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWB9hYj6GtCt"},"outputs":[],"source":["# заморозим слои\n","for param in model.parameters():\n","  param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4f6-sQ9GryD"},"outputs":[],"source":["# 10 - число наших классов\n","model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n","# теперь requires_grad=True только у model.fc"]},{"cell_type":"markdown","metadata":{"id":"O9FVdZ_uA1gV"},"source":["**Вопрос:** почему нужно использовать lr warmup для fine-tune предобученной модели?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gB-fxutNWqf"},"outputs":[],"source":["# осталось лишь заметить, что пайплайн обучения уже написан - он хранится в model_pl\n","# вам осталось его только запустить\n","# проведите несколько экспериментов:\n","# 1. Дообучите только голову\n","# 2. Дообучите всю модель\n","# 3. Поменяйте пайплайн аугментаций с вашего на тот, что использовался для предобученной модели\n","# 4. Откусите голову и обучите SVM на данных, полученных из feature extractor'a. Попробуйте с аугментациями и без них.\n","# Такой подход сработает, ведь feature extractor можно рассматривать как функцию, которая отображает данные из одного пространства в другое,\n","# где эти данные линейно разделимы\n","# сравните результаты между полной сетью, сетью с дообучением головы и сетью с SVM. Где результаты лучше и почему?"]},{"cell_type":"markdown","metadata":{"id":"2W2AIPlp93_b"},"source":["**Вопросы:**  \n","1. Какая разница по качеству между обучением всей модели и только головы? Как вы думаете, какие преимущества у каждого из этих подходов?\n","2. Какие зависимости вы обнаружили между различными значениями гиперпараметров и процессом обучения модели?\n","3. Прочитайте раздел Loss Functions [отсюда](https://cs231n.github.io/neural-networks-2/) (можете и другие разделы). Как вы думаете, почему нельзя обучать классификатор на MSE?"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPaVIzsVCrg+zgqrZqYExN+","provenance":[{"file_id":"1-QsqbFnU1KhIiKO6ERjanY825JUSZwiK","timestamp":1727991278398}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
