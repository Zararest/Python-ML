{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ3DJzu7FDX_"
      },
      "source": [
        "# Домашнее задание 2.1. Сверточные сети\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQVARDpwNsOa"
      },
      "source": [
        "В этом задании вы должны:\n",
        "1. Написать слой Conv2d на Numpy и определить в нем forward-backward методы\n",
        "2. Определить слой MaxPool2d\n",
        "3. Написать всю необходимую обвязку для обучения: оптимизатор с адаптивным шагом и класс, позволяющий изменять расписание для learning rate'а\n",
        "\n",
        "\n",
        "\n",
        "> Обратите внимание, что в этом задании больше нет тестов.\n",
        "> Вы должны сами проверять свой код.  \n",
        "> Это можно сделать так:\n",
        "> 1. Написать юнит-тесты с помощью Pytorch. То есть, ваш модудь должен повторять поведение torch'а\n",
        "> 2. Проверять архитектуру не на всем датасете, а на подвыборке: при наивной имплементации слоев одна эпоха на всем датасете будет занимать около двух часов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMVkqpoEOoD3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Numpy-имплементация сверточной нейронной сети\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmTxOp7KOoEG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Вставьте сюда имплементацию из первого домашнего задания.\n",
        "\n",
        "\n",
        "\n",
        "> Обратите внимание, что обновление весов теперь производится с помощью специального класса **Optimizer**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lmfLBp4tOoEN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def load_mnist(flatten=False):\n",
        "    \"\"\"taken from https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py\"\"\"\n",
        "    # We first define a download function, supporting both Python 2 and 3.\n",
        "    if sys.version_info[0] == 2:\n",
        "        from urllib import urlretrieve\n",
        "    else:\n",
        "        from urllib.request import urlretrieve\n",
        "\n",
        "    def download(filename, source='https://ossci-datasets.s3.amazonaws.com/mnist/'):\n",
        "        print(\"Downloading %s\" % filename)\n",
        "        urlretrieve(source + filename, filename)\n",
        "\n",
        "    # We then define functions for loading MNIST images and labels.\n",
        "    # For convenience, they also download the requested files if needed.\n",
        "    import gzip\n",
        "\n",
        "    def load_mnist_images(filename):\n",
        "        if not os.path.exists(filename):\n",
        "            download(filename)\n",
        "        # Read the inputs in Yann LeCun's binary format.\n",
        "        with gzip.open(filename, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "        # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
        "        # following the shape convention: (examples, channels, rows, columns)\n",
        "        data = data.reshape(-1, 1, 28, 28)\n",
        "        # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
        "        # (Actually to range [0, 255/256], for compatibility to the version\n",
        "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
        "        return data / np.float32(256)\n",
        "\n",
        "    def load_mnist_labels(filename):\n",
        "        if not os.path.exists(filename):\n",
        "            download(filename)\n",
        "        # Read the labels in Yann LeCun's binary format.\n",
        "        with gzip.open(filename, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "        # The labels are vectors of integers now, that's exactly what we want.\n",
        "        return data\n",
        "\n",
        "    # We can now download and read the training and test set images and labels.\n",
        "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
        "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
        "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
        "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "    # We reserve the last 10000 training examples for validation.\n",
        "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
        "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
        "\n",
        "    if flatten:\n",
        "        X_train = X_train.reshape([X_train.shape[0], -1])\n",
        "        X_val = X_val.reshape([X_val.shape[0], -1])\n",
        "        X_test = X_test.reshape([X_test.shape[0], -1])\n",
        "\n",
        "    # We just return all the arrays in order, as expected in main().\n",
        "    # (It doesn't matter how we do this as long as we can read them again.)\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jYZ3ptaiOoER",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    \"\"\"\n",
        "    A building block. Each layer is capable of performing two things:\n",
        "\n",
        "    - Process input to get output:           output = layer.forward(input)\n",
        "\n",
        "    - Propagate gradients through itself:    grad_input = layer.backward(input, grad_output)\n",
        "\n",
        "    Some layers also have learnable parameters which they update during layer.backward.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"Here you can initialize layer parameters (if any) and auxiliary stuff.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def get_grad_weights(self):\n",
        "        return None\n",
        "\n",
        "    def get_weights(self):\n",
        "        return None\n",
        "    \n",
        "    def set_weights(self, weights):\n",
        "        pass\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Takes input data of shape [batch, input_units], returns output data [batch, output_units]\n",
        "        \"\"\"\n",
        "        return input\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        \"\"\"\n",
        "        Performs a backpropagation step through the layer, with respect to the given input.\n",
        "\n",
        "        To compute loss gradients w.r.t input, you need to apply chain rule (backprop):\n",
        "\n",
        "        d loss / d x  = (d loss / d layer) * (d layer / d x)\n",
        "\n",
        "        Luckily, you already receive d loss / d layer as input, so you only need to multiply it by d layer / d x.\n",
        "\n",
        "        If your layer has parameters (e.g. dense layer), you also need to update them here using d loss / d layer\n",
        "        \"\"\"\n",
        "        input_dim = input.shape[1]\n",
        "\n",
        "        d_layer_d_input = np.eye(input_dim)\n",
        "\n",
        "        return np.dot(grad_output, d_layer_d_input) # chain rule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qe246l61OoEe",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class ReLU(Layer):\n",
        "    def __init__(self):\n",
        "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n",
        "        pass\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Apply elementwise ReLU to [batch, input_units] matrix\"\"\"\n",
        "        output = np.array(input)\n",
        "        output[output < 0] = 0\n",
        "        return output\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        \"\"\"Compute gradient of loss w.r.t. ReLU input\"\"\"\n",
        "        relu_grad_mask = np.zeros_like(input)\n",
        "        relu_grad_mask[input > 0] = 1\n",
        "        return grad_output * relu_grad_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "g22Gzs_2OoEl",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class Dense(Layer):\n",
        "    def __init__(self, input_units, output_units, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        A dense layer is a layer which performs a learned affine transformation:\n",
        "        f(x) = <W*x> + b\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # initialize weights with small random numbers from normal distribution\n",
        "        # you can change the intializtion method\n",
        "        self.weights = np.random.randn(input_units, output_units)*0.01\n",
        "        self.biases = np.zeros(output_units)\n",
        "\n",
        "        self.grad_weights = None\n",
        "        self.grad_biases = None\n",
        "\n",
        "    def get_weights(self):\n",
        "        return np.concatenate((self.weights, self.biases), axis=None)\n",
        "    \n",
        "    def get_grad_weights(self):\n",
        "        return np.concatenate((self.grad_weights, self.grad_biases), axis=None)\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        weights_size = np.size(self.weights)\n",
        "        biases_size = np.size(self.biases)\n",
        "        all_weights_size = weights_size + biases_size\n",
        "        assert np.shape(weights)[0] == all_weights_size\n",
        "        self.weights = np.reshape(weights[:weights_size], np.shape(self.weights))\n",
        "        self.biases = np.reshape(weights[weights_size:], np.shape(self.biases))\n",
        "\n",
        "    def forward(self,input):\n",
        "        \"\"\"\n",
        "        Perform an affine transformation:\n",
        "        f(x) = <W*x> + b\n",
        "\n",
        "        input shape: [batch, input_units]\n",
        "        output shape: [batch, output_units]\n",
        "        \"\"\"\n",
        "        return np.dot(input, self.weights) + self.biases\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "\n",
        "        # compute d f / d x = d f / d dense * d dense / d x\n",
        "        # where d dense/ d x = weights transposed\n",
        "        # grad_output is a derivative of the next (in forward) layer of prediction\n",
        "        # this result is needed for the next layer\n",
        "        grad_input = np.dot(grad_output, np.transpose(self.weights))\n",
        "\n",
        "        # compute gradient w.r.t. weights and biases\n",
        "        self.grad_weights = np.dot(np.transpose(input), grad_output)\n",
        "        self.grad_biases = np.sum(grad_output, axis=0)\n",
        "\n",
        "        # Gradient step should be performed with the help of separate optimizer\n",
        "        assert self.grad_weights.shape == self.weights.shape and self.grad_biases.shape == self.biases.shape\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A1vN8h41ILY9"
      },
      "outputs": [],
      "source": [
        "class Conv2d(Layer):\n",
        "    def __init__(self, input_channels, output_channels, kernel_size, learning_rate=0.1):\n",
        "        self.weights = np.random.randn(input_channels, output_channels, kernel_size, kernel_size)*0.01\n",
        "        self.biases = np.zeros(output_channels)\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        self.grad_weights = None\n",
        "        self.grad_biases = None\n",
        "\n",
        "    def _conv(input, weights, biases):\n",
        "        kernel_height = np.shape(weights)[2]\n",
        "        kernel_width = np.shape(weights)[3]\n",
        "        output_chanels = np.shape(weights)[1]\n",
        "        # Output dimention is determined by the number of filters in the layer.\n",
        "        # Each filter is a tensor with the size (input_channels, kernel_size, kernel_size)\n",
        "        # (In this example second axis is an index of filter)\n",
        "        # Such a filter produces one number per convolution \n",
        "        #   and this convolution is performed for each part of the input tensor.\n",
        "        batch_size = np.shape(input)[0]\n",
        "        output_height = np.shape(input)[2] - kernel_height + 1\n",
        "        output_width = np.shape(input)[3] - kernel_width + 1\n",
        "\n",
        "        # This is the result of convollution of each filter\n",
        "        filters = np.empty((output_chanels, output_height, output_width, batch_size))\n",
        "        for filter_idx in range(output_chanels):\n",
        "            for i in range(output_height):\n",
        "                for j in range(output_width):\n",
        "                    filters[filter_idx, i, j] = \\\n",
        "                        np.tensordot(input[:, :, i:i+kernel_height, j:j+kernel_width],\n",
        "                                     weights[:, filter_idx, :, :],\n",
        "                                     axes=([1, 2, 3], [0, 1, 2]))\n",
        "        output = np.rollaxis(filters, 3, 0)\n",
        "        if biases is not None:\n",
        "        # Here values from biases are broadcasted\n",
        "            output += np.reshape(biases, (1, output_chanels, 1, 1))\n",
        "        return output\n",
        "\n",
        "    def _pad(tensor, val, new_height, new_width):\n",
        "        pad_h = (new_height - np.shape(tensor)[2]) // 2\n",
        "        pad_w = (new_width - np.shape(tensor)[3]) // 2\n",
        "        padding = ((0, 0), (0, 0), (pad_h, pad_h), (pad_w, pad_w))\n",
        "        res = np.pad(tensor, padding, 'constant', constant_values=(val, val))\n",
        "        assert np.shape(res)[2] == new_height and np.shape(res)[3] == new_width\n",
        "        return res\n",
        "    \n",
        "    def _flip_transpose(tensor):\n",
        "        tensor = np.flip(tensor, (2, 3))\n",
        "        tensor = np.moveaxis(tensor, 2, 3) # this should work\n",
        "        return tensor\n",
        "    \n",
        "    def get_grad_weights(self):\n",
        "        return self.grad_weights\n",
        "    \n",
        "    def get_weights(self):\n",
        "        return self.weights\n",
        "    \n",
        "    def set_weights(self, weights):\n",
        "        self.weights = weights\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Perform an convolution:\n",
        "\n",
        "        output_height = input_height - kernel_size + 1\n",
        "        output_width = input_width - kernel_size + 1\n",
        "\n",
        "        input shape: [batch, input_channels, input_height, input_width]\n",
        "        output shape: [batch, output_channels, output_height, output_width]\n",
        "        \"\"\"\n",
        "        return Conv2d._conv(input, self.weights, self.biases)\n",
        "        \n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        # Grad output has the shape [batch, output_channels, output_height, output_width]\n",
        "        # I don't know how this is possible, but if has these axises, convolution just works\n",
        "        input = np.moveaxis(input, 0, 1)\n",
        "        self.grad_weights = Conv2d._conv(input, grad_output, None)\n",
        "        input = np.moveaxis(input, 0, 1)\n",
        "        # dldb = dldz * dzdb \n",
        "        # dzdb = 1\n",
        "        # dldz = grad_output\n",
        "        # Each biases' component is applied to each element with the fixed output_chanels axis,\n",
        "        #   so input gradient is the sum of all output gradients\n",
        "        grad_biases = np.sum(grad_output, axis=(0, 2, 3))\n",
        "\n",
        "        kernel_size = np.shape(self.weights)[2]\n",
        "        # Probably I shouldn't change input tensor, but whatever\n",
        "        grad_padded = Conv2d._pad(grad_output, 0,\n",
        "                                   np.shape(input)[2] + kernel_size - 1,\n",
        "                                   np.shape(input)[3] + kernel_size - 1)\n",
        "        tmp_weights = np.copy(self.weights)\n",
        "        tmp_weights = Conv2d._flip_transpose(tmp_weights)\n",
        "        tmp_weights = np.moveaxis(tmp_weights, 0, 1)\n",
        "        grad_input = Conv2d._conv(grad_padded, tmp_weights, None)\n",
        "\n",
        "        # Gradient step is in a separate optimizer\n",
        "        assert self.grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test shapes:\n",
            "torch.Size([10, 2, 3, 4])\n",
            "(10, 2, 3, 4)\n"
          ]
        }
      ],
      "source": [
        "# Conv2D test\n",
        "from torch import nn\n",
        "import torch\n",
        "test_batch_size = 10\n",
        "test_input_chanels = 3\n",
        "test_output_chanels = 2\n",
        "test_input_height = 4\n",
        "test_input_width = 5\n",
        "test_kernel_size = 2\n",
        "\n",
        "test_conv = Conv2d(input_channels=test_input_chanels, \n",
        "                   output_channels=test_output_chanels, \n",
        "                   kernel_size=test_kernel_size)\n",
        "test_input = np.random.randn(test_batch_size, \n",
        "                             test_input_chanels, \n",
        "                             test_input_height,\n",
        "                             test_input_width)\n",
        "test_output = test_conv.forward(test_input)\n",
        "test_layer_torch = nn.Conv2d(in_channels=test_input_chanels,\n",
        "                     out_channels=test_output_chanels,\n",
        "                     kernel_size=(test_kernel_size, test_kernel_size))\n",
        "test_ref = test_layer_torch(torch.tensor(test_input, dtype=torch.float))\n",
        "print(\"Test shapes:\")\n",
        "print(test_ref.shape)\n",
        "print(test_output.shape)\n",
        "#assert torch.equal(torch.tensor(test_output, dtype=torch.float), test_ref)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shapes (10, 3, 4, 5), (10, 2, 3, 4)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[[[-4.14535637e-04, -5.93849499e-05,  2.00001671e-04,\n",
              "          -5.26122708e-05, -8.43926273e-05],\n",
              "         [-2.42368745e-04, -4.15107601e-04,  4.35640231e-04,\n",
              "           4.53876905e-04, -1.41820157e-04],\n",
              "         [ 4.12014211e-04,  3.95610927e-04,  1.08992059e-03,\n",
              "           6.58144610e-04,  1.14750358e-03],\n",
              "         [-1.15227724e-04,  7.91097578e-05,  2.07772217e-04,\n",
              "           1.88890035e-04, -1.12398687e-04]],\n",
              "\n",
              "        [[-4.32519075e-04, -1.30322377e-04,  3.07750213e-04,\n",
              "          -3.57175903e-05,  1.59119872e-04],\n",
              "         [-2.97246658e-04,  8.33617792e-04, -1.81965779e-03,\n",
              "          -1.91923470e-03,  4.90359412e-04],\n",
              "         [ 5.75104359e-04,  1.05689824e-03, -1.05906573e-03,\n",
              "           8.63326986e-04, -1.62202612e-03],\n",
              "         [ 8.07397416e-05, -5.05576305e-04, -5.92513622e-04,\n",
              "          -5.68821806e-04, -7.00909647e-05]],\n",
              "\n",
              "        [[-1.48276255e-04,  9.90937843e-05,  4.06921291e-04,\n",
              "           1.73460678e-04,  1.77456872e-04],\n",
              "         [-4.49029655e-04, -3.64236121e-05,  1.89010486e-03,\n",
              "           1.58314992e-03,  9.68583917e-04],\n",
              "         [-8.77409156e-05, -2.26600142e-04,  5.04917738e-04,\n",
              "           1.00016323e-03,  9.50465735e-04],\n",
              "         [ 7.89339780e-05,  3.20665923e-04,  5.10570654e-04,\n",
              "           3.49935478e-04, -2.21813977e-04]]],\n",
              "\n",
              "\n",
              "       [[[ 1.83344894e-04, -5.15499050e-04, -4.19839325e-04,\n",
              "          -7.92928744e-04, -5.80101527e-04],\n",
              "         [ 4.44498306e-04,  1.13807681e-03,  2.19596244e-04,\n",
              "           2.66233227e-05,  4.73621596e-05],\n",
              "         [-3.47655486e-05,  8.75558173e-05, -4.78936359e-04,\n",
              "           4.06821362e-04, -3.54674436e-04],\n",
              "         [-7.33514682e-05,  7.15848068e-05,  6.42566994e-04,\n",
              "          -1.84654418e-04,  2.34628815e-04]],\n",
              "\n",
              "        [[-2.11523314e-04, -6.45703044e-04,  5.47080271e-04,\n",
              "          -1.51170757e-03,  8.55742445e-04],\n",
              "         [ 4.69273475e-04, -2.38702307e-03,  4.10029083e-04,\n",
              "          -4.95744997e-04,  2.54243323e-04],\n",
              "         [ 3.97265294e-04, -2.43170792e-04,  3.53713549e-04,\n",
              "           1.00976009e-03,  9.10817287e-04],\n",
              "         [ 5.18543574e-05, -1.17703150e-04, -9.74880332e-04,\n",
              "           2.62674374e-04, -7.59288927e-04]],\n",
              "\n",
              "        [[-1.44244928e-07,  1.27162697e-04,  6.26384563e-04,\n",
              "          -3.98880934e-04,  9.45818716e-04],\n",
              "         [ 9.05525630e-04,  1.17818012e-03,  5.58925283e-04,\n",
              "          -2.91750446e-05,  3.27025527e-04],\n",
              "         [-1.75690441e-04, -5.97838374e-04, -1.47917358e-04,\n",
              "          -8.08796485e-05, -1.52045731e-03],\n",
              "         [-7.56519333e-05,  3.88994073e-04,  9.00853376e-04,\n",
              "           8.19668542e-05,  2.80810109e-04]]],\n",
              "\n",
              "\n",
              "       [[[ 1.43399217e-04, -2.21501535e-04, -4.81298786e-04,\n",
              "           1.49527265e-04,  1.41113660e-04],\n",
              "         [-5.52953007e-04, -4.82482579e-04,  2.74927647e-04,\n",
              "          -1.05586693e-03, -4.41360530e-04],\n",
              "         [-6.16442333e-05,  3.56895759e-05, -2.27214240e-04,\n",
              "          -6.94105672e-04, -7.78198138e-04],\n",
              "         [ 2.99011060e-04,  4.29442900e-04, -2.73242814e-04,\n",
              "          -1.48173639e-04, -5.60622141e-04]],\n",
              "\n",
              "        [[ 5.78982328e-04, -1.31656247e-03,  6.74791464e-04,\n",
              "           1.40414558e-04, -2.85111411e-04],\n",
              "         [-5.15752202e-04,  1.02017535e-03,  7.22694211e-04,\n",
              "           5.36218654e-04,  3.02888312e-04],\n",
              "         [-9.64561430e-04,  1.41636150e-03, -8.94764465e-04,\n",
              "           1.37552377e-03,  1.34822705e-03],\n",
              "         [-2.12686931e-04, -6.63532497e-04,  3.38142733e-04,\n",
              "           2.66101022e-04,  8.05874487e-04]],\n",
              "\n",
              "        [[ 1.21348468e-04, -7.14642157e-04,  5.70392867e-04,\n",
              "          -2.01359398e-04, -3.18651007e-04],\n",
              "         [-6.92323832e-04, -9.82467459e-05, -1.76398381e-04,\n",
              "          -2.01162809e-03, -5.98033260e-04],\n",
              "         [ 9.52182829e-06,  1.04662802e-03, -1.15896877e-03,\n",
              "          -1.08661679e-03, -1.79039427e-03],\n",
              "         [ 6.68313621e-04,  6.14406464e-04, -5.49985301e-04,\n",
              "          -4.24759784e-04, -8.73866066e-04]]],\n",
              "\n",
              "\n",
              "       [[[-3.33179404e-04, -6.41800231e-04, -2.34464807e-04,\n",
              "          -8.60283390e-05, -2.90837226e-04],\n",
              "         [-6.44265879e-04, -1.09000929e-03, -1.05565252e-03,\n",
              "          -1.17151112e-03,  8.56501134e-05],\n",
              "         [ 3.66544006e-04,  9.55313650e-05,  4.52365873e-04,\n",
              "           8.51598603e-04,  6.21414268e-04],\n",
              "         [-1.30841778e-04, -3.05358733e-04, -3.82631848e-04,\n",
              "          -5.66122824e-04, -6.44095001e-04]],\n",
              "\n",
              "        [[-4.78305834e-04, -6.10671735e-04,  1.00138614e-03,\n",
              "          -1.24772515e-03,  5.43650674e-04],\n",
              "         [-1.09178368e-03, -2.80587677e-04,  4.84323468e-04,\n",
              "          -7.37445495e-05,  2.75946115e-05],\n",
              "         [ 3.00468251e-04,  1.22483243e-03,  1.13526922e-03,\n",
              "           1.77552248e-03, -6.62025835e-04],\n",
              "         [ 9.27683559e-05,  2.29851800e-04,  3.00571325e-04,\n",
              "           2.04931146e-04,  5.12231370e-04]],\n",
              "\n",
              "        [[-1.40496538e-04,  1.13768158e-05,  6.01671802e-04,\n",
              "          -6.92423042e-04,  6.06131921e-04],\n",
              "         [-3.93382640e-04,  5.13470573e-05, -6.86543218e-05,\n",
              "          -5.67092497e-04,  1.40761253e-03],\n",
              "         [-1.27814782e-04, -8.14318464e-04, -4.70949023e-04,\n",
              "          -3.72206856e-04, -9.84530735e-04],\n",
              "         [-2.09949922e-04, -5.14326606e-04, -5.02879777e-04,\n",
              "          -9.60762226e-04, -1.08720748e-03]]],\n",
              "\n",
              "\n",
              "       [[[-4.51241419e-04, -3.43362815e-04, -2.99231885e-04,\n",
              "           5.12502637e-05,  1.81602006e-04],\n",
              "         [ 8.66380042e-04,  9.32754423e-04,  9.54867380e-05,\n",
              "          -1.11440768e-03, -6.02479776e-04],\n",
              "         [ 1.53202651e-05,  2.75218774e-04, -8.05941291e-05,\n",
              "          -4.74275029e-04, -3.86899037e-05],\n",
              "         [-7.92522499e-06,  3.28467047e-04,  4.17845757e-04,\n",
              "           4.75035222e-04, -4.12609621e-04]],\n",
              "\n",
              "        [[-1.05530531e-03,  5.27778016e-04,  2.06873608e-04,\n",
              "           3.08325427e-04, -4.47953769e-04],\n",
              "         [ 2.93027240e-04, -1.93374182e-04, -1.14518494e-03,\n",
              "           2.10699950e-03,  9.23220032e-04],\n",
              "         [ 5.76527528e-05, -2.64073005e-03, -3.21678083e-04,\n",
              "          -1.75257090e-04, -1.98222908e-04],\n",
              "         [ 5.52489807e-06, -2.76986396e-04, -1.65124548e-04,\n",
              "          -6.16791648e-04,  9.22266112e-04]],\n",
              "\n",
              "        [[-2.56771972e-04,  7.26854161e-04,  1.46533892e-04,\n",
              "          -1.57357622e-04, -5.03362841e-04],\n",
              "         [ 6.77694378e-04,  1.00119384e-03, -3.18729376e-04,\n",
              "          -1.48834632e-03, -1.11552807e-03],\n",
              "         [ 5.66003853e-04,  9.98772269e-04,  1.14542218e-03,\n",
              "           4.54553279e-04,  4.50841294e-04],\n",
              "         [ 1.32179569e-05,  4.27529432e-04,  8.77596839e-04,\n",
              "           3.81144951e-04, -5.76922042e-04]]],\n",
              "\n",
              "\n",
              "       [[[ 1.72829233e-04,  5.56542528e-04,  7.55595876e-04,\n",
              "           5.12899074e-04,  1.48574512e-04],\n",
              "         [ 1.09841087e-04,  4.63575367e-04,  5.10464822e-04,\n",
              "          -9.88040925e-04, -4.94818687e-04],\n",
              "         [ 1.86504778e-04, -4.13263969e-04, -1.06895451e-03,\n",
              "           2.93178903e-04, -1.02721082e-03],\n",
              "         [-5.60460598e-05,  2.11854693e-04, -5.40557094e-05,\n",
              "          -4.68426701e-05, -2.67851495e-04]],\n",
              "\n",
              "        [[ 8.42727696e-05,  6.36788170e-04,  8.27487425e-04,\n",
              "          -1.83757941e-04, -2.97148581e-04],\n",
              "         [-1.70724299e-04,  1.80299438e-04, -1.71169638e-03,\n",
              "          -5.48654198e-05,  3.21708430e-04],\n",
              "         [ 1.16300180e-04, -1.96872731e-03,  4.92330795e-04,\n",
              "          -2.48537884e-04,  1.88138780e-03],\n",
              "         [ 3.97111584e-05, -1.55594135e-04,  7.19303676e-04,\n",
              "           2.00332519e-04,  3.81625154e-04]],\n",
              "\n",
              "        [[ 4.61473018e-05,  2.45757851e-04,  5.62239733e-05,\n",
              "          -5.68332609e-04, -3.32002509e-04],\n",
              "         [ 2.81131071e-04,  1.25809675e-03, -8.45727808e-05,\n",
              "          -5.13516853e-04, -5.92571780e-04],\n",
              "         [ 4.56392197e-04, -2.01644534e-04,  3.05667141e-04,\n",
              "           3.73376507e-04, -1.82819054e-03],\n",
              "         [-8.27293290e-05, -7.42395059e-05, -7.33525730e-05,\n",
              "          -1.41655074e-04, -4.18196261e-04]]],\n",
              "\n",
              "\n",
              "       [[[ 2.13036379e-05,  5.89870382e-04, -1.06820869e-04,\n",
              "          -3.91111447e-04, -1.81260567e-04],\n",
              "         [-1.65329926e-04, -8.76208153e-04,  3.58211466e-04,\n",
              "           2.30655010e-04,  3.63447114e-04],\n",
              "         [-1.46875773e-04, -1.56802673e-04,  1.16778576e-04,\n",
              "           5.29312910e-04,  7.91205561e-04],\n",
              "         [ 1.16504226e-04,  2.80116805e-06, -8.09235915e-04,\n",
              "          -1.99812173e-04, -1.22948792e-04]],\n",
              "\n",
              "        [[ 4.63579062e-04,  2.98570876e-04, -1.01829502e-03,\n",
              "          -1.69062473e-04,  3.79659362e-04],\n",
              "         [ 3.21086841e-04,  8.48391477e-04, -4.72361372e-06,\n",
              "          -2.86161404e-04, -3.99567325e-04],\n",
              "         [-2.74838292e-04,  9.71585811e-04, -6.45755751e-04,\n",
              "           1.82412957e-03, -1.12758531e-03],\n",
              "         [-8.29050765e-05, -1.57693111e-04,  1.24122875e-03,\n",
              "           1.14667789e-05, -3.54069460e-04]],\n",
              "\n",
              "        [[ 7.96319691e-05, -2.71819212e-04, -5.76329682e-04,\n",
              "           2.64088096e-04,  4.24771044e-04],\n",
              "         [-6.05229397e-04, -1.29388425e-03,  3.97688510e-04,\n",
              "          -1.84532135e-05,  9.01056720e-04],\n",
              "         [-2.08256468e-04,  2.46927151e-04, -7.75169445e-04,\n",
              "           2.85776579e-04, -5.48279092e-04],\n",
              "         [ 2.70166301e-04, -3.66855700e-04, -1.18118253e-03,\n",
              "          -5.36062602e-05, -2.98450838e-04]]],\n",
              "\n",
              "\n",
              "       [[[ 1.29773995e-04, -1.78386010e-04, -7.61133943e-04,\n",
              "           4.85290565e-04,  5.53558359e-04],\n",
              "         [-2.12322929e-05,  6.49865278e-04,  1.35673448e-03,\n",
              "          -2.18088128e-04,  2.99004318e-05],\n",
              "         [-6.10273107e-04, -3.40544161e-04, -6.50473950e-04,\n",
              "          -3.67648154e-04, -4.56543687e-05],\n",
              "         [ 3.13163728e-04, -1.79534814e-04, -2.47799398e-04,\n",
              "           5.32613278e-04,  3.25396527e-04]],\n",
              "\n",
              "        [[ 8.87619681e-05, -8.43057420e-04, -2.66794013e-04,\n",
              "           1.92886592e-03, -7.24129866e-04],\n",
              "         [-4.00235340e-04,  2.48459160e-04, -1.30147778e-03,\n",
              "          -1.05608545e-04, -5.77982108e-04],\n",
              "         [-1.46069856e-03, -2.88339952e-05, -4.77436964e-04,\n",
              "          -6.04106572e-04,  2.11177335e-04],\n",
              "         [-2.20614051e-04,  7.79921490e-04,  6.72317720e-04,\n",
              "          -4.20247290e-04, -2.77424556e-04]],\n",
              "\n",
              "        [[ 3.88089813e-05, -1.67312571e-04,  4.80926012e-04,\n",
              "           9.62691589e-04, -7.96112697e-04],\n",
              "         [ 1.10033529e-04,  1.61521965e-03,  1.07515876e-03,\n",
              "          -1.72344853e-05,  3.99512741e-04],\n",
              "         [ 1.41640948e-04,  1.25032363e-03, -7.13828442e-04,\n",
              "           6.62899540e-04,  9.10517016e-04],\n",
              "         [ 1.10724517e-04, -4.51377850e-04, -3.32338422e-04,\n",
              "           8.89958177e-04,  5.45505038e-04]]],\n",
              "\n",
              "\n",
              "       [[[ 7.31953550e-04,  1.23996339e-03,  7.80498629e-04,\n",
              "          -1.10234771e-04, -1.28456239e-04],\n",
              "         [-2.61776484e-04, -1.13665039e-03, -1.14801757e-03,\n",
              "           3.81835712e-04,  2.41935261e-04],\n",
              "         [ 2.92048895e-04,  4.24618674e-04,  7.25640045e-04,\n",
              "           1.30383902e-03,  2.65359666e-04],\n",
              "         [ 1.25938336e-04,  6.43913026e-04, -9.82929783e-04,\n",
              "          -1.83098458e-04,  8.70988638e-05]],\n",
              "\n",
              "        [[ 1.41462005e-03,  5.51656241e-04, -8.42124503e-04,\n",
              "          -1.03306835e-04,  2.47152459e-04],\n",
              "         [ 3.11387701e-04, -8.38343153e-04, -1.89423161e-03,\n",
              "          -4.16773611e-04, -2.12806851e-04],\n",
              "         [-4.59169376e-05,  1.41060508e-04,  1.56181978e-03,\n",
              "          -1.27530989e-03, -4.25706497e-04],\n",
              "         [-9.10809280e-05, -1.32782255e-03,  1.22657131e-03,\n",
              "          -1.05431934e-04, -1.68334518e-04]],\n",
              "\n",
              "        [[ 3.68018573e-04, -5.35568666e-04, -8.16260956e-04,\n",
              "           2.07827862e-04,  2.75812011e-04],\n",
              "         [-3.22336043e-04, -9.13270674e-04,  2.75930753e-04,\n",
              "           2.93778293e-03,  4.59644165e-04],\n",
              "         [ 2.37112113e-04,  3.88445609e-04, -3.94810653e-07,\n",
              "           8.48767865e-04,  3.67785717e-04],\n",
              "         [ 6.94777826e-04,  6.52000159e-04, -1.38760780e-03,\n",
              "          -2.98702971e-04,  1.27085818e-04]]],\n",
              "\n",
              "\n",
              "       [[[-2.81252089e-04,  2.37927094e-04,  5.64243941e-04,\n",
              "          -6.02675314e-05, -2.45402392e-04],\n",
              "         [ 6.43874642e-05,  2.40264946e-05, -5.68815635e-05,\n",
              "           9.63290732e-05,  3.73017796e-04],\n",
              "         [ 2.23017855e-05,  2.19899001e-04, -9.29930071e-05,\n",
              "          -6.31466383e-04, -3.60608507e-04],\n",
              "         [ 4.88486189e-05, -8.50298445e-05, -1.80595534e-04,\n",
              "          -1.93739920e-04,  7.95843419e-05]],\n",
              "\n",
              "        [[-5.00292498e-04,  1.03655505e-03, -1.26799573e-05,\n",
              "          -8.57784207e-04,  4.72506015e-04],\n",
              "         [-4.48010401e-04,  1.15616707e-03, -6.91512280e-04,\n",
              "          -7.13188462e-04, -4.82732699e-04],\n",
              "         [-3.18195334e-04, -3.19970816e-04, -1.04976385e-03,\n",
              "           3.89360385e-04,  6.78527186e-04],\n",
              "         [-3.43954853e-05,  1.70435143e-04,  3.35896980e-04,\n",
              "           5.96655498e-04,  3.25847274e-07]],\n",
              "\n",
              "        [[-1.34350054e-04,  5.01809940e-04, -3.38204219e-04,\n",
              "          -3.52874540e-04,  5.27309531e-04],\n",
              "         [ 2.67258829e-07,  3.98079182e-04, -3.06328288e-04,\n",
              "           5.96035220e-04,  7.88467440e-04],\n",
              "         [ 3.43583952e-04,  8.72760113e-04, -2.24726817e-04,\n",
              "          -5.33504574e-04, -8.54215747e-05],\n",
              "         [ 1.26342716e-05, -2.32164718e-04, -5.38791018e-04,\n",
              "          -2.86360133e-04,  1.47135955e-04]]]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f\"Input shapes {np.shape(test_input)}, {np.shape(test_output)}\")\n",
        "test_conv.backward(test_input, test_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p1iE85PpMm0Z"
      },
      "outputs": [],
      "source": [
        "class MaxPool2d(Layer):\n",
        "    def __init__(self, kernel_size):\n",
        "        self.kernel_size = kernel_size\n",
        "        self.max_elem_mask = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Perform an pooling:\n",
        "\n",
        "        output_height = input_height // kernel_size\n",
        "        output_width = input_width // kernel_size\n",
        "\n",
        "        input shape: [batch, input_channels, input_height, input_width]\n",
        "        output shape: [batch, input_channels, output_height, output_width]\n",
        "        \"\"\"\n",
        "        type = input.dtype\n",
        "        kernel_size = self.kernel_size\n",
        "        batch = np.shape(input)[0]\n",
        "        input_chanels = np.shape(input)[1]\n",
        "        output_height = np.shape(input)[2]\n",
        "        output_width = np.shape(input)[3]\n",
        "        output = np.empty((output_height, output_width, batch, input_chanels))\n",
        "        self.max_elem_mask = np.empty((batch, input_chanels, np.shape(input)[2], np.shape(input)[3]))\n",
        "        for i in range(output_height):\n",
        "            for j in range(output_width):\n",
        "                input_slice = input[:, :, i:i+kernel_size, j:j+kernel_size]\n",
        "                max_tensor = np.max(input_slice, axis=(2, 3))\n",
        "# How should I handlel such indexes convertions???????\n",
        "                output[i, j] = max_tensor\n",
        "                self.max_elem_mask[:, :, i:i+kernel_size, j:j+kernel_size] = \\\n",
        "                    np.equal(input_slice, np.reshape(max_tensor, \n",
        "                                                     (np.shape(max_tensor)[0],\n",
        "                                                      np.shape(max_tensor)[1],\n",
        "                                                     1, 1)))\n",
        "        return np.moveaxis(output, [0, 1], [2, 3])\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        type = input.dtype\n",
        "        kernel_size = self.kernel_size\n",
        "        grad_input = self.max_elem_mask\n",
        "        for i in range(np.shape(grad_output)[2]):\n",
        "            for j in range(np.shape(grad_output)[3]):\n",
        "                grad_input[:, :, i:i+kernel_size, j:j+kernel_size] = \\\n",
        "                    np.multiply(grad_output[:, :, i:i+1, j:j+1], \n",
        "                                self.max_elem_mask[:, :, i:i+kernel_size, j:j+kernel_size],\n",
        "                                dtype=type)\n",
        "        self.max_elem_mask = None\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 3, 4, 5)\n",
            "input_shape (10, 3, 4, 5) grad shape: (10, 3, 4, 5)\n"
          ]
        }
      ],
      "source": [
        "test_maxpool = MaxPool2d(2)\n",
        "test_output = test_maxpool.forward(test_input)\n",
        "print(np.shape(test_maxpool.max_elem_mask))\n",
        "test_backward = test_maxpool.backward(test_input, test_output)\n",
        "print(f\"input_shape {np.shape(test_input)} grad shape: {np.shape(test_backward)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3W-GM45xSqJD"
      },
      "outputs": [],
      "source": [
        "class Flatten(Layer):\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Perform an flatten operation:\n",
        "\n",
        "        input shape: [batch, input_channels, input_height, input_width]\n",
        "        output shape: [batch, input_channels * output_height * output_width]\n",
        "        \"\"\"\n",
        "        flattened_size = np.shape(input)[1] * np.shape(input)[2] * np.shape(input)[3]\n",
        "        return np.reshape(input, (np.shape(input)[0], flattened_size))\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        return np.reshape(grad_output, np.shape(input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iCuNsUikOoE1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def softmax_crossentropy_with_logits(logits,reference_answers):\n",
        "    \"\"\"Compute crossentropy from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
        "    logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n",
        "\n",
        "    xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
        "\n",
        "    return xentropy\n",
        "\n",
        "def grad_softmax_crossentropy_with_logits(logits,reference_answers):\n",
        "    \"\"\"Compute crossentropy gradient from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
        "    ones_for_answers = np.zeros_like(logits)\n",
        "    ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
        "\n",
        "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
        "\n",
        "    return (- ones_for_answers + softmax) / logits.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muokQIA3UcnL"
      },
      "source": [
        "## Имплементация оптимизатора и изменения learning rate'a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBzMVan_XzFM"
      },
      "source": [
        "В имплементации этих двух классов есть небольшие неточности.\n",
        "Посмотрите, как сделана имплементация метода моментов в Pytorch и добавьте пропущенное.\n",
        "\n",
        "> Добавлять моменты Нестерова не нужно!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "n4hyzuIcUqLd"
      },
      "outputs": [],
      "source": [
        "class SGDOptimizer:\n",
        "    def __init__(self, model, momentum=0.9, dampening=0.0, weight_decay=0.0):\n",
        "        \"\"\"\n",
        "        Wrapper which perfoms weights update\n",
        "        \"\"\"\n",
        "        self.momentum = momentum\n",
        "        self.dampening = dampening\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "        self.model = model\n",
        "        self.momentum_buffer = [None] * len(model)\n",
        "        \n",
        "\n",
        "    def step(self, grad_weights, lr=0.1):\n",
        "        \"\"\"\n",
        "        Update weights\n",
        "        \"\"\"\n",
        "        # For no there is no input parameter\n",
        "        #if self.weight_decay != 0:\n",
        "        #  grad_weights = grad_weights + self.weight_decay * input\n",
        "\n",
        "        for layer, layer_moment, layer_grad_weights in zip(self.model, \n",
        "                                                           self.momentum_buffer,\n",
        "                                                           grad_weights):    \n",
        "            layer_weights = layer.get_weights()\n",
        "            if layer_weights is None:\n",
        "                continue\n",
        "\n",
        "            if self.momentum != 0:\n",
        "                if layer_moment is None:\n",
        "                    layer_moment = layer_grad_weights\n",
        "                else:\n",
        "                    layer_moment = self.momentum * layer_moment + \\\n",
        "                                        (1 - self.dampening) * layer_grad_weights\n",
        "                layer.set_weights(layer_weights - lr * layer_moment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4DX-leurYblp"
      },
      "outputs": [],
      "source": [
        "class LRScheduler:\n",
        "    def __init__(self, lr):\n",
        "        \"\"\"\n",
        "        Wrapper which perfoms learning rate updates\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.current_step = 0\n",
        "\n",
        "    def get_lr(self):\n",
        "      \"\"\"\n",
        "      Update learing rate for current iteration\n",
        "      \"\"\"\n",
        "      current_lr = self.lr / (self.current_step + 1)\n",
        "      #<your code here>\n",
        "      self.current_step += 1\n",
        "      return current_lr\n",
        "\n",
        "    def reset(self):\n",
        "       self.current_step = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlEURTE9OoE5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Итоговая нейросеть\n",
        "\n",
        "Все готово для запуска нейросети. Нейросеть будем тестировать на классическом датасете MNIST. Код ниже визуализирует несколько примеров из этого датасета."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2KKQ81e0OoE6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist(flatten=False)\n",
        "\n",
        "plt.figure(figsize=[6,6])\n",
        "for i in range(4):\n",
        "    plt.subplot(2,2,i+1)\n",
        "    plt.title(\"Label: %i\"%y_train[i])\n",
        "    plt.imshow(X_train[i].reshape([28,28]),cmap='gray');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGXtnvX4OoE7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "В нашей реализации сеть - просто список (Python-list) слоев.\n",
        "\n",
        "\n",
        "\n",
        "> Обратите внимание, что у нас нет глобального пулинга. При изменении архитектуры сети вы должны поменять входую размерность в последнем Dense слое\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VicezF_TOoE8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "network = []\n",
        "network.append(Conv2d(1, 4, 5))\n",
        "network.append(MaxPool2d(2))\n",
        "network.append(ReLU())\n",
        "network.append(Conv2d(4, 8, 5))\n",
        "network.append(MaxPool2d(2))\n",
        "network.append(ReLU())\n",
        "network.append(Flatten())\n",
        "network.append(Dense(3200, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "1sUrd667ZDuK"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = SGDOptimizer(network)\n",
        "scheduler = LRScheduler(learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "482hIf_UOoE9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Реализуйте прямой проход по целой сети, последовательно вызывая .forward() для каждого слоя."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OKRyUyj5OoE9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def forward(network, X):\n",
        "    \"\"\"\n",
        "    Compute activations of all network layers by applying them sequentially.\n",
        "    Return a list of activations for each layer.\n",
        "    Make sure last activation corresponds to network logits.\n",
        "    \"\"\"\n",
        "    activations = []\n",
        "    input = X\n",
        "\n",
        "    for layer in network:\n",
        "        input = layer.forward(input)\n",
        "        activations.append(input)\n",
        "\n",
        "    assert len(activations) == len(network)\n",
        "    return activations\n",
        "\n",
        "def predict(network, X):\n",
        "    \"\"\"\n",
        "    Use network to predict the most likely class for each sample.\n",
        "    \"\"\"\n",
        "    logits = forward(network, X)[-1]\n",
        "    return logits.argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "UfUyHKPyOoE-",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def train(network, X, y, optimizer, scheduler):\n",
        "   \"\"\"\n",
        "   Train your network on a given batch of X and y.\n",
        "   You first need to run forward to get all layer activations.\n",
        "   Then you can run layer.backward going from last to first layer.\n",
        "\n",
        "   After you called backward for all layers, all Dense layers have already made one gradient step.\n",
        "   \"\"\"\n",
        "\n",
        "   # Get the layer activations\n",
        "   layer_activations = forward(network,X)\n",
        "   layer_inputs = [X] + layer_activations  #layer_input[i] is an input for network[i]\n",
        "   logits = layer_activations[-1]\n",
        "\n",
        "   # Compute the loss and the initial gradient\n",
        "   loss = softmax_crossentropy_with_logits(logits,y)\n",
        "   loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n",
        "\n",
        "   grad_weights = []\n",
        "   for i in range(0, len(network)):\n",
        "      cur_pos = len(network) - 1 - i\n",
        "      loss_grad = network[cur_pos].backward(layer_inputs[cur_pos], loss_grad)\n",
        "      grad_weights.insert(0, network[cur_pos].get_grad_weights())\n",
        "\n",
        "   lr = lr = scheduler.get_lr()\n",
        "   # Optimizer performs step for all the weights captured before\n",
        "   optimizer.step(grad_weights, lr)\n",
        "   \n",
        "   return np.mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJG4VMsROoE_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Все готово для запуска обучения. Если все реализовано корректно, то точность классификации на валидационном множестве **должна быть около** 99%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "kq5XTDNNOoE_",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
        "    assert len(inputs) == len(targets)\n",
        "    if shuffle:\n",
        "        indices = np.random.permutation(len(inputs))\n",
        "    for start_idx in tqdm(range(0, len(inputs) - batchsize + 1, batchsize)):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchsize]\n",
        "        else:\n",
        "            excerpt = slice(start_idx, start_idx + batchsize)\n",
        "        yield inputs[excerpt], targets[excerpt]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7q2KcwkTOoFA",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "train_log = []\n",
        "val_log = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "kaxQu9WsOoFB",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c1a1a380eca46a1a47cc71461664bbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1562 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n",
            "set weight\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_batch,y_batch \u001b[38;5;129;01min\u001b[39;00m iterate_minibatches(X_train, y_train, batchsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m----> 4\u001b[0m         train(network, x_batch, y_batch, optimizer, scheduler)\n\u001b[1;32m      6\u001b[0m     train_log\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(predict(network, X_train) \u001b[38;5;241m==\u001b[39m y_train))\n\u001b[1;32m      7\u001b[0m     val_log\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(predict(network, X_val) \u001b[38;5;241m==\u001b[39m y_val))\n",
            "Cell \u001b[0;32mIn[41], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(network, X, y, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(network)):\n\u001b[1;32m     21\u001b[0m    cur_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(network) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m i\n\u001b[0;32m---> 22\u001b[0m    loss_grad \u001b[38;5;241m=\u001b[39m network[cur_pos]\u001b[38;5;241m.\u001b[39mbackward(layer_inputs[cur_pos], loss_grad)\n\u001b[1;32m     23\u001b[0m    grad_weights\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, network[cur_pos]\u001b[38;5;241m.\u001b[39mget_grad_weights())\n\u001b[1;32m     25\u001b[0m lr \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39mget_lr()\n",
            "Cell \u001b[0;32mIn[5], line 95\u001b[0m, in \u001b[0;36mConv2d.backward\u001b[0;34m(self, input, grad_output)\u001b[0m\n\u001b[1;32m     93\u001b[0m tmp_weights \u001b[38;5;241m=\u001b[39m Conv2d\u001b[38;5;241m.\u001b[39m_flip_transpose(tmp_weights)\n\u001b[1;32m     94\u001b[0m tmp_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(tmp_weights, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m grad_input \u001b[38;5;241m=\u001b[39m Conv2d\u001b[38;5;241m.\u001b[39m_conv(grad_padded, tmp_weights, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Gradient step is in a separate optimizer\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_weights\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mand\u001b[39;00m grad_biases\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases\u001b[38;5;241m.\u001b[39mshape\n",
            "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36mConv2d._conv\u001b[0;34m(input, weights, biases)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(output_height):\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(output_width):\n\u001b[1;32m     29\u001b[0m             filters[filter_idx, i, j] \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 30\u001b[0m                 np\u001b[38;5;241m.\u001b[39mtensordot(\u001b[38;5;28minput\u001b[39m[:, :, i:i\u001b[38;5;241m+\u001b[39mkernel_height, j:j\u001b[38;5;241m+\u001b[39mkernel_width],\n\u001b[1;32m     31\u001b[0m                              weights[:, filter_idx, :, :],\n\u001b[1;32m     32\u001b[0m                              axes\u001b[38;5;241m=\u001b[39m([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     33\u001b[0m output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrollaxis(filters, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m biases \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Here values from biases are broadcasted\u001b[39;00m\n",
            "File \u001b[0;32m~/.conda/envs/ML/lib/python3.11/site-packages/numpy/core/numeric.py:1108\u001b[0m, in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m axes_a:\n\u001b[1;32m   1107\u001b[0m     N2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m as_[axis]\n\u001b[0;32m-> 1108\u001b[0m newshape_a \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(multiply\u001b[38;5;241m.\u001b[39mreduce([as_[ax] \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m notin])), N2)\n\u001b[1;32m   1109\u001b[0m olda \u001b[38;5;241m=\u001b[39m [as_[axis] \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m notin]\n\u001b[1;32m   1111\u001b[0m notin \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndb) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m axes_b]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(15):\n",
        "\n",
        "    for x_batch,y_batch in iterate_minibatches(X_train, y_train, batchsize=32, shuffle=True):\n",
        "        train(network, x_batch, y_batch, optimizer, scheduler)\n",
        "\n",
        "    train_log.append(np.mean(predict(network, X_train) == y_train))\n",
        "    val_log.append(np.mean(predict(network, X_val) == y_val))\n",
        "\n",
        "    clear_output()\n",
        "    print(\"Epoch\",epoch)\n",
        "    print(\"Train accuracy:\",train_log[-1])\n",
        "    print(\"Val accuracy:\",val_log[-1])\n",
        "    plt.plot(train_log,label='train accuracy')\n",
        "    plt.plot(val_log,label='val accuracy')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
