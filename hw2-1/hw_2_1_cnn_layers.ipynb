{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ3DJzu7FDX_"
      },
      "source": [
        "# Домашнее задание 2.1. Сверточные сети\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQVARDpwNsOa"
      },
      "source": [
        "В этом задании вы должны:\n",
        "1. Написать слой Conv2d на Numpy и определить в нем forward-backward методы\n",
        "2. Определить слой MaxPool2d\n",
        "3. Написать всю необходимую обвязку для обучения: оптимизатор с адаптивным шагом и класс, позволяющий изменять расписание для learning rate'а\n",
        "\n",
        "\n",
        "\n",
        "> Обратите внимание, что в этом задании больше нет тестов.\n",
        "> Вы должны сами проверять свой код.  \n",
        "> Это можно сделать так:\n",
        "> 1. Написать юнит-тесты с помощью Pytorch. То есть, ваш модудь должен повторять поведение torch'а\n",
        "> 2. Проверять архитектуру не на всем датасете, а на подвыборке: при наивной имплементации слоев одна эпоха на всем датасете будет занимать около двух часов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMVkqpoEOoD3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Numpy-имплементация сверточной нейронной сети\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmTxOp7KOoEG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Вставьте сюда имплементацию из первого домашнего задания.\n",
        "\n",
        "\n",
        "\n",
        "> Обратите внимание, что обновление весов теперь производится с помощью специального класса **Optimizer**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lmfLBp4tOoEN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def load_mnist(flatten=False):\n",
        "    \"\"\"taken from https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py\"\"\"\n",
        "    # We first define a download function, supporting both Python 2 and 3.\n",
        "    if sys.version_info[0] == 2:\n",
        "        from urllib import urlretrieve\n",
        "    else:\n",
        "        from urllib.request import urlretrieve\n",
        "\n",
        "    def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
        "        print(\"Downloading %s\" % filename)\n",
        "        urlretrieve(source + filename, filename)\n",
        "\n",
        "    # We then define functions for loading MNIST images and labels.\n",
        "    # For convenience, they also download the requested files if needed.\n",
        "    import gzip\n",
        "\n",
        "    def load_mnist_images(filename):\n",
        "        if not os.path.exists(filename):\n",
        "            download(filename)\n",
        "        # Read the inputs in Yann LeCun's binary format.\n",
        "        with gzip.open(filename, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "        # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
        "        # following the shape convention: (examples, channels, rows, columns)\n",
        "        data = data.reshape(-1, 1, 28, 28)\n",
        "        # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
        "        # (Actually to range [0, 255/256], for compatibility to the version\n",
        "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
        "        return data / np.float32(256)\n",
        "\n",
        "    def load_mnist_labels(filename):\n",
        "        if not os.path.exists(filename):\n",
        "            download(filename)\n",
        "        # Read the labels in Yann LeCun's binary format.\n",
        "        with gzip.open(filename, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "        # The labels are vectors of integers now, that's exactly what we want.\n",
        "        return data\n",
        "\n",
        "    # We can now download and read the training and test set images and labels.\n",
        "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
        "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
        "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
        "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "    # We reserve the last 10000 training examples for validation.\n",
        "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
        "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
        "\n",
        "    if flatten:\n",
        "        X_train = X_train.reshape([X_train.shape[0], -1])\n",
        "        X_val = X_val.reshape([X_val.shape[0], -1])\n",
        "        X_test = X_test.reshape([X_test.shape[0], -1])\n",
        "\n",
        "    # We just return all the arrays in order, as expected in main().\n",
        "    # (It doesn't matter how we do this as long as we can read them again.)\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jYZ3ptaiOoER",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    \"\"\"\n",
        "    A building block. Each layer is capable of performing two things:\n",
        "\n",
        "    - Process input to get output:           output = layer.forward(input)\n",
        "\n",
        "    - Propagate gradients through itself:    grad_input = layer.backward(input, grad_output)\n",
        "\n",
        "    Some layers also have learnable parameters which they update during layer.backward.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"Here you can initialize layer parameters (if any) and auxiliary stuff.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Takes input data of shape [batch, input_units], returns output data [batch, output_units]\n",
        "        \"\"\"\n",
        "        return input\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        \"\"\"\n",
        "        Performs a backpropagation step through the layer, with respect to the given input.\n",
        "\n",
        "        To compute loss gradients w.r.t input, you need to apply chain rule (backprop):\n",
        "\n",
        "        d loss / d x  = (d loss / d layer) * (d layer / d x)\n",
        "\n",
        "        Luckily, you already receive d loss / d layer as input, so you only need to multiply it by d layer / d x.\n",
        "\n",
        "        If your layer has parameters (e.g. dense layer), you also need to update them here using d loss / d layer\n",
        "        \"\"\"\n",
        "        input_dim = input.shape[1]\n",
        "\n",
        "        d_layer_d_input = np.eye(input_dim)\n",
        "\n",
        "        return np.dot(grad_output, d_layer_d_input) # chain rule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Qe246l61OoEe",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class ReLU(Layer):\n",
        "    def __init__(self):\n",
        "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n",
        "        pass\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Apply elementwise ReLU to [batch, input_units] matrix\"\"\"\n",
        "        output = np.array(input)\n",
        "        output[output < 0] = 0\n",
        "        return output\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        \"\"\"Compute gradient of loss w.r.t. ReLU input\"\"\"\n",
        "        relu_grad_mask = np.zeros_like(input)\n",
        "        relu_grad_mask[input > 0] = 1\n",
        "        return grad_output * relu_grad_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g22Gzs_2OoEl",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class Dense(Layer):\n",
        "    def __init__(self, input_units, output_units, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        A dense layer is a layer which performs a learned affine transformation:\n",
        "        f(x) = <W*x> + b\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # initialize weights with small random numbers from normal distribution\n",
        "        # you can change the intializtion method\n",
        "        self.weights = np.random.randn(input_units, output_units)*0.01\n",
        "        self.biases = np.zeros(output_units)\n",
        "\n",
        "    def forward(self,input):\n",
        "        \"\"\"\n",
        "        Perform an affine transformation:\n",
        "        f(x) = <W*x> + b\n",
        "\n",
        "        input shape: [batch, input_units]\n",
        "        output shape: [batch, output_units]\n",
        "        \"\"\"\n",
        "        return np.dot(input, self.weights) + self.biases\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "\n",
        "        # compute d f / d x = d f / d dense * d dense / d x\n",
        "        # where d dense/ d x = weights transposed\n",
        "        # grad_output is a derivative of the next (in forward) layer of prediction\n",
        "        # this result is needed for the next layer\n",
        "        grad_input = np.dot(grad_output, np.transpose(self.weights))\n",
        "\n",
        "        # compute gradient w.r.t. weights and biases\n",
        "        grad_weights = np.dot(np.transpose(input), grad_output)\n",
        "        grad_biases = np.sum(grad_output, axis=0)\n",
        "\n",
        "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
        "        # Here we perform a stochastic gradient descent step.\n",
        "        # or step of another gradient method\n",
        "        self.weights = self.weights - self.learning_rate * grad_weights\n",
        "        self.biases = self.biases - self.learning_rate * grad_biases\n",
        "\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "A1vN8h41ILY9"
      },
      "outputs": [],
      "source": [
        "class Conv2d(Layer):\n",
        "    def __init__(self, input_channels, output_channels, kernel_size):\n",
        "\n",
        "        self.weights = np.random.randn(input_channels, output_channels, kernel_size, kernel_size)*0.01\n",
        "        self.biases = np.zeros(output_channels)\n",
        "        self.output_chanels = output_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        self.grad_weights = None\n",
        "        self.grad_biases = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Perform an convolution:\n",
        "\n",
        "        output_height = input_height - kernel_size + 1\n",
        "        output_width = input_width - kernel_size + 1\n",
        "\n",
        "        input shape: [batch, input_channels, input_height, input_width]\n",
        "        output shape: [batch, output_channels, output_height, output_width]\n",
        "        \"\"\"\n",
        "        # Output dimention is determined by the number of filters in the layer.\n",
        "        # Each filter is a tensor with the size (input_channels, kernel_size, kernel_size)\n",
        "        # (In this example second axis is an index of filter)\n",
        "        # Such a filter produces one number per convolution \n",
        "        #   and this convolution is performed for each part of the input tensor.\n",
        "        batch_size = np.shape(input)[0]\n",
        "        output_height = np.shape(input)[2] - self.kernel_size + 1\n",
        "        output_width = np.shape(input)[3] - self.kernel_size + 1\n",
        "\n",
        "        # This is the result of convollution of each filter\n",
        "        filters = np.empty((self.output_chanels, output_height, output_width, batch_size))\n",
        "        for filter_idx in range(self.output_chanels):\n",
        "            for i in range(output_height):\n",
        "                for j in range(output_width):\n",
        "                    filters[filter_idx, i, j] = \\\n",
        "                        np.tensordot(input[:, :, i:i+self.kernel_size, j:j+self.kernel_size],\n",
        "                                     self.weights[:, filter_idx, :, :],\n",
        "                                     axes=([1, 2, 3], [0, 1, 2]))\n",
        "        return np.rollaxis(filters, 3, 0)\n",
        "        \n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        #grad_input = <your code here>\n",
        "\n",
        "        #grad_weights = <your code here>\n",
        "        #grad_biases = <your code here>\n",
        "\n",
        "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
        "\n",
        "        self.grad_weights = grad_weights\n",
        "        self.grad_biases = grad_biases\n",
        "\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[-0.6838,  0.0923, -0.4602,  0.4486],\n",
            "          [ 0.5164, -0.3346, -0.2623, -0.4785],\n",
            "          [ 0.4358,  0.1483,  0.0891, -0.2875]],\n",
            "\n",
            "         [[-1.1064,  0.2061, -0.6074,  1.4716],\n",
            "          [ 0.2603, -0.6969,  0.0148,  0.8142],\n",
            "          [ 0.2549, -1.5044,  0.6521,  0.1686]]],\n",
            "\n",
            "\n",
            "        [[[-0.8534,  0.4540, -0.3437, -0.4620],\n",
            "          [-0.3190,  0.2090, -0.1892, -0.3953],\n",
            "          [-0.1837, -0.1451, -0.0466, -0.1749]],\n",
            "\n",
            "         [[ 0.2089,  0.1504, -0.6972, -1.0789],\n",
            "          [ 0.1066, -0.0919, -0.8480,  0.1634],\n",
            "          [ 0.1517,  0.5613,  0.1536,  1.0877]]],\n",
            "\n",
            "\n",
            "        [[[-0.5526, -0.8650,  0.1007, -0.7047],\n",
            "          [-0.8038, -0.3513, -0.0599,  0.0467],\n",
            "          [ 0.2070, -0.3426,  0.1781, -0.2867]],\n",
            "\n",
            "         [[ 0.7698,  0.7011,  0.1731, -0.2240],\n",
            "          [-0.0336,  0.1821, -0.5542, -0.6382],\n",
            "          [ 1.1757, -1.3990, -0.0182,  0.7523]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0263, -0.7677,  0.0338, -0.4457],\n",
            "          [-0.0618,  0.5206, -0.3122, -0.0073],\n",
            "          [-0.1349, -0.4238,  0.1395,  0.3325]],\n",
            "\n",
            "         [[ 1.7262, -0.4790,  0.2851, -0.2574],\n",
            "          [ 1.0839, -0.1951, -0.2953, -0.6637],\n",
            "          [ 0.5716,  0.1706,  1.2002, -0.1376]]],\n",
            "\n",
            "\n",
            "        [[[-0.3077, -0.0338,  0.5558, -0.0443],\n",
            "          [ 0.4105,  0.2224, -0.0308,  0.1021],\n",
            "          [-0.0770, -0.0058,  0.2642,  0.1877]],\n",
            "\n",
            "         [[-0.9994, -0.1514,  1.0108,  0.4637],\n",
            "          [ 0.3872, -0.5255, -0.7114, -0.1346],\n",
            "          [ 0.3996,  0.6179,  0.0408, -0.6557]]],\n",
            "\n",
            "\n",
            "        [[[-0.1868,  0.0049, -0.0778,  0.0546],\n",
            "          [-0.5955, -1.1501, -0.1822, -0.8173],\n",
            "          [-0.2052, -0.6210, -0.7519, -0.3051]],\n",
            "\n",
            "         [[ 0.2633,  0.5314,  0.8131,  0.3509],\n",
            "          [ 0.1942, -0.1167,  0.9895, -0.0022],\n",
            "          [ 0.7617, -0.7050, -0.4252, -0.8417]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8192,  0.0106, -0.5678, -0.7866],\n",
            "          [ 0.0872,  0.6887, -0.0831, -0.6839],\n",
            "          [ 0.3038, -0.4365, -0.1343,  0.3532]],\n",
            "\n",
            "         [[ 0.3477, -0.6505,  0.3871,  0.4025],\n",
            "          [-0.4083,  1.3012,  0.1530, -1.1075],\n",
            "          [-0.1420, -0.7064,  0.1564,  0.8110]]],\n",
            "\n",
            "\n",
            "        [[[-0.3773, -0.2039,  0.6800, -0.2476],\n",
            "          [-0.1078, -1.3205, -0.7517,  0.5737],\n",
            "          [-0.9867, -0.1358, -0.4015, -0.4637]],\n",
            "\n",
            "         [[-0.5080,  0.4231,  1.0305, -0.5156],\n",
            "          [ 0.4490, -0.7375,  0.2250,  1.2398],\n",
            "          [ 0.5599,  0.6250, -0.8725,  0.2586]]],\n",
            "\n",
            "\n",
            "        [[[-0.1448, -0.2318,  0.4924,  0.2367],\n",
            "          [-0.6374, -0.9098,  0.0321,  0.1547],\n",
            "          [-0.4106, -0.0678, -0.5179, -0.0758]],\n",
            "\n",
            "         [[ 1.3459, -0.1533, -0.0997, -0.1250],\n",
            "          [ 0.5558, -1.0604,  0.1926,  1.0730],\n",
            "          [ 0.8865, -0.2910, -0.3403,  1.0034]]],\n",
            "\n",
            "\n",
            "        [[[-0.1777, -0.5728, -0.4227,  0.0206],\n",
            "          [ 0.6452, -0.1107,  0.5906,  0.4374],\n",
            "          [-0.1373,  0.7136, -0.0404, -0.6273]],\n",
            "\n",
            "         [[ 0.3992, -0.8988,  0.4391, -0.8483],\n",
            "          [ 1.6989, -0.3364, -0.1230,  0.0507],\n",
            "          [ 0.0940,  0.1065,  0.1329,  0.7309]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "[[[[ 1.90174109e-02  7.76455956e-03 -5.14997815e-02 -1.32054417e-02]\n",
            "   [-5.64569925e-03  1.06732933e-02 -6.94241862e-04  5.49949201e-02]\n",
            "   [ 2.50670545e-02 -3.38667442e-02  5.09243311e-03 -3.52586535e-02]]\n",
            "\n",
            "  [[-1.26748866e-02 -1.21061688e-03  9.00932519e-03  2.15254101e-02]\n",
            "   [-2.28080541e-02  2.31478688e-02  2.58181163e-02 -6.88763782e-04]\n",
            "   [ 8.06223808e-03 -3.35332387e-03 -1.04244450e-02  8.98850031e-03]]]\n",
            "\n",
            "\n",
            " [[[ 2.14844014e-02  1.40573795e-02  2.65857493e-02 -1.32854017e-02]\n",
            "   [ 2.77414928e-02  1.10203297e-02 -7.02693155e-03 -1.75624061e-02]\n",
            "   [-8.27095314e-03 -2.53696840e-02 -3.30068823e-02  2.74518396e-02]]\n",
            "\n",
            "  [[ 8.76254251e-03 -2.13410834e-02  5.76086103e-04  4.44175822e-04]\n",
            "   [-1.50128376e-02  4.79979315e-03  1.22397421e-02  9.54492166e-03]\n",
            "   [-3.45689153e-02  5.10167575e-02 -3.22104710e-02  1.88577786e-03]]]\n",
            "\n",
            "\n",
            " [[[ 1.22710983e-02  2.81638956e-03 -3.97766204e-02 -2.79595869e-03]\n",
            "   [ 2.55915093e-02  3.28510444e-02 -6.44344631e-03 -8.78020999e-03]\n",
            "   [ 3.73379619e-02  9.38722200e-04 -1.17093814e-02  1.78827793e-02]]\n",
            "\n",
            "  [[ 1.38616024e-03  2.55247083e-02 -2.62136605e-02  2.77789233e-02]\n",
            "   [ 3.58192095e-02 -2.29996241e-02  2.03649240e-02 -3.76231621e-03]\n",
            "   [-3.49413162e-03 -1.81719744e-02 -3.39871415e-03  1.87791088e-02]]]\n",
            "\n",
            "\n",
            " [[[ 4.65193177e-02  7.25371272e-04 -1.08341050e-02 -1.21158479e-02]\n",
            "   [ 1.13715423e-02 -3.32868116e-02  2.23783808e-02 -3.39520698e-02]\n",
            "   [ 4.08870275e-02 -8.66054173e-03 -2.72745772e-02 -1.60570283e-02]]\n",
            "\n",
            "  [[ 1.46789148e-02 -1.64546646e-02 -1.16150589e-02  2.13080908e-02]\n",
            "   [ 1.03226177e-02  2.01755138e-03  1.27054010e-02 -2.78465228e-02]\n",
            "   [-2.71475058e-02  3.67911546e-02  6.51611681e-03  5.49069821e-03]]]\n",
            "\n",
            "\n",
            " [[[-4.30177330e-02  2.49721403e-03 -2.57762491e-03  5.09813342e-03]\n",
            "   [-2.10886030e-03  1.80561068e-02  1.92175629e-02  4.73105634e-03]\n",
            "   [ 5.20716927e-03  2.05094750e-04  1.39083069e-03  5.66251243e-03]]\n",
            "\n",
            "  [[-2.85598685e-02 -5.51531102e-03  1.39860558e-02  4.47157955e-02]\n",
            "   [-2.43622133e-02  4.25813641e-03  5.20798158e-03  3.02184997e-03]\n",
            "   [-9.53976555e-04  1.22794365e-02 -8.17368001e-03 -3.50578338e-02]]]\n",
            "\n",
            "\n",
            " [[[ 2.83792911e-02 -1.58870099e-02 -3.04800284e-02  5.40197222e-02]\n",
            "   [ 2.75343862e-02 -4.04423690e-02 -2.96190030e-04 -1.12974217e-02]\n",
            "   [ 1.20013634e-02 -1.09917419e-02  6.99013333e-02  9.86032603e-05]]\n",
            "\n",
            "  [[-1.59647803e-02 -1.67318236e-03 -2.36190120e-02 -6.49716890e-03]\n",
            "   [-1.58280352e-02 -7.56357146e-03 -2.48709294e-02 -5.79697665e-03]\n",
            "   [ 2.96065121e-02 -1.90897882e-02  1.19879187e-02 -8.20339181e-03]]]\n",
            "\n",
            "\n",
            " [[[-3.36442973e-02  9.12111257e-04  1.31380189e-02 -1.38053650e-02]\n",
            "   [-4.20547119e-02 -5.92845893e-03 -1.65678930e-02 -1.31781139e-03]\n",
            "   [ 2.26983967e-02  4.66058627e-02  2.73407111e-02 -1.11365719e-02]]\n",
            "\n",
            "  [[ 1.07655294e-02  1.50531450e-02  6.54231762e-03  1.93680270e-02]\n",
            "   [ 3.36500201e-02 -1.20036045e-02  4.71116463e-02  5.83855320e-03]\n",
            "   [-3.14204660e-02  1.63510996e-02 -8.17594026e-03 -9.57190906e-03]]]\n",
            "\n",
            "\n",
            " [[[-2.89103448e-02 -5.29511626e-02 -2.09891366e-02 -1.54601895e-02]\n",
            "   [ 3.25153169e-02  3.69231547e-02  7.24544988e-03  1.44875137e-02]\n",
            "   [ 5.54555169e-03 -1.07204246e-02 -1.21757600e-03  5.10502793e-02]]\n",
            "\n",
            "  [[-1.11692803e-02 -3.55218413e-03 -1.97061473e-02  1.74423678e-02]\n",
            "   [-1.28936454e-02 -9.97745136e-03  1.37658339e-04  6.08596839e-03]\n",
            "   [ 2.82905400e-02 -2.64760724e-02 -1.06652326e-02 -7.31664668e-03]]]\n",
            "\n",
            "\n",
            " [[[ 1.23112311e-02 -2.14083202e-02 -9.77609190e-03 -3.91758110e-02]\n",
            "   [ 5.09596711e-02 -7.19430919e-03 -1.23361519e-02  2.49321971e-02]\n",
            "   [ 4.53056018e-02 -1.11767746e-02 -1.95156540e-02  2.02682574e-02]]\n",
            "\n",
            "  [[ 1.44569625e-02 -4.30789218e-02 -2.13693314e-02  2.95324691e-02]\n",
            "   [ 2.76629391e-02 -2.01106469e-02 -1.13969315e-02  1.79150049e-02]\n",
            "   [ 5.09747843e-02 -1.99240664e-02  4.00850341e-02  3.03280824e-02]]]\n",
            "\n",
            "\n",
            " [[[ 4.00211092e-02  8.26931555e-03  2.50948986e-02 -3.98054694e-02]\n",
            "   [-8.47888224e-03 -3.93419788e-02 -2.41108370e-02  2.46782868e-03]\n",
            "   [-2.54174636e-02 -2.00828167e-02  4.16139177e-02  2.14135124e-04]]\n",
            "\n",
            "  [[ 3.11794097e-02 -1.48633104e-02  1.10650345e-02 -1.89339287e-03]\n",
            "   [-1.84127010e-04  1.09473607e-02  1.44137673e-02  1.19712148e-02]\n",
            "   [ 1.12013514e-02 -1.38569353e-02 -1.56044518e-02  5.68558690e-02]]]]\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[36], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_ref)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_output)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(torch\u001b[38;5;241m.\u001b[39mtensor(test_output, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat), test_ref)\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Conv2D test\n",
        "#from torch import nn\n",
        "#import torch\n",
        "#test_batch_size = 10\n",
        "#test_input_chanels = 3\n",
        "#test_output_chanels = 2\n",
        "#test_input_height = 4\n",
        "#test_input_width = 5\n",
        "#test_kernel_size = 2\n",
        "#\n",
        "#test_conv = Conv2d(input_channels=test_input_chanels, \n",
        "#                   output_channels=test_output_chanels, \n",
        "#                   kernel_size=test_kernel_size)\n",
        "#test_input = np.random.randn(test_batch_size, \n",
        "#                             test_input_chanels, \n",
        "#                             test_input_height,\n",
        "#                             test_input_width)\n",
        "#test_output = test_conv.forward(test_input)\n",
        "#test_layer = nn.Conv2d(in_channels=test_input_chanels,\n",
        "#                     out_channels=test_output_chanels,\n",
        "#                     kernel_size=(test_kernel_size, test_kernel_size))\n",
        "#test_ref = test_layer(torch.tensor(test_input, dtype=torch.float))\n",
        "#print(test_ref)\n",
        "#print(test_output)\n",
        "#assert torch.equal(torch.tensor(test_output, dtype=torch.float), test_ref)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1iE85PpMm0Z"
      },
      "outputs": [],
      "source": [
        "class MaxPool2d(Layer):\n",
        "    def __init__(self, kernel_size):\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Perform an pooling:\n",
        "\n",
        "        output_height = input_height // kernel_size\n",
        "        output_width = input_width // kernel_size\n",
        "\n",
        "        input shape: [batch, input_channels, input_height, input_width]\n",
        "        output shape: [batch, input_channels, output_height, output_width]\n",
        "        \"\"\"\n",
        "        #<your code here>\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        #grad_input = <your code here>\n",
        "\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W-GM45xSqJD"
      },
      "outputs": [],
      "source": [
        "class Flatten(Layer):\n",
        "    def forward(self, input):\n",
        "          \"\"\"\n",
        "          Perform an flatten operation:\n",
        "\n",
        "          input shape: [batch, input_channels, input_height, input_width]\n",
        "          output shape: [batch, input_channels * output_height * output_width]\n",
        "          \"\"\"\n",
        "          #<your code here>\n",
        "\n",
        "    def backward(self, input, grad_output):\n",
        "        #grad_input = <your code here>\n",
        "\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCuNsUikOoE1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def softmax_crossentropy_with_logits(logits,reference_answers):\n",
        "    \"\"\"Compute crossentropy from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
        "    logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n",
        "\n",
        "    xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
        "\n",
        "    return xentropy\n",
        "\n",
        "def grad_softmax_crossentropy_with_logits(logits,reference_answers):\n",
        "    \"\"\"Compute crossentropy gradient from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
        "    ones_for_answers = np.zeros_like(logits)\n",
        "    ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
        "\n",
        "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
        "\n",
        "    return (- ones_for_answers + softmax) / logits.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muokQIA3UcnL"
      },
      "source": [
        "## Имплементация оптимизатора и изменения learning rate'a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBzMVan_XzFM"
      },
      "source": [
        "В имплементации этих двух классов есть небольшие неточности.\n",
        "Посмотрите, как сделана имплементация метода моментов в Pytorch и добавьте пропущенное.\n",
        "\n",
        "> Добавлять моменты Нестерова не нужно!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4hyzuIcUqLd"
      },
      "outputs": [],
      "source": [
        "class SGDOptimizer:\n",
        "    def __init__(self, momentum=0.9, dampening=0.0, weight_decay=0.0):\n",
        "        \"\"\"\n",
        "        Wrapper which perfoms weights update\n",
        "        \"\"\"\n",
        "        self.momentum = momentum\n",
        "        self.dampening = dampening\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "        # здесь будем копить моментумы\n",
        "        self.momentum_buffer = 0\n",
        "\n",
        "    def step(self, weights, grad_weights, lr=0.1):\n",
        "      \"\"\"\n",
        "      Update weights\n",
        "      \"\"\"\n",
        "      self.momentum_buffer = self.momentum * self.momentum_buffer + (1 - self.dampening) * grad_weights\n",
        "\n",
        "      #<your code here>\n",
        "\n",
        "      return weights - lr * self.momentum_buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DX-leurYblp"
      },
      "outputs": [],
      "source": [
        "class LRScheduler:\n",
        "    def __init__(self, lr):\n",
        "        \"\"\"\n",
        "        Wrapper which perfoms learning rate updates\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.current_step = 0\n",
        "\n",
        "    def get_lr(self, step):\n",
        "      \"\"\"\n",
        "      Update learing rate for current iteration\n",
        "      \"\"\"\n",
        "      current_lr = self.lr / (self.current_step + 1)\n",
        "      #<your code here>\n",
        "      self.current_step += 1\n",
        "      return current_lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlEURTE9OoE5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Итоговая нейросеть\n",
        "\n",
        "Все готово для запуска нейросети. Нейросеть будем тестировать на классическом датасете MNIST. Код ниже визуализирует несколько примеров из этого датасета."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KKQ81e0OoE6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist(flatten=False)\n",
        "\n",
        "plt.figure(figsize=[6,6])\n",
        "for i in range(4):\n",
        "    plt.subplot(2,2,i+1)\n",
        "    plt.title(\"Label: %i\"%y_train[i])\n",
        "    plt.imshow(X_train[i].reshape([28,28]),cmap='gray');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGXtnvX4OoE7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "В нашей реализации сеть - просто список (Python-list) слоев.\n",
        "\n",
        "\n",
        "\n",
        "> Обратите внимание, что у нас нет глобального пулинга. При изменении архитектуры сети вы должны поменять входую размерность в последнем Dense слое\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VicezF_TOoE8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "network = []\n",
        "network.append(Conv2d(1, 4, 5))\n",
        "network.append(MaxPool2d(2))\n",
        "network.append(ReLU())\n",
        "network.append(Conv2d(4, 8, 5))\n",
        "network.append(MaxPool2d(2))\n",
        "network.append(ReLU())\n",
        "network.append(Flatten())\n",
        "network.append(Dense(5 * 5 * 8, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sUrd667ZDuK"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = SGDOptimizer()\n",
        "scheduler = LRScheduler(learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "482hIf_UOoE9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Реализуйте прямой проход по целой сети, последовательно вызывая .forward() для каждого слоя."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKRyUyj5OoE9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def forward(network, X):\n",
        "    \"\"\"\n",
        "    Compute activations of all network layers by applying them sequentially.\n",
        "    Return a list of activations for each layer.\n",
        "    Make sure last activation corresponds to network logits.\n",
        "    \"\"\"\n",
        "    activations = []\n",
        "    input = X\n",
        "\n",
        "    # <your code here>\n",
        "\n",
        "    assert len(activations) == len(network)\n",
        "    return activations\n",
        "\n",
        "def predict(network, X):\n",
        "    \"\"\"\n",
        "    Use network to predict the most likely class for each sample.\n",
        "    \"\"\"\n",
        "    logits = forward(network, X)[-1]\n",
        "    return logits.argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfUyHKPyOoE-",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def train(network,X,y):\n",
        "    \"\"\"\n",
        "    Train your network on a given batch of X and y.\n",
        "    You first need to run forward to get all layer activations.\n",
        "    Then you can run layer.backward going from last to first layer.\n",
        "\n",
        "    After you called backward for all layers, all Dense layers have already made one gradient step.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the layer activations\n",
        "    layer_activations = forward(network,X)\n",
        "    layer_inputs = [X] + layer_activations  #layer_input[i] is an input for network[i]\n",
        "    logits = layer_activations[-1]\n",
        "\n",
        "    # Compute the loss and the initial gradient\n",
        "    loss = softmax_crossentropy_with_logits(logits,y)\n",
        "    loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n",
        "\n",
        "    # propagate gradients through network layers using .backward\n",
        "    # hint: start from last layer and move to earlier layers\n",
        "    #<YOUR CODE>\n",
        "\n",
        "    # update weights and biases with optimizer\n",
        "    #<YOUR CODE>\n",
        "\n",
        "    # update learning rate\n",
        "    #<YOUR CODE>\n",
        "\n",
        "    return np.mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJG4VMsROoE_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Все готово для запуска обучения. Если все реализовано корректно, то точность классификации на валидационном множестве **должна быть около** 99%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq5XTDNNOoE_",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
        "    assert len(inputs) == len(targets)\n",
        "    if shuffle:\n",
        "        indices = np.random.permutation(len(inputs))\n",
        "    for start_idx in tqdm(range(0, len(inputs) - batchsize + 1, batchsize)):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchsize]\n",
        "        else:\n",
        "            excerpt = slice(start_idx, start_idx + batchsize)\n",
        "        yield inputs[excerpt], targets[excerpt]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7q2KcwkTOoFA",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "train_log = []\n",
        "val_log = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaxQu9WsOoFB",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for epoch in range(15):\n",
        "\n",
        "    for x_batch,y_batch in iterate_minibatches(X_train, y_train, batchsize=32, shuffle=True):\n",
        "        train(network, x_batch, y_batch)\n",
        "\n",
        "    train_log.append(np.mean(predict(network, X_train) == y_train))\n",
        "    val_log.append(np.mean(predict(network, X_val) == y_val))\n",
        "\n",
        "    clear_output()\n",
        "    print(\"Epoch\",epoch)\n",
        "    print(\"Train accuracy:\",train_log[-1])\n",
        "    print(\"Val accuracy:\",val_log[-1])\n",
        "    plt.plot(train_log,label='train accuracy')\n",
        "    plt.plot(val_log,label='val accuracy')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
